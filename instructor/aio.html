<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>HPC User: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<script src="../assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="../assets/styles.css">
<script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../favicons/incubator/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicons/incubator/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../favicons/incubator/favicon-16x16.png">
<link rel="manifest" href="../favicons/incubator/site.webmanifest">
<link rel="mask-icon" href="../favicons/incubator/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="white">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="black">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo.svg"><span class="badge text-bg-danger">
          <abbr title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.">
            <a href="https://docs.carpentries.org/resources/curriculum/lesson-life-cycle.html" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
              Pre-Alpha
            </a>
            <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text">
<li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul>
</li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='../aio.html';">Learner View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      HPC User
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            HPC User
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<hr>
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul>
</li>
      </ul>
</div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="../instructor/aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  HPC User
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text">
<li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul>
</li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../aio.html">Learner View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->

            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="introduction.html">1. Introduction</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="profiling-code.html">2. Profiling Code for Performance</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="performance-concepts.html">3. Performance Concepts</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="parallel-concepts.html">4. Parallel Computing Concepts</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="multi-threaded.html">5. Multi-Threaded Programs</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="message-passing.html">6. Message-Passing Programs</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="language-survey.html">7. Language Survey</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="c-cpp.html">8. C and C++ Languages</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush10">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading10">
        <a href="fortran.html">9. The Fortran Language</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush11">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading11">
        <a href="python.html">10. The Python Language</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush12">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading12">
        <a href="r.html">11. The R Language</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush13">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading13">
        <a href="matlab.html">12. The Matlab Language</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush14">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading14">
        <a href="array-jobs.html">13. Array Jobs</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush15">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading15">
        <a href="gpus.html">14. Accelerating Scientific Computing with GPUs</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush16">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading16">
        <a href="high-throughput-computing.html">15. High-Throughput Computing</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush17">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading17">
        <a href="hpc-resources.html">16. HPC Resources</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <hr>
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources">
<a href="../instructor/aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">

            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-introduction"><p>Content from <a href="introduction.html">Introduction</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/introduction.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 20 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What should I expect to learn from the HPC User module?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Set the basis for learning about High-Performance Computing in
Science.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="overview">Overview<a class="anchor" aria-label="anchor" href="#overview"></a>
</h2>
<hr class="half-width">
<p>In doing computational science it is very common to start a project
by writing code on a personal computer. Often as the project proceeds we
find that we need more computer resources to complete the science
project. This may come in the form of needing more processing power to
complete the research in a reasonable time. It may also mean needing
more memory to be able to run larger calculations. Or it may just mean
needing to do a very large number of smaller jobs that would overwhelm a
single computer system.</p>
<p>In these cases where we need to seek out more computational
resources, we also need to start understanding the performance aspects
of our code. More power is not always the answer, sometimes writing more
efficient code can get the job done equally as well.</p>
<p>This HPC User lesson is aimed at scientists who need to use computers
to do calculations, and not at computer scientists or computer engineers
who need to be experts at programming in a High-Performance Computing
environment. This lesson will be aimed at giving an overview of
performance concepts to provide a general understanding of how to
operate in an HPC environment.</p>
</section><section><h2 class="section-heading" id="organization">Organization<a class="anchor" aria-label="anchor" href="#organization"></a>
</h2>
<hr class="half-width">
<p>The first few chapters concentrate on discussing performance issues
at the conceptual level with practical examples. <strong>These examples
are currently given in Python but it is intended to eventually have the
user and instructor choose the language that the examples display in to
make it more appropriate to teach this to groups primarily interested in
R, C/C++, Fortran, or Matlab too</strong>. As the lesson proceeds these
same concepts will be used in different ways and with examples in
different computer languages to help drill them in.</p>
<p>The middle third of the lesson is a language survey. Even though most
scientists may work primarily in a single language, it is important to
understand the strengths and weaknesses of alternative languages as well
as their own favorite.</p>
<p>The last sections provide overviews of some more advanced topics like
working with GPUs to accelerate scientific codes. It may be that some of
this will be skipped by your instructor due to time limitations but it
is good to have these available for reference purposes.</p>
<p>There are hands-on exercises throughout the lesson where you will be
asked to apply some of what you have learned. There are also optional
homework assignments available for those who want to challenge
themselves outside of the workshop.</p>
<p>Most sections also have website links at the end which provide a
means to seek out more information.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>The HPC User lesson will help to understand basic concepts affecting
performance in programming.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-profiling-code"><p>Content from <a href="profiling-code.html">Profiling Code for Performance</a></p>
<hr>
<p>Last updated on 2025-09-17 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/profiling-code.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 20 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How to measure performance?</li>
<li>How to measure memory usage?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Learn the different methods available to measure time and memory
usage externally and from within a program.</li>
<li>Understand what parts of a program are important to time.</li>
<li>Learn how to do a scaling study for multi-core and multi-node
jobs.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>When we talk about the performance of a program, we are always
interested in how much time it takes to run, but in some cases we also
need to know how much memory the program uses if we are pushing the
limits of our computer. Even more than that, we often need to know how
much time each part of the code takes so that we know where to
concentrate our efforts as we try to improve the overall performance of
the program. So we need to be able to time the entire run, and also
internally each part of the code. For parallel codes, we also need to
know how efficiently they scale as we increase the number of cores or
compute nodes in order to determine what resources to request.</p>
<section><h2 class="section-heading" id="timing-a-program-externally">Timing a Program Externally<a class="anchor" aria-label="anchor" href="#timing-a-program-externally"></a>
</h2>
<hr class="half-width">
<p>Linux has a <strong>time</strong> function that can proceed any
command, so this can be used to time the entire job externally even if
we don’t have access to the source code. This can be used to time a
short test run in order to estimate the run time needed for the complete
job. When we get to talking about parallel computing, or using multiple
compute cores to run a single job, the <strong>time</strong> function
will prove useful for getting the execution time for a job as it depends
on the number of cores. For example, it is common to test the same job
on 1, 4, 8, 16, and 32 cores to see how it scales with more cores to
determine what number of cores is most efficient to use.</p>
<p>Let’s start with a few simple examples of using the
<strong>time</strong> function at the command prompt. Try timing the
<strong>pwd</strong> command which prints the current working
directory.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="bu">time</span> pwd</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>/Users/daveturner

real	0m0.000s
user	0m0.000s
sys	0m0.000s</code></pre>
</div>
<p>The first thing you see is the output of the <strong>pwd</strong>
command, which in this case is the directory
<strong>/Users/daveturner</strong> on my Mac. Then the
<strong>time</strong> function prints its output, always as real time,
which is what we want, then user and system time which we can ignore.
This shows that the <strong>pwd</strong> command is faster than the
clock can measure. This is important to note that the
<strong>time</strong> command isn’t accurate to less than 1 millisecond,
so in general we should always make sure we are measuring execution
times that are greater than a second in general.</p>
<p>Below is another example where this time we are timing the
<strong>ls</strong> function which will list the files in the current
directory.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="bu">time</span> ls</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>file1 file2 file3

real	0m0.110s
user	0m0.006s
sys	0m0.027s</code></pre>
</div>
<p>When I do this on my Mac, I get a real time of just 0.006 seconds
because it’s really fast to access the local hard disk. The test above
is from a very large cluster computer that has a parallel file server
with 1 Petabyte of storage (1 Petabyte is 1000 Terabytes, and each
Terabyte is 1000 Gigabytes). The performance for accessing large files
on a parallel file server is very good, but it does take longer to do
small tasks like get the contents of the current directory. How does
this compare to the system you are on? On large HPC (High-Performance
Computing) systems like this cluster, the speed also depends on what
file system you are testing. You can usually access the local disk at
/tmp, but your home directory may be on another file system, and often
there is fast scratch space that is very high performance but only used
for programs when they are running.</p>
<p>Below we are going to use the <strong>sleep</strong> command to time
an interval of 5 seconds just to simulate what we might see in a real
job. In this case, even though the sleep function was supposed to go 5
seconds, there was some overhead or inaccuracy in the timing routine or
the length of the sleep. This is one thing that you always need to be
aware of when measuring performance. If you are measuring short things,
you may want to measure multiple times and take an average.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="bu">time</span> sleep 5</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>real	0m5.052s
user	0m0.001s
sys	0m0.003s</code></pre>
</div>
<p>In addition to worrying about the clock accuracy, you also need to
worry about interference from other jobs that may be running on the same
compute node you are on. The best way to time a real job is to test it
out on a completely isolated computer. If you are on an HPC system with
a batch queue, you can always request an entire compute node and then
just use part of the node you requested, even a single compute core. If
this is not possible, then try to get the job as isolated as you can.
Submitting a single-core request to a job queue is one example of this,
where you at least are sure that your job is the only one on the cores
that you requested. Your job will still be sharing the memory bus and L3
cache with other jobs. Jobs usually don’t effect each other much from
this, but they can. If your job is using the network to communicate with
other compute nodes, that might also be shared with other jobs running
on the same node. The single largest factor to be aware of is that other
jobs using the same file server as you are can definitely affect the
performance of your job if your code is doing lots of IO (Input and
Output). On HPC systems, this can be true even if the other jobs are not
on the same compute node as your job. If you want to isolate your job
from others in this case, you will need to do your IO to the local disk
(usually /tmp).</p>
</section><section><h2 class="section-heading" id="timing-internal-parts-of-a-program">Timing Internal Parts of a Program<a class="anchor" aria-label="anchor" href="#timing-internal-parts-of-a-program"></a>
</h2>
<hr class="half-width">
<p>Every computer language has multiple clock functions that can be used
to time sections of the code. The syntax is different in each language,
but they all work about the same, and there is always a very high
precision function that is accurate down to somewhere in the nanosecond
range, though I typically don’t trust these for measuring less than a
microsecond interval. Each of these clock functions returns the current
time, so to measure the time in an interval you need to store the start
time, do some calculations or IO, then get the end time and subtract the
two to get the time used for that part of the code.</p>
<p>In Python since version 3.3, the best timer is in the
<strong>time</strong> package. To use it, you must start by importing
the package. In C/C++ the <strong>clock_gettime()</strong> function
returns the current time accurate to less than a microsecond. Accuracy
of other timers like <strong>SYSTEM CLOCK()</strong> in Fortran 90 vary
with the system and compiler. Below are examples of using the clock
functions to measure the time it takes to do a loop, then measure the
time it takes to dump an array out to a file.</p>
<div class="tabs">
<nav><div id="nav-tab-1" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-1-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Python" type="button" role="tab" aria-controls="nav-tabpanel-1-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-1-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-R" type="button" role="tab" aria-controls="nav-tabpanel-1-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-C" type="button" role="tab" aria-controls="nav-tabpanel-1-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-1-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-1-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-1" class="tab-content">
<div id="nav-tabpanel-1-Python" class="tab-pane show active" role="tabpanel" aria-labelledby="nav-tab-1-Python">
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># timing_example.py - Example code showing how to put timing around an IO loop.</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">1000000</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>array <span class="op">=</span> [ <span class="bu">float</span>(i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N ) ]</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>t_start <span class="op">=</span> time.perf_counter()</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a><span class="bu">sum</span> <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N ):</span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>   <span class="bu">sum</span> <span class="op">+=</span> array[i]</span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a>t_loop <span class="op">=</span> time.perf_counter() <span class="op">-</span> t_start</span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The loop took "</span>, t_loop, <span class="st">" seconds"</span>)</span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a>t_start <span class="op">=</span> time.perf_counter()</span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a>fd <span class="op">=</span> <span class="bu">open</span>( <span class="st">"array.out"</span>, <span class="st">"w"</span>)</span>
<span id="cb7-20"><a href="#cb7-20" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N ):</span>
<span id="cb7-21"><a href="#cb7-21" tabindex="-1"></a>   fd.write( <span class="bu">str</span>(array[i]) <span class="op">+</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span> )</span>
<span id="cb7-22"><a href="#cb7-22" tabindex="-1"></a>fd.close()</span>
<span id="cb7-23"><a href="#cb7-23" tabindex="-1"></a></span>
<span id="cb7-24"><a href="#cb7-24" tabindex="-1"></a>t_output <span class="op">=</span> time.perf_counter() <span class="op">-</span> t_start</span>
<span id="cb7-25"><a href="#cb7-25" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The output took "</span>, t_output, <span class="st">" seconds"</span>)</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-1-R" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-1-R">
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># timing example code for R</span></span>
<span><span class="co"># USAGE:  Rscript timing_example.R</span></span>
<span></span>
<span></span>
<span>   <span class="co"># Allocate space for and initialize the array</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">1000000</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu">vector</span><span class="op">(</span> <span class="st">"double"</span>, <span class="va">n</span> <span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span><span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span> <span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>   <span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">as.double</span><span class="op">(</span><span class="va">i</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span></span>
<span>   <span class="co"># Time a simple summation loop first</span></span>
<span></span>
<span><span class="va">dummy</span> <span class="op">&lt;-</span> <span class="fu">matrix</span><span class="op">(</span> <span class="fl">1</span><span class="op">:</span><span class="fl">125000000</span> <span class="op">)</span>       <span class="co"># 1 GB of data to flush caches</span></span>
<span></span>
<span><span class="va">t_start</span> <span class="op">=</span> <span class="fu">proc.time</span><span class="op">(</span><span class="op">)</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span></span>
<span><span class="va">a_sum</span> <span class="op">&lt;-</span> <span class="fl">0.0</span></span>
<span><span class="kw">for</span><span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span> <span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>   <span class="va">a_sum</span> <span class="op">&lt;-</span> <span class="va">a_sum</span> <span class="op">+</span> <span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">t_end</span> <span class="op">=</span> <span class="fu">proc.time</span><span class="op">(</span><span class="op">)</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="fu">sprintf</span><span class="op">(</span><span class="st">"Summation with for loop took %6.3f seconds"</span>, <span class="va">t_end</span><span class="op">-</span><span class="va">t_start</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="fu">sprintf</span><span class="op">(</span><span class="st">"a_sum = %.6e for vector size %i"</span>, <span class="va">a_sum</span>, <span class="va">n</span> <span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span></span>
<span>   <span class="co"># Time the file write</span></span>
<span></span>
<span><span class="va">t_start</span> <span class="op">=</span> <span class="fu">proc.time</span><span class="op">(</span><span class="op">)</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span></span>
<span><span class="fu">writeLines</span><span class="op">(</span> <span class="fu">as.character</span><span class="op">(</span> <span class="va">x</span> <span class="op">)</span>, <span class="st">"timing_example.out"</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">t_end</span> <span class="op">=</span> <span class="fu">proc.time</span><span class="op">(</span><span class="op">)</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="fu">sprintf</span><span class="op">(</span><span class="st">"File write for vector size %i took %6.3f seconds"</span>, <span class="va">n</span>, <span class="va">t_end</span><span class="op">-</span><span class="va">t_start</span><span class="op">)</span><span class="op">)</span></span></code></pre>
</div>
</div>
<div id="nav-tabpanel-1-C" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-1-C">
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">C<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode c" tabindex="0"><code class="sourceCode c"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co">// timing_example.c - Example code showing how to put timing around an IO loop</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;stdlib.h&gt;</span></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;time.h&gt;</span></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;sys/time.h&gt;</span></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a><span class="dt">int</span> main <span class="op">(</span><span class="dt">int</span> argc<span class="op">,</span> <span class="dt">char</span> <span class="op">**</span>argv<span class="op">)</span></span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>   <span class="dt">int</span> i<span class="op">,</span> N<span class="op">;</span></span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>   <span class="dt">double</span> t_loop<span class="op">,</span> t_sum<span class="op">,</span> t_io<span class="op">,</span> a_sum<span class="op">,</span> <span class="op">*</span>array<span class="op">;</span></span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a>   <span class="kw">struct</span> timespec ts<span class="op">,</span> tf<span class="op">,</span> ts_sum<span class="op">,</span> tf_sum<span class="op">,</span> ts_io<span class="op">,</span> tf_io<span class="op">;</span></span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a>   <span class="dt">FILE</span> <span class="op">*</span>fd<span class="op">;</span></span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a></span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a>      <span class="co">// Allocate space for the array and initialize it</span></span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a>   N <span class="op">=</span> <span class="dv">1000000</span><span class="op">;</span></span>
<span id="cb9-18"><a href="#cb9-18" tabindex="-1"></a>   array <span class="op">=</span> malloc<span class="op">(</span> N <span class="op">*</span> <span class="kw">sizeof</span><span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">);</span></span>
<span id="cb9-19"><a href="#cb9-19" tabindex="-1"></a></span>
<span id="cb9-20"><a href="#cb9-20" tabindex="-1"></a>   <span class="cf">for</span><span class="op">(</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> N<span class="op">;</span> i<span class="op">++</span> <span class="op">)</span> <span class="op">{</span></span>
<span id="cb9-21"><a href="#cb9-21" tabindex="-1"></a>      array<span class="op">[</span>i<span class="op">]</span> <span class="op">=</span> <span class="op">(</span><span class="dt">double</span><span class="op">)</span> i<span class="op">;</span></span>
<span id="cb9-22"><a href="#cb9-22" tabindex="-1"></a>   <span class="op">}</span></span>
<span id="cb9-23"><a href="#cb9-23" tabindex="-1"></a></span>
<span id="cb9-24"><a href="#cb9-24" tabindex="-1"></a>      <span class="co">// Put timing around our loop</span></span>
<span id="cb9-25"><a href="#cb9-25" tabindex="-1"></a></span>
<span id="cb9-26"><a href="#cb9-26" tabindex="-1"></a>   clock_gettime<span class="op">(</span>CLOCK_REALTIME<span class="op">,</span> <span class="op">&amp;</span>ts<span class="op">);</span></span>
<span id="cb9-27"><a href="#cb9-27" tabindex="-1"></a></span>
<span id="cb9-28"><a href="#cb9-28" tabindex="-1"></a>   a_sum <span class="op">=</span> <span class="fl">0.0</span><span class="op">;</span></span>
<span id="cb9-29"><a href="#cb9-29" tabindex="-1"></a>   <span class="cf">for</span><span class="op">(</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> N<span class="op">;</span> i<span class="op">++</span> <span class="op">)</span> <span class="op">{</span></span>
<span id="cb9-30"><a href="#cb9-30" tabindex="-1"></a>      a_sum <span class="op">+=</span> array<span class="op">[</span>i<span class="op">];</span></span>
<span id="cb9-31"><a href="#cb9-31" tabindex="-1"></a>   <span class="op">}</span></span>
<span id="cb9-32"><a href="#cb9-32" tabindex="-1"></a></span>
<span id="cb9-33"><a href="#cb9-33" tabindex="-1"></a>   clock_gettime<span class="op">(</span>CLOCK_REALTIME<span class="op">,</span> <span class="op">&amp;</span>tf<span class="op">);</span></span>
<span id="cb9-34"><a href="#cb9-34" tabindex="-1"></a>   t_loop <span class="op">=</span>  <span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">(</span> tf<span class="op">.</span>tv_sec <span class="op">-</span> ts<span class="op">.</span>tv_sec <span class="op">);</span></span>
<span id="cb9-35"><a href="#cb9-35" tabindex="-1"></a>   t_loop <span class="op">+=</span> <span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">(</span>tf<span class="op">.</span>tv_nsec <span class="op">-</span> ts<span class="op">.</span>tv_nsec<span class="op">)</span> <span class="op">*</span> <span class="fl">1e-9</span><span class="op">;</span></span>
<span id="cb9-36"><a href="#cb9-36" tabindex="-1"></a></span>
<span id="cb9-37"><a href="#cb9-37" tabindex="-1"></a>   printf<span class="op">(</span> <span class="st">"The loop took </span><span class="sc">%lf</span><span class="st"> seconds</span><span class="sc">\n</span><span class="st">"</span><span class="op">,</span> t_loop <span class="op">);</span></span>
<span id="cb9-38"><a href="#cb9-38" tabindex="-1"></a></span>
<span id="cb9-39"><a href="#cb9-39" tabindex="-1"></a>      <span class="co">// Now time the file write</span></span>
<span id="cb9-40"><a href="#cb9-40" tabindex="-1"></a></span>
<span id="cb9-41"><a href="#cb9-41" tabindex="-1"></a>   clock_gettime<span class="op">(</span>CLOCK_REALTIME<span class="op">,</span> <span class="op">&amp;</span>ts_io<span class="op">);</span></span>
<span id="cb9-42"><a href="#cb9-42" tabindex="-1"></a></span>
<span id="cb9-43"><a href="#cb9-43" tabindex="-1"></a>   fd <span class="op">=</span> fopen<span class="op">(</span> <span class="st">"time_example.out"</span><span class="op">,</span> <span class="st">"w"</span> <span class="op">);</span></span>
<span id="cb9-44"><a href="#cb9-44" tabindex="-1"></a>   <span class="cf">for</span><span class="op">(</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> N<span class="op">;</span> i<span class="op">++</span> <span class="op">)</span> <span class="op">{</span></span>
<span id="cb9-45"><a href="#cb9-45" tabindex="-1"></a>      fprintf<span class="op">(</span> fd<span class="op">,</span> <span class="st">"</span><span class="sc">%lf\n</span><span class="st">"</span><span class="op">,</span> array<span class="op">[</span>i<span class="op">]</span> <span class="op">);</span></span>
<span id="cb9-46"><a href="#cb9-46" tabindex="-1"></a>   <span class="op">}</span></span>
<span id="cb9-47"><a href="#cb9-47" tabindex="-1"></a>   fclose<span class="op">(</span> fd <span class="op">);</span></span>
<span id="cb9-48"><a href="#cb9-48" tabindex="-1"></a></span>
<span id="cb9-49"><a href="#cb9-49" tabindex="-1"></a>   clock_gettime<span class="op">(</span>CLOCK_REALTIME<span class="op">,</span> <span class="op">&amp;</span>tf_io<span class="op">);</span></span>
<span id="cb9-50"><a href="#cb9-50" tabindex="-1"></a>   t_io <span class="op">=</span>  <span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">(</span> tf_io<span class="op">.</span>tv_sec <span class="op">-</span> ts_io<span class="op">.</span>tv_sec <span class="op">);</span></span>
<span id="cb9-51"><a href="#cb9-51" tabindex="-1"></a>   t_io <span class="op">+=</span> <span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">(</span>tf_io<span class="op">.</span>tv_nsec <span class="op">-</span> ts_io<span class="op">.</span>tv_nsec<span class="op">)</span> <span class="op">*</span> <span class="fl">1e-9</span><span class="op">;</span></span>
<span id="cb9-52"><a href="#cb9-52" tabindex="-1"></a></span>
<span id="cb9-53"><a href="#cb9-53" tabindex="-1"></a>   printf<span class="op">(</span> <span class="st">"The IO write took </span><span class="sc">%lf</span><span class="st"> seconds</span><span class="sc">\n</span><span class="st">"</span><span class="op">,</span> t_io <span class="op">);</span></span>
<span id="cb9-54"><a href="#cb9-54" tabindex="-1"></a><span class="op">}</span></span></code></pre>
</div>
</div>
<div id="nav-tabpanel-1-Fortran" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-1-Fortran">
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">FORTRAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode fortran" tabindex="0"><code class="sourceCode fortranfixed"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co">! timing_example.f90 - Example code showing how to put timing around an IO loop.</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="kw">PROGRAM</span> timing_example</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>   <span class="dt">INTEGER</span> <span class="dt">::</span> i, N, c_start, c_stop, c_rate, cs_start, cs_stop</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>   <span class="dt">INTEGER</span> <span class="dt">::</span> cio_start, cio_stop, fd</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>   <span class="dt">DOUBLE PRECISION</span> <span class="dt">::</span> t_sum, t_loop, a_sum, t_io</span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>   <span class="dt">DOUBLE PRECISION</span>, <span class="dt">ALLOCATABLE</span> <span class="dt">::</span> array(:)</span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>   <span class="dt">DOUBLE PRECISION</span>, <span class="dt">ALLOCATABLE</span> <span class="dt">::</span> dummy(:)</span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>      <span class="co">! Allocate space for the array and initialize it</span></span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>   N <span class="kw">=</span> <span class="dv">100000000</span>;</span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a>   <span class="kw">ALLOCATE</span>( array(N) )</span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a>   <span class="kw">DO</span> i <span class="kw">=</span> <span class="dv">1</span>, N</span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a>      array(i) <span class="kw">=</span> i</span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>   <span class="kw">END DO</span></span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a>      <span class="co">! Initialize a dummy array to clear cache</span></span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a></span>
<span id="cb10-23"><a href="#cb10-23" tabindex="-1"></a>   <span class="kw">ALLOCATE</span>( dummy(<span class="dv">125000000</span>) )</span>
<span id="cb10-24"><a href="#cb10-24" tabindex="-1"></a>   <span class="kw">DO</span> i <span class="kw">=</span> <span class="dv">1</span>, <span class="dv">125000000</span></span>
<span id="cb10-25"><a href="#cb10-25" tabindex="-1"></a>      dummy(i) <span class="kw">=</span> <span class="fl">0.0</span></span>
<span id="cb10-26"><a href="#cb10-26" tabindex="-1"></a>   <span class="kw">END DO</span></span>
<span id="cb10-27"><a href="#cb10-27" tabindex="-1"></a></span>
<span id="cb10-28"><a href="#cb10-28" tabindex="-1"></a>      <span class="co">! Put timing around our loop</span></span>
<span id="cb10-29"><a href="#cb10-29" tabindex="-1"></a></span>
<span id="cb10-30"><a href="#cb10-30" tabindex="-1"></a>   <span class="kw">CALL</span> <span class="fu">SYSTEM_CLOCK</span>( COUNT_RATE <span class="kw">=</span> c_rate )</span>
<span id="cb10-31"><a href="#cb10-31" tabindex="-1"></a>   <span class="kw">CALL</span> <span class="fu">SYSTEM_CLOCK</span>( <span class="fu">COUNT</span> <span class="kw">=</span> c_start )</span>
<span id="cb10-32"><a href="#cb10-32" tabindex="-1"></a></span>
<span id="cb10-33"><a href="#cb10-33" tabindex="-1"></a>   <span class="co">!t_sum = 0.0</span></span>
<span id="cb10-34"><a href="#cb10-34" tabindex="-1"></a>   a_sum <span class="kw">=</span> <span class="fl">0.0</span></span>
<span id="cb10-35"><a href="#cb10-35" tabindex="-1"></a>   <span class="kw">DO</span> i <span class="kw">=</span> <span class="dv">1</span>, N</span>
<span id="cb10-36"><a href="#cb10-36" tabindex="-1"></a>      <span class="co">!CALL SYSTEM_CLOCK( COUNT = cs_start )</span></span>
<span id="cb10-37"><a href="#cb10-37" tabindex="-1"></a>      a_sum <span class="kw">=</span> a_sum <span class="kw">+</span> array(i)</span>
<span id="cb10-38"><a href="#cb10-38" tabindex="-1"></a>      <span class="co">!CALL SYSTEM_CLOCK( COUNT = cs_stop )</span></span>
<span id="cb10-39"><a href="#cb10-39" tabindex="-1"></a>      <span class="co">!t_sum = t_sum + DBLE(cs_stop - cs_start) / c_rate</span></span>
<span id="cb10-40"><a href="#cb10-40" tabindex="-1"></a>   <span class="kw">END DO</span></span>
<span id="cb10-41"><a href="#cb10-41" tabindex="-1"></a></span>
<span id="cb10-42"><a href="#cb10-42" tabindex="-1"></a>   <span class="kw">CALL</span> <span class="fu">SYSTEM_CLOCK</span>( <span class="fu">COUNT</span> <span class="kw">=</span> c_stop )</span>
<span id="cb10-43"><a href="#cb10-43" tabindex="-1"></a>   t_loop <span class="kw">=</span> <span class="bu">DBLE</span>(c_stop <span class="kw">-</span> c_start) <span class="kw">/</span> c_rate</span>
<span id="cb10-44"><a href="#cb10-44" tabindex="-1"></a></span>
<span id="cb10-45"><a href="#cb10-45" tabindex="-1"></a>   <span class="fu">WRITE(*</span>,<span class="fu">*)</span> <span class="st">"a_sum = "</span>, a_sum</span>
<span id="cb10-46"><a href="#cb10-46" tabindex="-1"></a>   <span class="co">!WRITE(*,*) "The sum took ", t_sum, " seconds "</span></span>
<span id="cb10-47"><a href="#cb10-47" tabindex="-1"></a>   <span class="fu">WRITE(*</span>,<span class="fu">*)</span> <span class="st">"The loop took "</span>, t_loop, <span class="st">" seconds "</span></span>
<span id="cb10-48"><a href="#cb10-48" tabindex="-1"></a></span>
<span id="cb10-49"><a href="#cb10-49" tabindex="-1"></a>      <span class="co">! Now time the file write</span></span>
<span id="cb10-50"><a href="#cb10-50" tabindex="-1"></a></span>
<span id="cb10-51"><a href="#cb10-51" tabindex="-1"></a>   <span class="kw">CALL</span> <span class="fu">SYSTEM_CLOCK</span>( <span class="fu">COUNT</span> <span class="kw">=</span> cio_start, COUNT_RATE <span class="kw">=</span> c_rate )</span>
<span id="cb10-52"><a href="#cb10-52" tabindex="-1"></a></span>
<span id="cb10-53"><a href="#cb10-53" tabindex="-1"></a>   <span class="fu">open(</span> fd, <span class="fu">file</span> <span class="kw">=</span> <span class="st">"timing_example.out"</span> <span class="fu">)</span></span>
<span id="cb10-54"><a href="#cb10-54" tabindex="-1"></a>   <span class="kw">DO</span> i <span class="kw">=</span> <span class="dv">1</span>, N</span>
<span id="cb10-55"><a href="#cb10-55" tabindex="-1"></a>      <span class="fu">write(</span> fd, <span class="fu">*)</span> array(i)</span>
<span id="cb10-56"><a href="#cb10-56" tabindex="-1"></a>   <span class="kw">END DO</span></span>
<span id="cb10-57"><a href="#cb10-57" tabindex="-1"></a></span>
<span id="cb10-58"><a href="#cb10-58" tabindex="-1"></a>   <span class="fu">close(</span> fd <span class="fu">)</span></span>
<span id="cb10-59"><a href="#cb10-59" tabindex="-1"></a></span>
<span id="cb10-60"><a href="#cb10-60" tabindex="-1"></a>   <span class="kw">CALL</span> <span class="fu">SYSTEM_CLOCK</span>( <span class="fu">COUNT</span> <span class="kw">=</span> cio_stop )</span>
<span id="cb10-61"><a href="#cb10-61" tabindex="-1"></a>   t_io <span class="kw">=</span> <span class="bu">DBLE</span>(cio_stop <span class="kw">-</span> cio_start) <span class="kw">/</span> c_rate</span>
<span id="cb10-62"><a href="#cb10-62" tabindex="-1"></a></span>
<span id="cb10-63"><a href="#cb10-63" tabindex="-1"></a>   <span class="fu">WRITE(*</span>,<span class="fu">*)</span> <span class="st">"The IO write  took = "</span>, t_io, <span class="st">" seconds "</span></span></code></pre>
</div>
</div>
<div id="nav-tabpanel-1-Matlab" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-1-Matlab">
<p>Not implemented yet.</p>
</div>
</div>
</div>
<p>Try running the <strong>timing_example</strong> code yourself for the
language you are working with. These are codes you should have
downloaded and unzipped in your HPC system, and should be in the
<strong>code</strong> directory. Timing will be dependent on the
language, but the values I see are in the millisecond range. Since both
of these are above the nanosecond range, we can be confident that the
timing routine is accurately measuring each.</p>
<p>Let’s see what we can learn by playing around with it some more. When
I run the python version preceded by the Linux <strong>time</strong>
function, I see a real time significantly larger than the loop time and
output time combined. The initialization time is not measured but
shouldn’t be more than the loop time. What all this means is that there
is some startup time for getting the python program running and
importing the <strong>time</strong> package, but we may also be seeing
the lack of accuracy of the external <strong>time</strong> function when
it comes to measuring things down in the millisecond range. We do not
see the same time discrepancy when running the C version.</p>
<p>Now lets change the program itself. Sometimes we need to time a part
of something that is in a larger loop, so we need to sum the times
together. Try changing the timing so that it is inside the summation
loop instead of outside it to see what happens. You can do this by
uncommenting the timing and printing functions in the code file.</p>
<div class="tabs">
<nav><div id="nav-tab-2" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-2-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Python" type="button" role="tab" aria-controls="nav-tabpanel-2-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-2-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-R" type="button" role="tab" aria-controls="nav-tabpanel-2-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-C" type="button" role="tab" aria-controls="nav-tabpanel-2-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-2-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-2-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-2" class="tab-content">
<div id="nav-tabpanel-2-Python" class="tab-pane show active" role="tabpanel" aria-labelledby="nav-tab-2-Python">
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>array <span class="op">=</span> [ <span class="bu">float</span>(i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N ) ]</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>t_start <span class="op">=</span> time.perf_counter()</span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a><span class="bu">sum</span> <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>t_sum <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N ):</span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a>   t0 <span class="op">=</span> time.perf_counter()</span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a>   <span class="bu">sum</span> <span class="op">+=</span> array[i]</span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a>   t_sum <span class="op">+=</span> time.perf_counter() <span class="op">-</span> t0</span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a>t_loop <span class="op">=</span> time.perf_counter() <span class="op">-</span> t_start</span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The sum took "</span>, t_sum, <span class="st">" seconds"</span>)</span>
<span id="cb11-18"><a href="#cb11-18" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The loop took "</span>, t_loop, <span class="st">" seconds"</span>)</span>
<span id="cb11-19"><a href="#cb11-19" tabindex="-1"></a></span>
<span id="cb11-20"><a href="#cb11-20" tabindex="-1"></a>t_start <span class="op">=</span> time.perf_counter()</span>
<span id="cb11-21"><a href="#cb11-21" tabindex="-1"></a></span>
<span id="cb11-22"><a href="#cb11-22" tabindex="-1"></a>fd <span class="op">=</span> <span class="bu">open</span>( <span class="st">"array.out"</span>, <span class="st">"w"</span>)</span>
<span id="cb11-23"><a href="#cb11-23" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N ):</span>
<span id="cb11-24"><a href="#cb11-24" tabindex="-1"></a>   fd.write( <span class="bu">str</span>(array[i]) <span class="op">+</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span> )</span>
<span id="cb11-25"><a href="#cb11-25" tabindex="-1"></a>fd.close()</span>
<span id="cb11-26"><a href="#cb11-26" tabindex="-1"></a></span>
<span id="cb11-27"><a href="#cb11-27" tabindex="-1"></a>t_output <span class="op">=</span> time.perf_counter() <span class="op">-</span> t_start</span>
<span id="cb11-28"><a href="#cb11-28" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The output took "</span>, t_output, <span class="st">" seconds"</span>)</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-2-R" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-2-R">
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># timing example code with internal loop timings for R</span></span>
<span><span class="co">#   This shows how to do this, but demonstrates that it can be very intrusive</span></span>
<span><span class="co"># USAGE:  Rscript timing_example2.R</span></span>
<span></span>
<span></span>
<span>   <span class="co"># Allocate space for and initialize the array</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">1000000</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu">vector</span><span class="op">(</span> <span class="st">"double"</span>, <span class="va">n</span> <span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span><span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span> <span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>   <span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">as.double</span><span class="op">(</span><span class="va">i</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span></span>
<span>   <span class="co"># Time a simple summation loop with internal timing as well</span></span>
<span></span>
<span><span class="va">dummy</span> <span class="op">&lt;-</span> <span class="fu">matrix</span><span class="op">(</span> <span class="fl">1</span><span class="op">:</span><span class="fl">125000000</span> <span class="op">)</span>       <span class="co"># 1 GB of data to flush caches</span></span>
<span></span>
<span><span class="va">t_sum</span> <span class="op">&lt;-</span> <span class="fl">0.0</span></span>
<span><span class="va">t_start</span> <span class="op">=</span> <span class="fu">proc.time</span><span class="op">(</span><span class="op">)</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span></span>
<span><span class="va">a_sum</span> <span class="op">&lt;-</span> <span class="fl">0.0</span></span>
<span><span class="kw">for</span><span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span> <span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>   <span class="va">t_0</span> <span class="op">=</span> <span class="fu">proc.time</span><span class="op">(</span><span class="op">)</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span>   <span class="va">a_sum</span> <span class="op">&lt;-</span> <span class="va">a_sum</span> <span class="op">+</span> <span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span>   <span class="va">t_sum</span> <span class="op">=</span> <span class="va">t_sum</span> <span class="op">+</span> <span class="op">(</span> <span class="fu">proc.time</span><span class="op">(</span><span class="op">)</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span> <span class="op">-</span> <span class="va">t_0</span> <span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">t_end</span> <span class="op">=</span> <span class="fu">proc.time</span><span class="op">(</span><span class="op">)</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="fu">sprintf</span><span class="op">(</span><span class="st">"Internal sums took %6.3f seconds"</span>, <span class="va">t_sum</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="fu">sprintf</span><span class="op">(</span><span class="st">"For loop with internal timing too took %6.3f seconds"</span>, <span class="va">t_end</span><span class="op">-</span><span class="va">t_start</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="fu">sprintf</span><span class="op">(</span><span class="st">"a_sum = %.6e for vector size %i"</span>, <span class="va">a_sum</span>, <span class="va">n</span> <span class="op">)</span> <span class="op">)</span></span></code></pre>
</div>
</div>
<div id="nav-tabpanel-2-C" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-2-C">
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">C<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode c" tabindex="0"><code class="sourceCode c"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="co">// timing_example.c - Example code showing how to put timing around an IO loop.</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;stdlib.h&gt;</span></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;time.h&gt;</span></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;sys/time.h&gt;</span></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a><span class="dt">int</span> main <span class="op">(</span><span class="dt">int</span> argc<span class="op">,</span> <span class="dt">char</span> <span class="op">**</span>argv<span class="op">)</span></span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a>   <span class="dt">int</span> i<span class="op">,</span> N<span class="op">;</span></span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a>   <span class="dt">double</span> t_loop<span class="op">,</span> t_sum<span class="op">,</span> t_io<span class="op">,</span> a_sum<span class="op">,</span> <span class="op">*</span>array<span class="op">;</span></span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a>   <span class="kw">struct</span> timespec ts<span class="op">,</span> tf<span class="op">,</span> ts_sum<span class="op">,</span> tf_sum<span class="op">,</span> ts_io<span class="op">,</span> tf_io<span class="op">;</span></span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a>   <span class="dt">FILE</span> <span class="op">*</span>fd<span class="op">;</span></span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a>      <span class="co">// Allocate space for the array and initialize it</span></span>
<span id="cb13-16"><a href="#cb13-16" tabindex="-1"></a></span>
<span id="cb13-17"><a href="#cb13-17" tabindex="-1"></a>   N <span class="op">=</span> <span class="dv">1000000</span><span class="op">;</span></span>
<span id="cb13-18"><a href="#cb13-18" tabindex="-1"></a>   array <span class="op">=</span> malloc<span class="op">(</span> N <span class="op">*</span> <span class="kw">sizeof</span><span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">);</span></span>
<span id="cb13-19"><a href="#cb13-19" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" tabindex="-1"></a>   <span class="cf">for</span><span class="op">(</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> N<span class="op">;</span> i<span class="op">++</span> <span class="op">)</span> <span class="op">{</span></span>
<span id="cb13-21"><a href="#cb13-21" tabindex="-1"></a>      array<span class="op">[</span>i<span class="op">]</span> <span class="op">=</span> <span class="op">(</span><span class="dt">double</span><span class="op">)</span> i<span class="op">;</span></span>
<span id="cb13-22"><a href="#cb13-22" tabindex="-1"></a>   <span class="op">}</span></span>
<span id="cb13-23"><a href="#cb13-23" tabindex="-1"></a></span>
<span id="cb13-24"><a href="#cb13-24" tabindex="-1"></a>      <span class="co">// Put timing around our loop</span></span>
<span id="cb13-25"><a href="#cb13-25" tabindex="-1"></a></span>
<span id="cb13-26"><a href="#cb13-26" tabindex="-1"></a>   clock_gettime<span class="op">(</span>CLOCK_REALTIME<span class="op">,</span> <span class="op">&amp;</span>ts<span class="op">);</span></span>
<span id="cb13-27"><a href="#cb13-27" tabindex="-1"></a></span>
<span id="cb13-28"><a href="#cb13-28" tabindex="-1"></a>   a_sum <span class="op">=</span> <span class="fl">0.0</span><span class="op">;</span></span>
<span id="cb13-29"><a href="#cb13-29" tabindex="-1"></a>   t_sum <span class="op">=</span> <span class="fl">0.0</span><span class="op">;</span></span>
<span id="cb13-30"><a href="#cb13-30" tabindex="-1"></a>   <span class="cf">for</span><span class="op">(</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> N<span class="op">;</span> i<span class="op">++</span> <span class="op">)</span> <span class="op">{</span></span>
<span id="cb13-31"><a href="#cb13-31" tabindex="-1"></a>      clock_gettime<span class="op">(</span>CLOCK_REALTIME<span class="op">,</span> <span class="op">&amp;</span>ts_sum<span class="op">);</span></span>
<span id="cb13-32"><a href="#cb13-32" tabindex="-1"></a>      a_sum <span class="op">+=</span> array<span class="op">[</span>i<span class="op">];</span></span>
<span id="cb13-33"><a href="#cb13-33" tabindex="-1"></a>      clock_gettime<span class="op">(</span>CLOCK_REALTIME<span class="op">,</span> <span class="op">&amp;</span>tf_sum<span class="op">);</span></span>
<span id="cb13-34"><a href="#cb13-34" tabindex="-1"></a>      t_sum <span class="op">=</span>  <span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">(</span> tf_sum<span class="op">.</span>tv_sec <span class="op">-</span> ts_sum<span class="op">.</span>tv_sec <span class="op">);</span></span>
<span id="cb13-35"><a href="#cb13-35" tabindex="-1"></a>      t_sum <span class="op">+=</span> <span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">(</span>tf_sum<span class="op">.</span>tv_nsec <span class="op">-</span> ts_sum<span class="op">.</span>tv_nsec<span class="op">)</span> <span class="op">*</span> <span class="fl">1e-9</span><span class="op">;</span></span>
<span id="cb13-36"><a href="#cb13-36" tabindex="-1"></a>   <span class="op">}</span></span>
<span id="cb13-37"><a href="#cb13-37" tabindex="-1"></a></span>
<span id="cb13-38"><a href="#cb13-38" tabindex="-1"></a>   clock_gettime<span class="op">(</span>CLOCK_REALTIME<span class="op">,</span> <span class="op">&amp;</span>tf<span class="op">);</span></span>
<span id="cb13-39"><a href="#cb13-39" tabindex="-1"></a>   t_loop <span class="op">=</span>  <span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">(</span> tf<span class="op">.</span>tv_sec <span class="op">-</span> ts<span class="op">.</span>tv_sec <span class="op">);</span></span>
<span id="cb13-40"><a href="#cb13-40" tabindex="-1"></a>   t_loop <span class="op">+=</span> <span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">(</span>tf<span class="op">.</span>tv_nsec <span class="op">-</span> ts<span class="op">.</span>tv_nsec<span class="op">)</span> <span class="op">*</span> <span class="fl">1e-9</span><span class="op">;</span></span>
<span id="cb13-41"><a href="#cb13-41" tabindex="-1"></a></span>
<span id="cb13-42"><a href="#cb13-42" tabindex="-1"></a>   printf<span class="op">(</span> <span class="st">"The sum took </span><span class="sc">%lf</span><span class="st"> seconds</span><span class="sc">\n</span><span class="st">"</span><span class="op">,</span> t_sum <span class="op">);</span></span>
<span id="cb13-43"><a href="#cb13-43" tabindex="-1"></a>   printf<span class="op">(</span> <span class="st">"The loop took </span><span class="sc">%lf</span><span class="st"> seconds</span><span class="sc">\n</span><span class="st">"</span><span class="op">,</span> t_loop <span class="op">);</span></span>
<span id="cb13-44"><a href="#cb13-44" tabindex="-1"></a></span>
<span id="cb13-45"><a href="#cb13-45" tabindex="-1"></a>      <span class="co">// Now time the file write</span></span>
<span id="cb13-46"><a href="#cb13-46" tabindex="-1"></a></span>
<span id="cb13-47"><a href="#cb13-47" tabindex="-1"></a>   clock_gettime<span class="op">(</span>CLOCK_REALTIME<span class="op">,</span> <span class="op">&amp;</span>ts_io<span class="op">);</span></span>
<span id="cb13-48"><a href="#cb13-48" tabindex="-1"></a></span>
<span id="cb13-49"><a href="#cb13-49" tabindex="-1"></a>   fd <span class="op">=</span> fopen<span class="op">(</span> <span class="st">"time_example.out"</span><span class="op">,</span> <span class="st">"w"</span> <span class="op">);</span></span>
<span id="cb13-50"><a href="#cb13-50" tabindex="-1"></a>   <span class="cf">for</span><span class="op">(</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> N<span class="op">;</span> i<span class="op">++</span> <span class="op">)</span> <span class="op">{</span></span>
<span id="cb13-51"><a href="#cb13-51" tabindex="-1"></a>      fprintf<span class="op">(</span> fd<span class="op">,</span> <span class="st">"</span><span class="sc">%lf\n</span><span class="st">"</span><span class="op">,</span> array<span class="op">[</span>i<span class="op">]</span> <span class="op">);</span></span>
<span id="cb13-52"><a href="#cb13-52" tabindex="-1"></a>   <span class="op">}</span></span>
<span id="cb13-53"><a href="#cb13-53" tabindex="-1"></a>   fclose<span class="op">(</span> fd <span class="op">);</span></span>
<span id="cb13-54"><a href="#cb13-54" tabindex="-1"></a></span>
<span id="cb13-55"><a href="#cb13-55" tabindex="-1"></a>   clock_gettime<span class="op">(</span>CLOCK_REALTIME<span class="op">,</span> <span class="op">&amp;</span>tf_io<span class="op">);</span></span>
<span id="cb13-56"><a href="#cb13-56" tabindex="-1"></a>   t_io <span class="op">=</span>  <span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">(</span> tf_io<span class="op">.</span>tv_sec <span class="op">-</span> ts_io<span class="op">.</span>tv_sec <span class="op">);</span></span>
<span id="cb13-57"><a href="#cb13-57" tabindex="-1"></a>   t_io <span class="op">+=</span> <span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">(</span>tf_io<span class="op">.</span>tv_nsec <span class="op">-</span> ts_io<span class="op">.</span>tv_nsec<span class="op">)</span> <span class="op">*</span> <span class="fl">1e-9</span><span class="op">;</span></span>
<span id="cb13-58"><a href="#cb13-58" tabindex="-1"></a></span>
<span id="cb13-59"><a href="#cb13-59" tabindex="-1"></a>   printf<span class="op">(</span> <span class="st">"The IO write took </span><span class="sc">%lf</span><span class="st"> seconds</span><span class="sc">\n</span><span class="st">"</span><span class="op">,</span> t_io <span class="op">);</span></span>
<span id="cb13-60"><a href="#cb13-60" tabindex="-1"></a><span class="op">}</span></span></code></pre>
</div>
</div>
<div id="nav-tabpanel-2-Fortran" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-2-Fortran">
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">FORTRAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode fortran" tabindex="0"><code class="sourceCode fortranfixed"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="co">! timing_example.f90 - Example code showing how to put timing around an IO loop.</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a><span class="kw">PROGRAM</span> timing_example</span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>   <span class="dt">INTEGER</span> <span class="dt">::</span> i, N, c_start, c_stop, c_rate, cs_start, cs_stop</span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a>   <span class="dt">INTEGER</span> <span class="dt">::</span> cio_start, cio_stop, fd</span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a>   <span class="dt">DOUBLE PRECISION</span> <span class="dt">::</span> t_sum, t_loop, a_sum, t_io</span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a>   <span class="dt">DOUBLE PRECISION</span>, <span class="dt">ALLOCATABLE</span> <span class="dt">::</span> array(:)</span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a>      <span class="co">! Allocate space for the array and initialize it</span></span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a>   N <span class="kw">=</span> <span class="dv">100000000</span>;</span>
<span id="cb14-13"><a href="#cb14-13" tabindex="-1"></a>   <span class="kw">ALLOCATE</span>( array(N) )</span>
<span id="cb14-14"><a href="#cb14-14" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" tabindex="-1"></a>   <span class="kw">DO</span> i <span class="kw">=</span> <span class="dv">1</span>, N</span>
<span id="cb14-16"><a href="#cb14-16" tabindex="-1"></a>      array(i) <span class="kw">=</span> i</span>
<span id="cb14-17"><a href="#cb14-17" tabindex="-1"></a>   <span class="kw">END DO</span></span>
<span id="cb14-18"><a href="#cb14-18" tabindex="-1"></a></span>
<span id="cb14-19"><a href="#cb14-19" tabindex="-1"></a>      <span class="co">! Put timing around our loop</span></span>
<span id="cb14-20"><a href="#cb14-20" tabindex="-1"></a></span>
<span id="cb14-21"><a href="#cb14-21" tabindex="-1"></a>   <span class="kw">CALL</span> <span class="fu">SYSTEM_CLOCK</span>( COUNT_RATE <span class="kw">=</span> c_rate )</span>
<span id="cb14-22"><a href="#cb14-22" tabindex="-1"></a>   <span class="kw">CALL</span> <span class="fu">SYSTEM_CLOCK</span>( <span class="fu">COUNT</span> <span class="kw">=</span> c_start )</span>
<span id="cb14-23"><a href="#cb14-23" tabindex="-1"></a></span>
<span id="cb14-24"><a href="#cb14-24" tabindex="-1"></a>   t_sum <span class="kw">=</span> <span class="fl">0.0</span></span>
<span id="cb14-25"><a href="#cb14-25" tabindex="-1"></a>   a_sum <span class="kw">=</span> <span class="fl">0.0</span></span>
<span id="cb14-26"><a href="#cb14-26" tabindex="-1"></a>   <span class="kw">DO</span> i <span class="kw">=</span> <span class="dv">1</span>, N</span>
<span id="cb14-27"><a href="#cb14-27" tabindex="-1"></a>      <span class="kw">CALL</span> <span class="fu">SYSTEM_CLOCK</span>( <span class="fu">COUNT</span> <span class="kw">=</span> cs_start )</span>
<span id="cb14-28"><a href="#cb14-28" tabindex="-1"></a>      a_sum <span class="kw">=</span> a_sum <span class="kw">+</span> array(i)</span>
<span id="cb14-29"><a href="#cb14-29" tabindex="-1"></a>      <span class="kw">CALL</span> <span class="fu">SYSTEM_CLOCK</span>( <span class="fu">COUNT</span> <span class="kw">=</span> cs_stop )</span>
<span id="cb14-30"><a href="#cb14-30" tabindex="-1"></a>      t_sum <span class="kw">=</span> t_sum <span class="kw">+</span> <span class="bu">DBLE</span>(cs_stop <span class="kw">-</span> cs_start) <span class="kw">/</span> c_rate</span>
<span id="cb14-31"><a href="#cb14-31" tabindex="-1"></a>   <span class="kw">END DO</span></span>
<span id="cb14-32"><a href="#cb14-32" tabindex="-1"></a></span>
<span id="cb14-33"><a href="#cb14-33" tabindex="-1"></a>   <span class="kw">CALL</span> <span class="fu">SYSTEM_CLOCK</span>( <span class="fu">COUNT</span> <span class="kw">=</span> c_stop )</span>
<span id="cb14-34"><a href="#cb14-34" tabindex="-1"></a>   t_loop <span class="kw">=</span> <span class="bu">DBLE</span>(c_stop <span class="kw">-</span> c_start) <span class="kw">/</span> c_rate</span>
<span id="cb14-35"><a href="#cb14-35" tabindex="-1"></a></span>
<span id="cb14-36"><a href="#cb14-36" tabindex="-1"></a>   <span class="fu">WRITE(*</span>,<span class="fu">*)</span> <span class="st">"a_sum = "</span>, a_sum</span>
<span id="cb14-37"><a href="#cb14-37" tabindex="-1"></a>   <span class="fu">WRITE(*</span>,<span class="fu">*)</span> <span class="st">"The sum took "</span>, t_sum, <span class="st">" seconds "</span></span>
<span id="cb14-38"><a href="#cb14-38" tabindex="-1"></a>   <span class="fu">WRITE(*</span>,<span class="fu">*)</span> <span class="st">"The loop took "</span>, t_loop, <span class="st">" seconds "</span></span>
<span id="cb14-39"><a href="#cb14-39" tabindex="-1"></a></span>
<span id="cb14-40"><a href="#cb14-40" tabindex="-1"></a>      <span class="co">! Now time the file write</span></span>
<span id="cb14-41"><a href="#cb14-41" tabindex="-1"></a></span>
<span id="cb14-42"><a href="#cb14-42" tabindex="-1"></a>   <span class="kw">CALL</span> <span class="fu">SYSTEM_CLOCK</span>( <span class="fu">COUNT</span> <span class="kw">=</span> cio_start, COUNT_RATE <span class="kw">=</span> c_rate )</span>
<span id="cb14-43"><a href="#cb14-43" tabindex="-1"></a></span>
<span id="cb14-44"><a href="#cb14-44" tabindex="-1"></a>   <span class="fu">open(</span> fd, <span class="fu">file</span> <span class="kw">=</span> <span class="st">"timing_example.out"</span> <span class="fu">)</span></span>
<span id="cb14-45"><a href="#cb14-45" tabindex="-1"></a>   <span class="kw">DO</span> i <span class="kw">=</span> <span class="dv">1</span>, N</span>
<span id="cb14-46"><a href="#cb14-46" tabindex="-1"></a>      <span class="fu">write(</span> fd, <span class="fu">*)</span> array(i)</span>
<span id="cb14-47"><a href="#cb14-47" tabindex="-1"></a>   <span class="kw">END DO</span></span>
<span id="cb14-48"><a href="#cb14-48" tabindex="-1"></a></span>
<span id="cb14-49"><a href="#cb14-49" tabindex="-1"></a>   <span class="fu">close(</span> fd <span class="fu">)</span></span>
<span id="cb14-50"><a href="#cb14-50" tabindex="-1"></a></span>
<span id="cb14-51"><a href="#cb14-51" tabindex="-1"></a>   <span class="kw">CALL</span> <span class="fu">SYSTEM_CLOCK</span>( <span class="fu">COUNT</span> <span class="kw">=</span> cio_stop )</span>
<span id="cb14-52"><a href="#cb14-52" tabindex="-1"></a>   t_io <span class="kw">=</span> <span class="bu">DBLE</span>(cio_stop <span class="kw">-</span> cio_start) <span class="kw">/</span> c_rate</span>
<span id="cb14-53"><a href="#cb14-53" tabindex="-1"></a></span>
<span id="cb14-54"><a href="#cb14-54" tabindex="-1"></a>   <span class="fu">WRITE(*</span>,<span class="fu">*)</span> <span class="st">"The IO write  took = "</span>, t_io, <span class="st">" seconds "</span></span>
<span id="cb14-55"><a href="#cb14-55" tabindex="-1"></a></span>
<span id="cb14-56"><a href="#cb14-56" tabindex="-1"></a><span class="kw">END PROGRAM</span> timing_example</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-2-Matlab" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-2-Matlab">
<p>Not implemented yet.</p>
</div>
</div>
</div>
<p>In my computer, the <strong>t_sum</strong> time is only a bit larger
than the <strong>t_loop</strong> time from before, but remember that
this doesn’t count the loop overhead. If we look at the
<strong>t_loop</strong> time instead, in my computer it is more than
double what it was before. When the clock routine is measuring very
small intervals each time, it can be intrusive in that it distorts the
measurement by increasing the run time of the entire code. It isn’t
surprising that this is intrusive since we are measuring the time it
takes to retrieve a single array element and do one addition. The code
is doing a subtraction and addition itself to calculate the time
interval, so it is probably more surprising that doing the timing in
this way is not more intrusive.</p>
</section><section><h2 class="section-heading" id="what-to-time">What to Time<a class="anchor" aria-label="anchor" href="#what-to-time"></a>
</h2>
<hr class="half-width">
<p>The goal is to fully profile your code so that you understand where
all the time is being spent. This means timing each computational
section where time is being spent, usually the loops for example. While
simple print statements may not be important contributors to the overall
run time of a code, any large input or output from files may be. When we
start talking about parallel programs that use multiple cores or even
multiple compute nodes it will become important to measure the time
taken in communicating data to other cores and other nodes. Once you
have a complete profile of where time is being spent, then you can
understand where to start in trying to optimize your program to make it
run faster.</p>
</section><section><h2 class="section-heading" id="measuring-parallel-job-scaling">Measuring Parallel Job Scaling<a class="anchor" aria-label="anchor" href="#measuring-parallel-job-scaling"></a>
</h2>
<hr class="half-width">
<p>When we get to talking about multi-processor jobs it will be very
important to understand how efficiently a job scales as we use more
processing cores. For this we will do what is called a scaling study
where we measure the performance of a typical job using different number
of processing cores. We may for example run on 1 core, then 4, 8, 16,
and 32 cores to see how efficiently the job scales as we apply more
processing power. This is done so that we can understand how many cores
we can efficiently apply to that job. If we get a 7 times speedup on 8
cores compared to 1, that less than ideal but still very good. If we
then see a 9 times speedup using 16 cores, then we’d probably want to
stick with using just 8 cores on that particular job. Do keep in mind
that scaling is very dependent on the problem size. Larger problems will
typically scale better to more cores, while smaller problems may be
limited to only a few cores. The goal is to determine how many cores we
can use with reasonable efficiency. The same kind of scaling study can
also be used for multi-node jobs, where we would test the performance on
1 node, 2, 4, and 8 nodes for example.</p>
<p>Problem size is one factor that can affect the scaling efficiency.
For multi-node jobs, choosing the fastest networking options, and
ensuring that all compute nodes are on the same network switch can both
increase the scaling efficiency.</p>
</section><section><h2 class="section-heading" id="tracking-memory-usage">Tracking Memory Usage<a class="anchor" aria-label="anchor" href="#tracking-memory-usage"></a>
</h2>
<hr class="half-width">
<p>When we think about high performance, we mostly think about running
jobs faster. For some programs, the memory usage may be the factor
limiting what types of science we can do. At the very least, we need to
know what memory to request when submitting jobs to a batch
scheduler.</p>
<p>For simple jobs, like the matrix multiplication code in the next
section, we can calculate the exact memory requirements. If we are going
to multiply two matrices of size NxN and put the results in a third,
then each matrix takes NxN x 8 Bytes if the elements are 64-bit floats,
so the total memory required would be 3 x NxN * 8 Bytes.</p>
<p>For more complicated programs, often the best approach is to do a
short test run to measure the memory use before submitting the full job.
This is especially true if you are submitting lots of similar jobs. If
your job goes over the requested memory, it is most often killed, so you
want to over estimate the request somewhat, but if you request too much
it can take a lot longer to get your job scheduled and result in
inefficient use of the resources as you will be locking up memory that
you are not using.</p>
<p>Measuring the memory usage is more difficult than it should be on
most systems, and it depends on what tools you have available. If you
are on an HPC system with a batch scheduler like Slurm, you can use the
<strong>sstat</strong> command to find the current memory usage for a
running job and <strong>seff</strong> to find the maximum memory used
for a completed job, using the job ID number in both cases to choose the
job you are interested in.</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="ex">seff</span> 5072064</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Job ID: 5072064
Cluster: beocat
User/Group: daveturner/daveturner_users
State: FAILED (exit code 16)
Cores: 1
CPU Utilized: 00:01:07
CPU Efficiency: 97.10% of 00:01:09 core-walltime
Job Wall-clock time: 00:01:09
Memory Utilized: 2.26 GB
Memory Efficiency: 11.31% of 20.00 GB</code></pre>
</div>
<p>The matrix multiplication job above used 10,000x10,000 matrices and
took 1 minute 9 seconds. We see that in this case it used 2.26 GB of
memory. One thing to keep in mind is that 1 GB can be calculated in
different ways. In this case, 1 kB is 1024 Bytes, 1 MB is 1024 x 1024
Bytes, and 1 GB is 1024 x 1024 x 1024 Bytes. So 3 matrices are 3 x NxN x
8 / (1024x1024x1024) GB = 2.235 GB, rounded up to 2.26 GB. In general,
if you estimate 1 GB as 10^9 Bytes that works fine.</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="ex">sstat</span> <span class="at">--format</span><span class="op">=</span>MaxRSS 5072069</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>MaxRSS
----------
  2289.50M</code></pre>
</div>
<p>For a running job you can use the <strong>sstat</strong> command with
the job ID number. The <strong>sstat</strong> command will dump a lot of
information out, so using the <strong>–format=MaxRSS</strong> parameter
provides just the real memory that we want. In this case, it is again
2.29 GB.</p>
<p>Different HPC systems may have batch queue systems other than Slurm,
but all will have similar methods of getting the memory usage for
running and completed jobs. If you are not running a job through a batch
system, you can use the <strong>htop</strong> command to find your
process and look at the <strong>Res</strong> or resident memory. This
works best for single-core jobs as multi-core jobs may show memory usage
for each thread.</p>
<p><strong>Ganglia</strong> is another option providing a web-based
interface to look at memory usage over time. If you have access to
Ganglia on your HPC system, it provides a node view only rather than a
job view, so it is only really useful if your job is the only one
running on a given compute node. However, being able to see the memory
use over time can be very helpful.</p>
<p>We will practice these approaches more in the upcoming modules.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>The <strong>time</strong> function can always be used externally to
measure performance but has limited accuracy of around 1
millisecond.</li>
<li>Internally there are precise clock routines that can be used to
measure the performance of each part of a code. These are different for
each programming language, but the use is always the same.</li>
<li>Scaling studies can help determine how many cores or nodes we can
efficiently use for a parallel job of a given problem size.</li>
<li>Measuring memory use can be done from outside a program, but you may
also be able to calculate total memory for simple programs.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-performance-concepts"><p>Content from <a href="performance-concepts.html">Performance Concepts</a></p>
<hr>
<p>Last updated on 2025-10-07 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/performance-concepts.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 40 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What does performance mean in programming?</li>
<li>How do I take advantage of optimized libraries?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand that what actually goes on in the computer may be much
more complex than what the user tells the computer to do.</li>
<li>Have a basic understanding of some of the performance issues to be
aware of.</li>
<li>Learn that you don’t have to be an expert programmer to take
advantage of advanced performance techniques, you just need to be aware
of how to use libraries optimized by experts.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="conceptual-view">Conceptual View<a class="anchor" aria-label="anchor" href="#conceptual-view"></a>
</h2>
<hr class="half-width">
<p>When we write a program for a computer, we view the operation from a
more conceptual level. The picture below is for a simple dot product
between two vectors <strong>X</strong> and <strong>Y</strong>, where the
dot product <strong>D<sub>prod</sub></strong> is the sum of the elements
of each vector multiplied together. Notice first that the indexing for
arrays in Python starts at 0 and goes to N-1. This varies between
languages, with C/C++ also starting at 0, while R, Matlab, and Fortran
start arrays at 1 and go to N.</p>
<p>When we think of a computer running a program to do this calculation,
we view it as starting with the variable
<strong>D<sub>prod</sub></strong> being pulled from main memory into the
processor where this sum is zeroed out. We then pull the first element
of <strong>X</strong> and the first element of <strong>Y</strong> into
the registers and multiply them together then summing them into
<strong>D<sub>prod</sub></strong>. We loop through all elements of the
vectors, each time pulling the <strong>X</strong> and <strong>Y</strong>
element into memory, multiplying them together and summing them into
<strong>D<sub>prod</sub></strong>. Then at the end, we push
<strong>D<sub>prod</sub></strong> back down into main memory where the
program prints the result out to the screen.</p>
<div class="tabs">
<nav><div id="nav-tab-1" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-1-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Python" type="button" role="tab" aria-controls="nav-tabpanel-1-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-1-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-R" type="button" role="tab" aria-controls="nav-tabpanel-1-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-C" type="button" role="tab" aria-controls="nav-tabpanel-1-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-1-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-1-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-1" class="tab-content">
<div id="nav-tabpanel-1-Python" class="tab-pane show active" role="tabpanel" aria-labelledby="nav-tab-1-Python">
<figure><img src="../fig/dot_prod_fig.jpg" alt="Dot product formula" class="figure mx-auto d-block"><div class="figcaption">Dot product between vectors X and Y</div>
</figure>
</div>
<div id="nav-tabpanel-1-R" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-1-R">
<figure><img src="../fig/dot_prod_fig-1-N.jpg" alt="Dot product formula" class="figure mx-auto d-block"><div class="figcaption">Dot product between vectors X and Y</div>
</figure>
</div>
<div id="nav-tabpanel-1-C" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-1-C">
<figure><img src="../fig/dot_prod_fig.jpg" alt="Dot product formula" class="figure mx-auto d-block"><div class="figcaption">Dot product between vectors X and Y</div>
</figure>
</div>
<div id="nav-tabpanel-1-Fortran" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-1-Fortran">
<figure><img src="../fig/dot_prod_fig-1-N.jpg" alt="Dot product formula" class="figure mx-auto d-block"><div class="figcaption">Dot product between vectors X and Y</div>
</figure>
</div>
<div id="nav-tabpanel-1-Matlab" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-1-Matlab">
<figure><img src="../fig/dot_prod_fig-1-N.jpg" alt="Dot product formula" class="figure mx-auto d-block"><div class="figcaption">Dot product between vectors X and Y</div>
</figure>
</div>
</div>
</div>
<p>This conceptual view of what the computer is doing is all we really
need to be aware of when we are starting to writing programs. But when
those programs start taking too long to run on a personal computer then
we need to understand what the computer is doing in more depth so we can
make sure that the code is running optimally. Computers are internally
quite complex, so fully understanding how code can be written in
different ways to streamline the processing can be very challenging.
Fortunately, not everyone needs to be able to write optimal low-level
code. For most of us, we just need to understand what programming
techniques in each language may cause performance problems, and
understand how to take advantage of optimization libraries that experts
have written for us.</p>
</section><section><h2 class="section-heading" id="the-computers-view">The Computer’s View<a class="anchor" aria-label="anchor" href="#the-computers-view"></a>
</h2>
<hr class="half-width">
<p>Let’s walk through the same dot product example again, but this time
looking at it from the point of view of the computer rather than our
conceptual view. The first thing to understand is that when you pull a
variable up from main memory into the registers in a processor, what
goes on behind the scene is very complicated, but fortunately for us
also totally automated. Variables don’t get pulled up individually but
as part of a 64-byte cache line. The variables in this cache line get
promoted through several layers of increasingly fast memory known as
cache layers, with a copy of the entire cache line being left behind in
each layer. In this way, the most frequently used data will be more
likely to be in one of the cache layers where it can be accessed more
quickly. In the case of our dot product, that means loading the first
element of <strong>X</strong> and its 64-byte cache line may take 10-33
ns while the next 7 only take 0.3-1 ns since those elements are now in
L1 cache too.</p>
<figure><img src="../fig/Memory_Hierarchy.jpg" alt="Diagram of the memory hierarchy in a typical computer" class="figure mx-auto d-block"><div class="figcaption">Memory Hierarchy in a Computer</div>
</figure><p>How does this knowledge help us? Performance is more about getting
data to the processor since most operations are very fast once the data
is in the processor registers. If the vector is instead not stored in
contiguous memory, with each variable in the next memory location, then
the subsequent 7 memory loads of <strong>X</strong> and
<strong>Y</strong> will take 20-33 ns each instead of 0.3-1 ns each.
This means that we need to ensure that variables we are using are in
contiguous memory whenever possible. There will be an exercise at the
end of this section where you will measure the difference in execution
time between these two cases.</p>
<p>Now let’s look at a simple matrix multiplication algorithm which is
fairly simple to program, but may have very different performance
depending on how you write the code.</p>
<div class="tabs">
<nav><div id="nav-tab-2" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-2-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Python" type="button" role="tab" aria-controls="nav-tabpanel-2-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-2-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-R" type="button" role="tab" aria-controls="nav-tabpanel-2-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-C" type="button" role="tab" aria-controls="nav-tabpanel-2-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-2-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-2-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-2" class="tab-content">
<div id="nav-tabpanel-2-Python" class="tab-pane show active" role="tabpanel" aria-labelledby="nav-tab-2-Python">
<figure><img src="../fig/matmult_fig.jpg" alt="Formula and diagram of a matrix multiply" class="figure mx-auto d-block"><div class="figcaption">Matrix multiplication C = A * B</div>
</figure>
</div>
<div id="nav-tabpanel-2-R" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-2-R">
<figure><img src="../fig/matmult_fig-1-N.jpg" alt="Formula and diagram of a matrix multiply" class="figure mx-auto d-block"><div class="figcaption">Matrix multiplication C = A * B</div>
</figure>
</div>
<div id="nav-tabpanel-2-C" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-2-C">
<figure><img src="../fig/matmult_fig.jpg" alt="Formula and diagram of a matrix multiply" class="figure mx-auto d-block"><div class="figcaption">Matrix multiplication C = A * B</div>
</figure>
</div>
<div id="nav-tabpanel-2-Fortran" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-2-Fortran">
<figure><img src="../fig/matmult_fig-1-N.jpg" alt="Formula and diagram of a matrix multiply" class="figure mx-auto d-block"><div class="figcaption">Matrix multiplication C = A * B</div>
</figure>
</div>
<div id="nav-tabpanel-2-Matlab" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-2-Matlab">
<figure><img src="../fig/matmult_fig-1-N.jpg" alt="Formula and diagram of a matrix multiply" class="figure mx-auto d-block"><div class="figcaption">Matrix multiplication C = A * B</div>
</figure>
</div>
</div>
</div>
<p>Once the matrices are initialized, the code to multiply them together
is fairly simple.</p>
<div class="tabs">
<nav><div id="nav-tab-3" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-3-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-Python" type="button" role="tab" aria-controls="nav-tabpanel-3-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-3-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-R" type="button" role="tab" aria-controls="nav-tabpanel-3-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-C" type="button" role="tab" aria-controls="nav-tabpanel-3-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-3-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-3-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-3" class="tab-content">
<div id="nav-tabpanel-3-Python" class="tab-pane show active" role="tabpanel" aria-labelledby="nav-tab-3-Python">
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># Complete code is in code/matmult.py</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N ):</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>( N ):</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>        C[i][j] <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N ):</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>            C[i][j] <span class="op">+=</span> A[i][k] <span class="op">*</span> B[k][j]</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-3-R" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-3-R">
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Complete code is in code/matmult_loops.R</span></span>
<span></span>
<span><span class="kw">for</span><span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span> <span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>   <span class="kw">for</span><span class="op">(</span> <span class="va">j</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span> <span class="op">)</span></span>
<span>   <span class="op">{</span></span>
<span>      <span class="kw">for</span><span class="op">(</span> <span class="va">k</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span> <span class="op">)</span></span>
<span>      <span class="op">{</span></span>
<span>         <span class="va">c</span><span class="op">[</span><span class="va">i</span>,<span class="va">j</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">c</span><span class="op">[</span><span class="va">i</span>,<span class="va">j</span><span class="op">]</span> <span class="op">+</span> <span class="va">a</span><span class="op">[</span><span class="va">i</span>,<span class="va">k</span><span class="op">]</span> <span class="op">*</span> <span class="va">b</span><span class="op">[</span><span class="va">k</span>,<span class="va">j</span><span class="op">]</span></span>
<span>      <span class="op">}</span></span>
<span>   <span class="op">}</span></span>
<span><span class="op">}</span></span></code></pre>
</div>
</div>
<div id="nav-tabpanel-3-C" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-3-C">
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">C<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode c" tabindex="0"><code class="sourceCode c"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co">// Complete code is in code/matmult.c</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>   N <span class="op">=</span> <span class="dv">1000</span><span class="op">;</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>   <span class="cf">for</span><span class="op">(</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> N<span class="op">;</span> i<span class="op">++</span> <span class="op">)</span> <span class="op">{</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>      <span class="cf">for</span><span class="op">(</span> j <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> j <span class="op">&lt;</span> N<span class="op">;</span> j<span class="op">++</span> <span class="op">)</span> <span class="op">{</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>         C<span class="op">[</span>i<span class="op">][</span>j<span class="op">]</span> <span class="op">=</span> <span class="fl">0.0</span><span class="op">;</span></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>         <span class="cf">for</span><span class="op">(</span> k <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> k <span class="op">&lt;</span> N<span class="op">;</span> k<span class="op">++</span> <span class="op">)</span> <span class="op">{</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>            C<span class="op">[</span>i<span class="op">][</span>j<span class="op">]</span> <span class="op">+=</span> A<span class="op">[</span>i<span class="op">][</span>k<span class="op">]</span> <span class="op">*</span> B<span class="op">[</span>k<span class="op">][</span>j<span class="op">];</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>         <span class="op">}</span></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>      <span class="op">}</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a>   <span class="op">}</span></span></code></pre>
</div>
</div>
<div id="nav-tabpanel-3-Fortran" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-3-Fortran">
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">FORTRAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode fortran" tabindex="0"><code class="sourceCode fortranfixed"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co">! Complete code is in code/matmult.f90</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>   N <span class="kw">=</span> <span class="dv">1000</span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>   <span class="kw">DO</span> i <span class="kw">=</span> <span class="dv">1</span>, N</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>      <span class="kw">DO</span> j <span class="kw">=</span> <span class="dv">1</span>, N</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>         C(i,j) <span class="kw">=</span> <span class="fl">0.0</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>         <span class="kw">DO</span> k <span class="kw">=</span> <span class="dv">1</span>, N</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>            C( i, j ) <span class="kw">=</span> C( i, j ) <span class="kw">+</span> A( i, k ) <span class="kw">*</span> B( k, j )</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>         <span class="kw">END DO</span></span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>      <span class="kw">END DO</span></span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>   <span class="kw">END DO</span></span></code></pre>
</div>
</div>
<div id="nav-tabpanel-3-Matlab" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-3-Matlab">
<p>Not implemented yet.</p>
</div>
</div>
</div>
<p>But if we are concerned about performance, we need to take a better
look at this code. Python is a row-major language like C/C++, which
means matrices like this are stored by rows first as in the picture
above. If we look at this code from a cache-line point of view, then it
looks optimal for the B matrix since when we load an element the others
in the cache line will get used in the next loop iterations, but the A
matrix is the opposite where elements being used next are farther
apart.</p>
<p>But it turns out this isn’t really the way to look at performance in
this case. For each element of C that we calculate, we will need N
elements of A and N elements of B. So every element of A and every
element of B will get re-used N times during this calculation. What is
important is that when we pull each element into the L1 cache where it
is the fastest to access, we want to re-use it as much as possible
rather than having to pull it repeatedly from the lower caches or main
memory.</p>
<p>An optimal approach has been developed in the past that pulls blocks
of each matrix into L1 cache. This block optimization results in a much
more complicated code, but also a much higher performing one. The good
news is that for users like us, we don’t have to ever program it
ourselves, we just need to know that it is in optimized libraries that
we can call at any time. Below are some examples of how to access the
low-level optimized libraries in the various languages.</p>
<div class="tabs">
<nav><div id="nav-tab-4" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-4-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-4-Python" type="button" role="tab" aria-controls="nav-tabpanel-4-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-4-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-4-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-4-R" type="button" role="tab" aria-controls="nav-tabpanel-4-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-4-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-4-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-4-C" type="button" role="tab" aria-controls="nav-tabpanel-4-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-4-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-4-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-4-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-4-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-4-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-4-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-4-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-4-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-4-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-4" class="tab-content">
<div id="nav-tabpanel-4-Python" class="tab-pane show active" role="tabpanel" aria-labelledby="nav-tab-4-Python">
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># Complete code is in code/matmult_numpy.py</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>C <span class="op">=</span> np.matmult( A, B )</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-4-R" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-4-R">
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Complete code is in matmult_builtin.R</span></span>
<span></span>
<span>   <span class="va">c</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">%*%</span> <span class="va">b</span></span></code></pre>
</div>
</div>
<div id="nav-tabpanel-4-C" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-4-C">
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">C<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode c" tabindex="0"><code class="sourceCode c"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co">// Complete code is in code/matmult_cblas.c</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;cblas.h&gt;</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>   N <span class="op">=</span> <span class="dv">1000</span><span class="op">;</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>   cblas_dgemm<span class="op">(</span> CblasRowMajor<span class="op">,</span> CblasNoTrans<span class="op">,</span> CblasNoTrans<span class="op">,</span></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>                N<span class="op">,</span> N<span class="op">,</span> N<span class="op">,</span> <span class="fl">1.0</span><span class="op">,</span> <span class="op">*</span>A<span class="op">,</span> N<span class="op">,</span> <span class="op">*</span>B<span class="op">,</span> N<span class="op">,</span> <span class="fl">1.0</span><span class="op">,</span> <span class="op">*</span>C<span class="op">,</span> N <span class="op">);</span></span></code></pre>
</div>
</div>
<div id="nav-tabpanel-4-Fortran" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-4-Fortran">
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">FORTRAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode fortran" tabindex="0"><code class="sourceCode fortranfixed"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co">! Complete code is in code/matmult_blas.f90</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="co">! gfortran -O3 -lblas -o matmult_blas matmult_blas.f90</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>   N <span class="kw">=</span> <span class="dv">1000</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>   <span class="kw">CALL</span> DGEMM( <span class="st">'N'</span>, <span class="st">'N'</span>, N, N, N, <span class="fl">1.0</span>, A, N, B, N, <span class="fl">0.0</span>, C, N )</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-4-Matlab" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-4-Matlab">
<p>Not implemented yet.</p>
</div>
</div>
</div>
<p>So while writing a matrix multiplication code from scratch is not
difficult, using the optimized function accessible from each language is
easier and guarantees the best performance. To find out how much
difference there is in performance, you will need to try for yourself by
measuring the execution time for a few different matrix sizes in the
exercise below.</p>
<div id="measuring-cache-line-effects" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="measuring-cache-line-effects" class="callout-inner">
<h3 class="callout-title">Measuring Cache Line Effects</h3>
<div class="callout-content">
<div class="tabs">
<nav><div id="nav-tab-5" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-5-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-5-Python" type="button" role="tab" aria-controls="nav-tabpanel-5-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-5-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-5-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-5-R" type="button" role="tab" aria-controls="nav-tabpanel-5-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-5-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-5-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-5-C" type="button" role="tab" aria-controls="nav-tabpanel-5-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-5-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-5-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-5-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-5-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-5-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-5-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-5-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-5-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-5-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-5" class="tab-content">
<div id="nav-tabpanel-5-Python" class="tab-pane show active" role="tabpanel" aria-labelledby="nav-tab-5-Python">
<p>Run the dot_product.py code several times to get an average execution
time for a dot product between two vectors of 1 million elements each.
Try to run them on an isolated system if possible, or through a batch
queue that at least ensures the code is being run on an isolated
processing core. Then run the dot_product_sparse.py code in the same
manner for comparison. How much faster is the first code where the
vectors are stored in contiguous memory? How much faster should it
be?</p>
</div>
<div id="nav-tabpanel-5-R" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-5-R">
<p>Run the dot_product.R code several times to get an average execution
time for a dot product between two vectors of 10 million elements each.
Try to run them on an isolated system if possible, or through a batch
queue that at least ensures the code is being run on an isolated
processing core. Then run the dot_product_sparse.R code in the same
manner for comparison. How much faster is the first code where the
vectors are stored in contiguous memory? How much faster should it
be?</p>
</div>
<div id="nav-tabpanel-5-C" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-5-C">
<p>Compile and run the dot_product_c.c code several times to get an
average execution time for a dot product between two vectors of 1
million elements each. Try to run them on an isolated system if
possible, or through a batch queue that at least ensures the code is
being run on an isolated processing core. Then compile and run the
dot_product_sparse.c code in the same manner for comparison. How much
faster is the first code where the vectors are stored in contiguous
memory? How much faster should it be?</p>
</div>
<div id="nav-tabpanel-5-Fortran" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-5-Fortran">
<p>Compile and run the dot_product_fortran.f90 code several times to get
an average execution time for a dot product between two vectors of 1
million elements each. Try to run them on an isolated system if
possible, or through a batch queue that at least ensures the code is
being run on an isolated processing core. Then compile and run the
dot_product_fortran_sparse.f90 code in the same manner for comparison.
How much faster is the first code where the vectors are stored in
contiguous memory? How much faster should it be?</p>
</div>
<div id="nav-tabpanel-5-Matlab" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-5-Matlab">
<p>Not implemented yet.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<div class="tabs">
<nav><div id="nav-tab-6" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-6-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-6-Python" type="button" role="tab" aria-controls="nav-tabpanel-6-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-6-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-6-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-6-R" type="button" role="tab" aria-controls="nav-tabpanel-6-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-6-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-6-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-6-C" type="button" role="tab" aria-controls="nav-tabpanel-6-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-6-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-6-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-6-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-6-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-6-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-6-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-6-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-6-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-6-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-6" class="tab-content">
<div id="nav-tabpanel-6-Python" class="tab-pane show active" role="tabpanel" aria-labelledby="nav-tab-6-Python">
<p>Is the time difference what we expected? When I ran this on a new
Intel processor that did not have any other jobs running, I measured 180
milliseconds for the contiguous memory case and 1230 milliseconds for
the sparse case, resulting in a 6.9 times speedup by keeping the vector
in contiguous memory. I also saw different results for other programming
languages. Since a cache line is 64 Bytes and each element is 8 bytes,
when the first element is loaded the next 7 are brought into L1 cache
essentially for free since they are in contiguous memory. Therefore we
expect it to take ~33 ns to load 8 elements of X, then ~33 ns to load 8
elements of Y, then only a few ns to get each element into the registers
and do the computations. For the sparse vectors, it should take 8 times
as long since each load will take ~33 ns. If you didn’t see an 8-times
speedup, don’t worry. The cache system is actually even more complicated
than this picture. The main thing to learn here is that if you take
advantage of the cache line by keeping the vectors in contiguous memory,
your code will run much faster.</p>
</div>
<div id="nav-tabpanel-6-R" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-6-R">
<p>Is the time difference what we expected? When I ran this on a new
Intel processor that did not have any other jobs running, I measured 51
milliseconds for the contiguous memory case and 217 milliseconds for the
sparse case, resulting in a 4.25 times speedup by keeping the vector in
contiguous memory. I also saw different results for other programming
languages. Since a cache line is 64 Bytes and each element is 8 bytes,
when the first element is loaded the next 7 are brought into L1 cache
essentially for free since they are in contiguous memory. Therefore we
expect it to take ~33 ns to load 8 elements of X, then ~33 ns to load 8
elements of Y, then only a few ns to get each element into the registers
and do the computations. For the sparse vectors, it should take 8 times
as long since each load will take ~33 ns. If you didn’t see an 8-times
speedup, don’t worry. The cache system is actually even more complicated
than this picture. The main thing to learn here is that if you take
advantage of the cache line by keeping the vectors in contiguous memory,
your code will run much faster.</p>
</div>
<div id="nav-tabpanel-6-C" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-6-C">
<p>Is the time difference what we expected? When I ran this on a new
processor that did not have any other jobs running, I measured ~16
milliseconds for the contiguous memory case and ~160 milliseconds for
the sparse case, resulting in a 10 times speedup by keeping the vector
in contiguous memory. I also saw different results for other programming
languages. Since a cache line is 64 Bytes and each element is 8 bytes,
when the first element is loaded the next 7 are brought into L1 cache
essentially for free since they are in contiguous memory. Therefore we
expect it to take ~33 ns to load 8 elements of X, then ~33 ns to load 8
elements of Y, then only a few ns to get each element into the registers
and do the computations. For the sparse vectors, it should take 8 times
as long since each load will take ~33 ns. If you didn’t see an 8 times
speedup exactly, don’t worry. The cache system is actually even more
complicated than this picture. The main thing to learn here is that if
you take advantage of the cache line by keeping the vectors in
contiguous memory, your code will run much faster.</p>
</div>
<div id="nav-tabpanel-6-Fortran" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-6-Fortran">
<p>Is the time difference what we expected? When I ran this on a new
processor that did not have any other jobs running, I measured ~20
milliseconds for the contiguous memory case and ~300 milliseconds for
the sparse case, resulting in a 15 times speedup by keeping the vector
in contiguous memory. I also saw different results for other programming
languages. Since a cache line is 64 Bytes and each element is 8 bytes,
when the first element is loaded the next 7 are brought into L1 cache
essentially for free since they are in contiguous memory. Therefore we
expect it to take ~33 ns to load 8 elements of X, then ~33 ns to load 8
elements of Y, then only a few ns to get each element into the registers
and do the computations. For the sparse vectors, it should take 8 times
as long since each load will take ~33 ns. If you didn’t see an 8 times
speedup exactly, don’t worry. The cache system is actually even more
complicated than this picture. The main thing to learn here is that if
you take advantage of the cache line by keeping the vectors in
contiguous memory, your code will run much faster.</p>
</div>
<div id="nav-tabpanel-6-Matlab" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-6-Matlab">
<p>Not implemented yet.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="time-different-matrix-multiplication-methods" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="time-different-matrix-multiplication-methods" class="callout-inner">
<h3 class="callout-title">Time Different Matrix Multiplication
Methods</h3>
<div class="callout-content">
<div class="tabs">
<nav><div id="nav-tab-7" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-7-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-7-Python" type="button" role="tab" aria-controls="nav-tabpanel-7-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-7-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-7-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-7-R" type="button" role="tab" aria-controls="nav-tabpanel-7-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-7-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-7-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-7-C" type="button" role="tab" aria-controls="nav-tabpanel-7-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-7-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-7-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-7-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-7-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-7-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-7-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-7-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-7-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-7-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-7" class="tab-content">
<div id="nav-tabpanel-7-Python" class="tab-pane show active" role="tabpanel" aria-labelledby="nav-tab-7-Python">
<p>There are 2 separate codes supplied to perform the same matrix
multiplication for a given matrix size, matmult.py is raw Python code
and matmult_numpy.py uses the highly optimized
<strong>np.matmult()</strong> function. Both programs take the matrix
size as an argument, so you run using <strong>python matmult.py
100</strong> for example to measure the performance for multiplying two
100x100 matrices. Measure the performance for each method on a small
10x10 matrix, an intermediate sized 100x100 matrix, and a large
1000x1000 matrix to see how each is affected by the optimized
<strong>numpy</strong> function. You should run this through a batch
scheduler if at all possible since numpy will grab any cores it can, and
for a fair comparison we want to test out only the single-core
performance.</p>
</div>
<div id="nav-tabpanel-7-R" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-7-R">
<p>There are 2 separate codes supplied to perform the same matrix
multiplication for a given matrix size, matmult_loops.R is raw R code
and matmult_builtin.R uses the built in **%*%<strong> operator. Both
programs take the matrix size as an argument, so you run using
</strong>Rscript matmult_loops.R 100** for example to measure the
performance for multiplying two 100x100 matrices. Measure the
performance for each method on a small 10x10 matrix, an intermediate
sized 100x100 matrix, and a large 1000x1000 matrix to see how each
performs. You should run this through a batch scheduler if at all
possible since numpy will grab any cores it can, and for a fair
comparison we want to test out only the single-core performance.</p>
</div>
<div id="nav-tabpanel-7-C" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-7-C">
<p>Compile and run the <strong>matmult.c</strong> and
<strong>matmult_cblas.c</strong> programs to compare the times for raw C
and the heavily optimized BLAS library <strong>dgemm()</strong>
function. Since these use statically allocated matrices you may need to
increase the stack size using ‘ulimit -s unlimited’. You may also need
to use a different compile line than in the code as your BLAS library
may be different on each system.</p>
</div>
<div id="nav-tabpanel-7-Fortran" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-7-Fortran">
<p>Compile and run the <strong>matmult.f90</strong> and
<strong>matmult_blas.f90</strong> programs to compare the times for raw
Fortran and the heavily optimized BLAS library <strong>DGEMM()</strong>
function. Since these use statically allocated matrices you may need to
increase the stack size using ‘ulimit -s unlimited’. You may also need
to use a different compile line than in the code as your BLAS library
may be different on each system.</p>
</div>
<div id="nav-tabpanel-7-Matlab" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-7-Matlab">
<p>Not implemented yet.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<div class="tabs">
<nav><div id="nav-tab-8" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-8-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-8-Python" type="button" role="tab" aria-controls="nav-tabpanel-8-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-8-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-8-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-8-R" type="button" role="tab" aria-controls="nav-tabpanel-8-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-8-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-8-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-8-C" type="button" role="tab" aria-controls="nav-tabpanel-8-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-8-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-8-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-8-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-8-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-8-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-8-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-8-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-8-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-8-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-8" class="tab-content">
<div id="nav-tabpanel-8-Python" class="tab-pane show active" role="tabpanel" aria-labelledby="nav-tab-8-Python">
<p>For the 10x10 matrix size there are 3 matrices having 100 elements
each needing 8 bytes storage, so storing all 3 matrices requires only
2.4 kB of memory. Everything fits entirely in L1 cache, so the block
optimized algorithm from <strong>numpy</strong> isn’t really needed. For
the 100x100 matrix size, 240 kB is needed to store all 3 matrices so
they will fit entirely in L2 cache, but not L1 cache. We therefore
expect a significant improvement by using the optimized
<strong>np.matmult()</strong> function. For the 1000x1000 matrix size,
we need 24 MB to store all 3 matrices so it will reside in L3 cache. The
<strong>np.matmult()</strong> function should speed up this run by
substantially more. The optimization of the <strong>numpy</strong>
routine however goes far beyond just block optimizing the algorithm so
that it reuses data in L1 cache though. There are also computational
optimizations that allow for many multiply-add operations to occur in
the same clock cycle, which is called vectorization.</p>
<p>My measurements on a modern Intel processor show more of a
performance benefit for larger matrix sizes. For 1000x1000 matrices, the
raw Python code was very slow at 6.5 MFlops (Million floating-point
operations per second). All the optimizations in the
<strong>numpy</strong> code brought the performance up to 15.4 GFlops,
or a whopping 2354 times faster. Raw Python code is fairly slow in
itself because it is interpreted and not compiled like C/C++/Fortran
code, clearly you can do very well if you learn to use the heavily
optimized library routines. C is still faster than Python, with raw C
code reaching 1.6 GFlops and the optimized CBLAS DGEMM routine reaching
91 GFlops.</p>
</div>
<div id="nav-tabpanel-8-R" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-8-R">
<p>For the 10x10 matrix size there are 3 matrices having 100 elements
each needing 8 bytes storage, so storing all 3 matrices requires only
2.4 kB of memory. Everything fits entirely in L1 cache, so a block
optimized algorithm from an optimized matrix multiply isn’t really
needed. For the 100x100 matrix size, 240 kB is needed to store all 3
matrices so they will fit entirely in L2 cache, but not L1 cache. We
therefore expect a significant improvement by using an optimized matrix
multiply function. For the 1000x1000 matrix size, we need 24 MB to store
all 3 matrices so it will reside in L3 cache. An optimized matrix
multiply function should speed up this run by substantially more. An
optimized matrix multiply routine however can go far beyond just block
optimizing the algorithm so that it reuses data in L1 cache though.
There are also computational optimizations that allow for many
multiply-add operations to occur in the same clock cycle, which is
called vectorization.</p>
<p>My measurements on a modern Intel processor show some very
interesting results. Using simple <strong>for</strong> loops I get 4 ms
for a 10x10 matrix, 154 ms for a 100x100 matrix, and a much larger 148
seconds for a 1000x1000 matrix. The built in matrix multiplication is
expected to be more optimized and I get 13 ms for a 10x10 matrix, 1 ms
for a 100x100 matrix, and 26 ms for the 1000x1000 matrix. The built in
matrix multiplication is clearly better except for the very small 10x10
matrix which seems to be an aberration. The 1000x1000 matrix is where it
shines taking only 26 ms where the <strong>for</strong> loop takes 148
seconds or nearly 5700 times as long. It isn’t clear why the difference
is this large, but clearly the built in matrix multiply is managing
cache much better.</p>
</div>
<div id="nav-tabpanel-8-C" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-8-C">
<p>For the 10x10 matrix size there are 3 matrices having 100 elements
each needing 8 bytes storage, so storing all 3 matrices requires only
2.4 kB of memory. Everything fits entirely in L1 cache, so a block
optimized algorithm from an optimized matrix multiply isn’t really
needed. For the 100x100 matrix size, 240 kB is needed to store all 3
matrices so they will fit entirely in L2 cache, but not L1 cache. We
therefore expect a significant improvement by using an optimized matrix
multiply function. For the 1000x1000 matrix size, we need 24 MB to store
all 3 matrices so it will reside in L3 cache. An optimized matrix
multiply function should speed up this run by substantially more. An
optimized matrix multiply routine however can go far beyond just block
optimizing the algorithm so that it reuses data in L1 cache though.
There are also computational optimizations that allow for many
multiply-add operations to occur in the same clock cycle, which is
called vectorization.</p>
<p>For a 1000x1000 matrix I got 1.2 seconds for the raw C code when
compiling with -O3 optimization. The <strong>cblas_dgemm()</strong>
function took only 0.015 seconds so it was 80 times faster. Even though
compiled C/C++ code is very fast, the <strong>DGEMM</strong> routine is
hand-optimized for each processor.</p>
</div>
<div id="nav-tabpanel-8-Fortran" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-8-Fortran">
<p>For the 10x10 matrix size there are 3 matrices having 100 elements
each needing 8 bytes storage, so storing all 3 matrices requires only
2.4 kB of memory. Everything fits entirely in L1 cache, so a block
optimized algorithm from an optimized matrix multiply isn’t really
needed. For the 100x100 matrix size, 240 kB is needed to store all 3
matrices so they will fit entirely in L2 cache, but not L1 cache. We
therefore expect a significant improvement by using an optimized matrix
multiply function. For the 1000x1000 matrix size, we need 24 MB to store
all 3 matrices so it will reside in L3 cache. An optimized matrix
multiply function should speed up this run by substantially more. An
optimized matrix multiply routine however can go far beyond just block
optimizing the algorithm so that it reuses data in L1 cache though.
There are also computational optimizations that allow for many
multiply-add operations to occur in the same clock cycle, which is
called vectorization.</p>
<p>For a 1000x1000 matrix I got 1.2 seconds for the raw Fortran code
when compiling with -O3 optimization. The <strong>DGEMM()</strong>
function took only 0.015 seconds so it was 80 times faster. Even though
compiled C/C++/Fortran code is very fast, the <strong>DGEMM</strong>
routine is hand-optimized for each processor.</p>
</div>
<div id="nav-tabpanel-8-Matlab" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-8-Matlab">
<p>Not implemented yet.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="advanced-exercise---transpose-b-to-cache-line-optimize-it" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="advanced-exercise---transpose-b-to-cache-line-optimize-it" class="callout-inner">
<h3 class="callout-title">Advanced Exercise - Transpose B to cache-line
optimize it</h3>
<div class="callout-content">
<p>As k is incremented in the innermost loop, elements of A are being
brought into cache efficiently since they are stored in contiguous
memory, as we learned from the dot product example. Unfortunately,
elements of B are not since they will be sparse, separated by N-1
elements each time. While in most languages we already know that we can
simply use the optimized library routine speedup the code, if this
wasn’t available one thing we’d consider is to transpose the B matrix so
that it is stored in column-major format before doing the matrix
multiplication. If you’re up for a challenge, try programming this up to
see if it improves the performance compared to the original code.</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Show me the solution </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" data-bs-parent="#accordionSolution3" aria-labelledby="headingSolution3">
<div class="accordion-body">
<p>There are a great many levels of optimization that can be done to the
matrix multiplication algorithm. Transposing B should improve the
performance some. For a more complete overview of what is done in the
<strong>np.matmult()</strong> algorithm and others like it, follow the
link: <a href="https://en.algorithmica.org/hpc/algorithms/matmul/" class="external-link uri">https://en.algorithmica.org/hpc/algorithms/matmul/</a></p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="summary">Summary<a class="anchor" aria-label="anchor" href="#summary"></a>
</h2>
<hr class="half-width">
<p>When it starts taking longer to run a given program, we need to start
looking beyond just whether it gives the correct answer and begin
considering performance. This means we need to go beyond the conceptual
view of how the program runs to look at how it makes use of the
underlying hardware architecture. While this can get very complicated
very quickly, most users just need to be aware of where performance
bottlenecks can occur in order to avoid them. Quite often, writing
optimal code just means taking advantage of highly optimized libraries
that experts have written and tuned. So most of us just need to know
when and where to look for these optimized routines in order to write
highly optimized code.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>A computer’s view of code is more complex than a user’s view.</li>
<li>It’s important to understand a little about what goes on when code
actually runs, but you don’t need to be able to program at that
level.</li>
<li>Whenever possible, use code written and optimized by experts instead
of writing your own version.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-parallel-concepts"><p>Content from <a href="parallel-concepts.html">Parallel Computing Concepts</a></p>
<hr>
<p>Last updated on 2025-09-12 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/parallel-concepts.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 40 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>Now that we can profile programs to find where the time is being
spent, how do we speed the code up?</li>
<li>What is parallel computing, and what are the underlying concepts
that make it work?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Learn different approaches to speeding up code.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>In the last chapter we learned how to profile a program to understand
where the time is being spent. In this section, we will talk more about
how to improve the performance of different parts of a program. This may
involve steering clear of inefficient methods in some computer
languages, minimizing the operation count, using optimized libraries,
and applying multiple cores or even multiple compute nodes to speed up
each computational part. Computations can sometimes be sped up
enormously using accelerators like GPUs (Graphic Processing Units) as
well. Reducing or eliminating IO can sometimes help, but ensuring that
the IO is done without costly locks, and to a file server that is not
overly used, can often help performance greatly as well.</p>
<section><h2 class="section-heading" id="optimizing-scalar-code">Optimizing Scalar Code<a class="anchor" aria-label="anchor" href="#optimizing-scalar-code"></a>
</h2>
<hr class="half-width">
<p>Programming in languages like C/C++ and Fortran produces fairly
efficient code in general because these are compiled languages. In other
words, you need to compile the code before executing it, and the
compilers do very intricate optimizations to ensure the resulting
executable is highly efficient. Interpretive languages like Python, R,
and Matlab only do some compilation on the fly. They are therefore much
less optimized, but more convenient to run. We have already learned the
importance of using optimized library routines whenever possible, but
this is especially true for the interpretive languages. Some languages
also have certain methods that are convenient, but very inefficient, and
what to avoid and how to get around them will be discussed in later
chapters.</p>
<p>One thing that can help in understanding performance is to know how
much it costs to perform different common math functions. We can express
the speed of a code in GFlops, or Giga (Billion) Floating-point
operations per second. A floating-point operation involves two operands
that are typically 64-bit floats. When counting the Flops, we ignore
integer arithmetic and comparisons since those are very fast in relation
to the floating-point operations. Below is a table of the Flop cost for
each operation. This can be thought of as for example how many
operations does it take to do a cosine function, since the cosine is
done using a math library.</p>
<table class="table">
<thead><tr class="header">
<th align="center">Function / Operation</th>
<th align="center">Flops count</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">* + -</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">/</td>
<td align="center">4</td>
</tr>
<tr class="odd">
<td align="center">square root</td>
<td align="center">4</td>
</tr>
<tr class="even">
<td align="center">sin()/cos()/tan()</td>
<td align="center">6</td>
</tr>
<tr class="odd">
<td align="center">exponent()</td>
<td align="center">14</td>
</tr>
</tbody>
</table>
<p>One example of how this knowledge can help is if you have a large
loop where you are dividing by 4.0. Instead, you reduce the operation
count by 3 if you multiply by 0.25. This is not needed in compiled
languages like C/C++ or Fortran since the compiler does this
optimization for you, but it can help in the interpretive languages. The
example below reduces the floating-point operation count by removing the
redundant calculation of theta and replacing the expensive calculations
of the cosine and sine by using an iterative method using trigonometric
identities.</p>
<div class="tabs">
<nav><div id="nav-tab-1" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-1-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Python" type="button" role="tab" aria-controls="nav-tabpanel-1-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-1-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-R" type="button" role="tab" aria-controls="nav-tabpanel-1-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-C" type="button" role="tab" aria-controls="nav-tabpanel-1-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-1-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-1-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-1" class="tab-content">
<div id="nav-tabpanel-1-Python" class="tab-pane show active" aria-labelledby="nav-tab-1-Python" role="tabpanel">
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># This is just partial code to demonstrate the mechanics of</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="co">#    using Flops minimization to optimize code for performance</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>    <span class="co"># Sum over each atom in the simulation</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N_atoms ):</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>    dx <span class="op">=</span> x[i] <span class="op">-</span> y[i]</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a>        <span class="co"># Sum over the frequencies</span></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>    <span class="cf">for</span> iq <span class="kw">in</span> <span class="bu">range</span>( NQ ):</span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>        theta <span class="op">=</span> <span class="fl">2.0</span> <span class="op">*</span> PI <span class="op">*</span> dx <span class="op">*</span> iq <span class="op">/</span> NQ</span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>        freq_real[iq] <span class="op">+=</span> cos( theta )</span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a>        freq_imag[iq] <span class="op">+=</span> sin( theta )</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-1-R" class="tab-pane" aria-labelledby="nav-tab-1-R" role="tabpanel">
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode r" tabindex="0"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># This is just partial code to demonstrate the mechanics of</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="co">#    using Flops minimization to optimize code for performance</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>    <span class="co"># Sum over each atom in the simulation</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="cf">for</span>( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N_atoms )</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>{</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>    dx <span class="ot">&lt;-</span> x[i] <span class="sc">-</span> y[i]</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>        <span class="co"># Sum over the frequencies</span></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a>    <span class="cf">for</span>( iq <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>NQ )</span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a>        theta <span class="ot">&lt;-</span> <span class="fl">2.0</span> <span class="sc">*</span> PI <span class="sc">*</span> dx <span class="sc">*</span> iq <span class="sc">/</span> NQ</span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>        freq_real[iq] <span class="ot">&lt;-</span> freq_real[iq] <span class="sc">+</span> <span class="fu">cos</span>( theta )</span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>        freq_imag[iq] <span class="ot">&lt;-</span> freq_imag[iq] <span class="sc">+</span> <span class="fu">sin</span>( theta )</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-1-C" class="tab-pane" aria-labelledby="nav-tab-1-C" role="tabpanel">
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">C<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode c" tabindex="0"><code class="sourceCode c"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co">// This is just partial code to demonstrate the mechanics of</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="co">//    using Flops minimization to optimize code for performance</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>      <span class="co">// Sum over each atom in the simulation and all frequencies</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>   <span class="cf">for</span><span class="op">(</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> N_atoms<span class="op">;</span> i<span class="op">++</span> <span class="op">)</span> <span class="op">{</span></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>      dx <span class="op">=</span> x<span class="op">[</span>i<span class="op">]</span> <span class="op">-</span> y<span class="op">[</span>i<span class="op">];</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>      <span class="cf">for</span><span class="op">(</span> iq <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> iq <span class="op">&lt;</span> NQ<span class="op">;</span> iq<span class="op">++</span> <span class="op">)</span> <span class="op">{</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>            <span class="co">// Sum over the frequencies</span></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>         theta <span class="op">=</span> <span class="op">(</span><span class="fl">2.0</span> <span class="op">*</span> PI <span class="op">*</span> dx <span class="op">*</span> iq<span class="op">)</span> <span class="op">/</span> NQ<span class="op">;</span></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>         freq_real<span class="op">[</span>iq<span class="op">]</span> <span class="op">+=</span> cos<span class="op">(</span> theta <span class="op">);</span></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>         freq_imag<span class="op">[</span>iq<span class="op">]</span> <span class="op">+=</span> sin<span class="op">(</span> theta <span class="op">);</span></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a>      <span class="op">}</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a>   <span class="op">}</span></span></code></pre>
</div>
</div>
<div id="nav-tabpanel-1-Fortran" class="tab-pane" aria-labelledby="nav-tab-1-Fortran" role="tabpanel">
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">FORTRAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode fortran" tabindex="0"><code class="sourceCode fortranfixed"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co">! This is just partial code to demonstrate the mechanics of</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="co">!    using Flops minimization to optimize code for performance</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>      <span class="co">! Sum over each atom in the simulation and all frequencies</span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>   <span class="kw">DO</span> i <span class="kw">=</span> <span class="dv">1</span>, N_atoms</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>      dx <span class="kw">=</span> x(i) <span class="kw">-</span> y(i)</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>      <span class="kw">DO</span> iq <span class="kw">=</span> <span class="dv">1</span>, NQ</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>            <span class="co">! Sum over the frequencies</span></span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>         theta <span class="kw">=</span> (<span class="fl">2.0</span> <span class="kw">*</span> PI <span class="kw">*</span> dx <span class="kw">*</span> iq) <span class="kw">/</span> NQ</span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a>         freq_real(iq) <span class="kw">=</span> freq_real(iq) <span class="kw">+</span> <span class="bu">cos</span>( theta )</span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a>         freq_imag(iq) <span class="kw">=</span> freq_imag(iq) <span class="kw">+</span> <span class="bu">sin</span>( theta )</span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a>      <span class="kw">END DO</span></span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a>   <span class="kw">END DO</span></span></code></pre>
</div>
</div>
<div id="nav-tabpanel-1-Matlab" class="tab-pane" aria-labelledby="nav-tab-1-Matlab" role="tabpanel">
<p>Not implemented yet.</p>
</div>
</div>
</div>
<div class="tabs">
<nav><div id="nav-tab-2" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-2-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Python" type="button" role="tab" aria-controls="nav-tabpanel-2-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-2-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-R" type="button" role="tab" aria-controls="nav-tabpanel-2-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-C" type="button" role="tab" aria-controls="nav-tabpanel-2-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-2-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-2-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-2" class="tab-content">
<div id="nav-tabpanel-2-Python" class="tab-pane show active" aria-labelledby="nav-tab-2-Python" role="tabpanel">
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># This is just partial code to demonstrate the mechanics of</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="co">#    using Flops minimization to optimize code for performance</span></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>d_theta <span class="op">=</span> ( <span class="fl">2.0</span> <span class="op">*</span> PI <span class="op">*</span> (x[<span class="dv">0</span>] <span class="op">-</span> y[<span class="dv">0</span>]) ) <span class="op">/</span> NQ</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>    <span class="co"># Sum over each atom in the simulation</span></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N_atoms ):</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>    dx <span class="op">=</span> x[i] <span class="op">-</span> y[i]</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>        <span class="co"># Calculate cos/sin of the theta increment and set starting cos/sin values</span></span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a>    cos_d_theta <span class="op">=</span> cos( d_theta )</span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a>    sin_d_theta <span class="op">=</span> sin( d_theta )</span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a>    cos_theta <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a>    sin_theta <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a>        <span class="co"># Sum over the frequencies</span></span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" tabindex="-1"></a>    <span class="cf">for</span> iq <span class="kw">in</span> <span class="bu">range</span>( NQ ):</span>
<span id="cb5-22"><a href="#cb5-22" tabindex="-1"></a>        cos_new <span class="op">=</span> cos_theta <span class="op">*</span> cos_d_theta <span class="op">-</span> sin_theta <span class="op">*</span> sin_d_theta</span>
<span id="cb5-23"><a href="#cb5-23" tabindex="-1"></a>        sin_theta <span class="op">=</span> sin_theta <span class="op">*</span> cos_d_theta <span class="op">+</span> cos_theta <span class="op">*</span> cos_d_theta</span>
<span id="cb5-24"><a href="#cb5-24" tabindex="-1"></a>        cos_theta <span class="op">=</span> cos_new</span>
<span id="cb5-25"><a href="#cb5-25" tabindex="-1"></a></span>
<span id="cb5-26"><a href="#cb5-26" tabindex="-1"></a>        freq_real[iq] <span class="op">+=</span> cos_theta</span>
<span id="cb5-27"><a href="#cb5-27" tabindex="-1"></a>        freq_imag[iq] <span class="op">+=</span> sin_theta</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-2-R" class="tab-pane" aria-labelledby="nav-tab-2-R" role="tabpanel">
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode r" tabindex="0"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># This is just partial code to demonstrate the mechanics of</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="co">#    using Flops minimization to optimize code for performance</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>d_theta <span class="ot">&lt;-</span> ( <span class="fl">2.0</span> <span class="sc">*</span> PI <span class="sc">*</span> (x[<span class="dv">0</span>] <span class="sc">-</span> y[<span class="dv">0</span>]) ) <span class="sc">/</span> NQ</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>    <span class="co"># Sum over each atom in the simulation</span></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a><span class="cf">for</span>( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N_atoms )</span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>{</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>    dx <span class="ot">&lt;-</span> x[i] <span class="sc">-</span> y[i]</span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a>        <span class="co"># Calculate cos/sin of the theta increment and set starting cos/sin values</span></span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a>    cos_d_theta <span class="ot">&lt;-</span> <span class="fu">cos</span>( d_theta )</span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a>    sin_d_theta <span class="ot">&lt;-</span> <span class="fu">sin</span>( d_theta )</span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a>    cos_theta <span class="ot">&lt;-</span> <span class="fl">1.0</span></span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a>    sin_theta <span class="ot">&lt;-</span> <span class="fl">0.0</span></span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" tabindex="-1"></a>        <span class="co"># Sum over the frequencies</span></span>
<span id="cb6-21"><a href="#cb6-21" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" tabindex="-1"></a>    <span class="cf">for</span>( iq <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>NQ )</span>
<span id="cb6-23"><a href="#cb6-23" tabindex="-1"></a>        cos_new <span class="ot">&lt;-</span> cos_theta <span class="sc">*</span> cos_d_theta <span class="sc">-</span> sin_theta <span class="sc">*</span> sin_d_theta</span>
<span id="cb6-24"><a href="#cb6-24" tabindex="-1"></a>        sin_theta <span class="ot">&lt;-</span> sin_theta <span class="sc">*</span> cos_d_theta <span class="sc">+</span> cos_theta <span class="sc">*</span> cos_d_theta</span>
<span id="cb6-25"><a href="#cb6-25" tabindex="-1"></a>        cos_theta <span class="ot">&lt;-</span> cos_new</span>
<span id="cb6-26"><a href="#cb6-26" tabindex="-1"></a></span>
<span id="cb6-27"><a href="#cb6-27" tabindex="-1"></a>        freq_real[iq] <span class="ot">&lt;-</span> freq_real[iq] <span class="sc">+</span> cos_theta</span>
<span id="cb6-28"><a href="#cb6-28" tabindex="-1"></a>        freq_imag[iq] <span class="ot">&lt;-</span> freq_imag[iq] <span class="sc">+</span> sin_theta</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-2-C" class="tab-pane" aria-labelledby="nav-tab-2-C" role="tabpanel">
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">C<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode c" tabindex="0"><code class="sourceCode c"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co">// This is just partial code to demonstrate the mechanics of</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="co">//    using Flops minimization to optimize code for performance</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>   d_theta <span class="op">=</span> <span class="op">(</span> <span class="fl">2.0</span> <span class="op">*</span> PI <span class="op">*</span> <span class="op">(</span>x<span class="op">[</span><span class="dv">0</span><span class="op">]</span> <span class="op">-</span> y<span class="op">[</span><span class="dv">0</span><span class="op">])</span> <span class="op">)</span> <span class="op">/</span> NQ<span class="op">;</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>      <span class="co">// Sum over each atom in the simulation and all frequencies</span></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>   <span class="cf">for</span><span class="op">(</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> N_atoms<span class="op">;</span> i<span class="op">++</span> <span class="op">)</span> <span class="op">{</span></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a>      dx <span class="op">=</span> x<span class="op">[</span>i<span class="op">]</span> <span class="op">-</span> y<span class="op">[</span>i<span class="op">];</span></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>         <span class="co">// Calculate cos/sin of the theta increment and set starting cos/sin values</span></span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a>      cos_d_theta <span class="op">=</span> cos<span class="op">(</span> d_theta <span class="op">);</span></span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a>      sin_d_theta <span class="op">=</span> sin<span class="op">(</span> d_theta <span class="op">);</span></span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a>      cos_theta <span class="op">=</span> <span class="fl">1.0</span><span class="op">;</span></span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a>      sin_theta <span class="op">=</span> <span class="fl">0.0</span><span class="op">;</span></span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a>      <span class="cf">for</span><span class="op">(</span> iq <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> iq <span class="op">&lt;</span> NQ<span class="op">;</span> iq<span class="op">++</span> <span class="op">)</span> <span class="op">{</span></span>
<span id="cb7-20"><a href="#cb7-20" tabindex="-1"></a></span>
<span id="cb7-21"><a href="#cb7-21" tabindex="-1"></a>         cos_new <span class="op">=</span> cos_theta <span class="op">*</span> cos_d_theta <span class="op">-</span> sin_theta <span class="op">*</span> sin_d_theta<span class="op">;</span></span>
<span id="cb7-22"><a href="#cb7-22" tabindex="-1"></a>         sin_theta <span class="op">=</span> sin_theta <span class="op">*</span> cos_d_theta <span class="op">+</span> cos_theta <span class="op">*</span> cos_d_theta<span class="op">;</span></span>
<span id="cb7-23"><a href="#cb7-23" tabindex="-1"></a>         cos_theta <span class="op">=</span> cos_new<span class="op">;</span></span>
<span id="cb7-24"><a href="#cb7-24" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" tabindex="-1"></a>            <span class="co">// Sum over the frequencies</span></span>
<span id="cb7-26"><a href="#cb7-26" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" tabindex="-1"></a>         freq_real<span class="op">[</span>iq<span class="op">]</span> <span class="op">+=</span> cos_theta<span class="op">;</span></span>
<span id="cb7-28"><a href="#cb7-28" tabindex="-1"></a>         freq_imag<span class="op">[</span>iq<span class="op">]</span> <span class="op">+=</span> sin_theta<span class="op">;</span></span>
<span id="cb7-29"><a href="#cb7-29" tabindex="-1"></a>      <span class="op">}</span></span>
<span id="cb7-30"><a href="#cb7-30" tabindex="-1"></a></span>
<span id="cb7-31"><a href="#cb7-31" tabindex="-1"></a>   <span class="op">}</span></span></code></pre>
</div>
</div>
<div id="nav-tabpanel-2-Fortran" class="tab-pane" aria-labelledby="nav-tab-2-Fortran" role="tabpanel">
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">FORTRAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode fortran" tabindex="0"><code class="sourceCode fortranfixed"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co">! This is just partial code to demonstrate the mechanics of</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="co">!    using Flops minimization to optimize code for performance</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>   d_theta <span class="kw">=</span> ( <span class="fl">2.0</span> <span class="kw">*</span> PI <span class="kw">*</span> (x(<span class="dv">0</span>) <span class="kw">-</span> y(<span class="dv">0</span>)) ) <span class="kw">/</span> NQ</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>      <span class="co">! Sum over each atom in the simulation and all frequencies</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>   <span class="kw">DO</span> i <span class="kw">=</span> <span class="dv">1</span>, N_atoms</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>      dx <span class="kw">=</span> x(i) <span class="kw">-</span> y(i)</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>         <span class="co">! Calculate cos/sin of the theta increment and set starting cos/sin values</span></span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>      cos_d_theta <span class="kw">=</span> <span class="bu">cos</span>( d_theta )</span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>      sin_d_theta <span class="kw">=</span> <span class="bu">sin</span>( d_theta )</span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a>      cos_theta <span class="kw">=</span> <span class="fl">1.0</span></span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a>      sin_theta <span class="kw">=</span> <span class="fl">0.0</span></span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a></span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a></span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a>      <span class="kw">DO</span> iq <span class="kw">=</span> <span class="dv">1</span>, NQ</span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a>         cos_new <span class="kw">=</span> cos_theta <span class="kw">*</span> cos_d_theta <span class="kw">-</span> sin_theta <span class="kw">*</span> sin_d_theta</span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a>         sin_theta <span class="kw">=</span> sin_theta <span class="kw">*</span> cos_d_theta <span class="kw">+</span> cos_theta <span class="kw">*</span> cos_d_theta</span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a>         cos_theta <span class="kw">=</span> cos_new</span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a></span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a>            <span class="co">! Sum over the frequencies</span></span>
<span id="cb8-27"><a href="#cb8-27" tabindex="-1"></a></span>
<span id="cb8-28"><a href="#cb8-28" tabindex="-1"></a>         freq_real(iq) <span class="kw">=</span> freq_real(iq) <span class="kw">+</span> cos_theta</span>
<span id="cb8-29"><a href="#cb8-29" tabindex="-1"></a>         freq_imag(iq) <span class="kw">=</span> freq_imag(iq) <span class="kw">+</span> sin_theta</span>
<span id="cb8-30"><a href="#cb8-30" tabindex="-1"></a></span>
<span id="cb8-31"><a href="#cb8-31" tabindex="-1"></a>      <span class="kw">END DO</span></span>
<span id="cb8-32"><a href="#cb8-32" tabindex="-1"></a></span>
<span id="cb8-33"><a href="#cb8-33" tabindex="-1"></a>   <span class="kw">END DO</span></span></code></pre>
</div>
</div>
<div id="nav-tabpanel-2-Matlab" class="tab-pane" aria-labelledby="nav-tab-2-Matlab" role="tabpanel">
<p>Not implemented yet.</p>
</div>
</div>
</div>
<p>This is however a very over-simplified picture since it involves just
analyzing one factor. In practice, most processors can overlap
calculations for better speed like in the AVX vector instruction sets of
the Intel and AMD x86 architectures.</p>
<div id="flops-count" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="flops-count" class="callout-inner">
<h3 class="callout-title">Flops count</h3>
<div class="callout-content">
<p>Count the floating-point operations (Flops) in the unoptimized and
optimized versions of the code above and calculate the expected speedup
rate.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>The unoptimized code uses <strong>N_atoms * ( 1 + 21 * NQ )
Flops</strong>. The optimized version uses <strong>N_atoms * ( 13 + 6 *
NQ ) Flops</strong>. For large NQ the speedup would be around 21/6 or
<strong>3.5 times</strong>.</p>
<p>The compiled languages C/C++/Fortran would optimize some of this loop
automatically by pulling the <strong>2.0 * PI * dx / NQ</strong> out of
the <strong>NQ</strong> loop and just multiplying this by
<strong>iq</strong> each time.</p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="parallelizing-code">Parallelizing Code<a class="anchor" aria-label="anchor" href="#parallelizing-code"></a>
</h2>
<hr class="half-width">
<p>It is always good to optimize a scalar code first, but if you still
need your code to run faster then one option is to use more processing
power. This means using more then one computational core with each core
working on a different part of the data. The goal is to get a speedup of
N times if you are using N cores, though often parallel programs will
fall short of this ideal.</p>
<p>There are two main types of parallel programming. The first is
multi-core or shared-memory programming. This is the easiest approach,
with a single program running but for computationally demanding sections
like loops multiple threads are used with typically one thread on each
computational core. In this way, the scalar part of the code does not
need to be altered and we only need to put parallelizing commands before
each loop to tell the computer how to divide the problem up. It is
called <strong>shared-memory</strong> because all threads operate on the
data that is shared in main memory. This is the easiest approach, is
often very efficient, but has the limitation that it needs to work only
on a single compute node. Multi-threading in C/C++ and Fortran use the
<strong>OpenMP</strong> package, Python uses a simplified version of
this called <strong>pymp</strong>, and R allows for this through the
<strong>mclapply()</strong> function.</p>
<p>If you need even more computational power, or need access to more
memory than is on a single node, then you need to use multi-node
computing. This is also referred to as distributed-memory computing
since each thread in this case is its own separate but identical
program, again just operating on a different part of the data.
Distributed-memory programs can be run on a single compute node when
needed, but are designed to run on very large numbers of nodes at the
same time. Some programs have been run on millions of compute nodes, or
some of the largest HPC systems in the world which may cost more than
$100 million. C/C++ and Fortran codes use MPI, the Message-Passing
Interface, launching all the copies of the program to the different
nodes using the <strong>mpirun</strong> command, then each node shakes
hands with the others with the <strong>MPI_Init()</strong> function.
Each thread or task will operate on a different part of the data, and
when data needs to be exchanged the programmer can use MPI commands like
<strong>MPI_Send()</strong> and <strong>MPI_Recv()</strong> to pass
blocks of data to other threads. This is a very powerful way to program,
but it is definitely much more complicated too. Python has the
<strong>mpi4py</strong> package which is a stripped down version of MPI,
but unfortunately you cannot do multi-node computing with R.</p>
<p>You will not be taught how to program in these parallel languages in
this course, but you will be shown how to recognize each type of
parallel approach and how to work with each efficiently.</p>
</section><section><h2 class="section-heading" id="parallel-computing-concepts">Parallel Computing Concepts<a class="anchor" aria-label="anchor" href="#parallel-computing-concepts"></a>
</h2>
<hr class="half-width">
<p>The syntax for doing parallel processing is different for
multi-threaded and multi-node programming, and also can vary for each
language, but handling multiple threads at the same time always involves
some of the same basic underlying concepts. Understanding the basic
concepts underlying these methods will help us to understand the
functions at the language level themselves.</p>
<div class="section level3">
<h3 id="locks-in-programs-and-file-systems">Locks in Programs and File Systems<a class="anchor" aria-label="anchor" href="#locks-in-programs-and-file-systems"></a>
</h3>
<p>A multi-threaded program uses shared-memory where many threads may
want to access the same data at the same time. If they are all reading
the data, this is not a problem. However, if even one thread wants to
change the data by writing to it while other threads may be reading it,
this can lead to uncertain results depending on which thread does its
read or write first. This uncertainty must therefore always be avoided,
and often it is handled by locking memory when a write occurs so that
only that one thread has access at that time.</p>
<p>The same thing can happen in parallel file servers where there are
multiple paths being exploited to the same data file in order to provide
better performance. If multiple threads, or even multiple programs, are
reading the same file or different files in the same directory then
everything is fine. However, if one of those is writing to a file then a
parallel file server will lock the entire directory down to prevent
other threads from reading until the write is completed. This is
something that every user needs to be aware of. It only applies to
parallel file servers, so local disk (/tmp) has no problems with this
since there is only one controller for the disk, while a parallel file
server has many controlling nodes. Some scratch space also can handle
multiple writes to the same directory without locking. Since this can
have severe impacts on performance, it is always good to ask your system
administrator if you don’t know. Ways around this include switching to a
different file system like /tmp while running the job, or putting the
files in different directories.</p>
</div>
<div class="section level3">
<h3 id="barriers">Barriers<a class="anchor" aria-label="anchor" href="#barriers"></a>
</h3>
<p>Since distributed-memory programs involve multiple copies of the same
code, we commonly need to ensure that all are at the same point in the
code. MPI uses barriers for this, an <strong>MPI_Barrier()</strong>
function to be exact. When this is encountered, each task will stop and
wait until all tasks reach that point in the code, they will communicate
this to each other, then continue on. A common example of why you would
need this would be in debugging an MPI code where you want to identify
where the code may be failing. If one task gets ahead of the other and
errors out, it may be that the root task will be at a different place in
the code and report that line where the job failed.</p>
</div>
<div class="section level3">
<h3 id="forks">Forks<a class="anchor" aria-label="anchor" href="#forks"></a>
</h3>
<p>All multi-threaded packages use some sort of a fork function. When a
loop is encountered and the root thread needs to spin up multiple
threads to do the work, it does so by doing a <strong>fork()</strong>
which duplicates the variables in the root thread. This is done
virtually which may be a bit confusing. If every piece of data was
copied it would increase the memory usage enormously for runs on large
numbers of cores, so only the pointers to the arrays are copied. If the
data is only being read then all threads can read from the original
array. If any thread writes to part of an array, then a unique copy of
that part of the array is made for that thread only. So the fork process
manages the memory usage behind the scenes to minimize the redundant
storage of data, but ensures that there is no need for a memory lock
when a thread writes to that data by making a copy instead.</p>
</div>
<div class="section level3">
<h3 id="dependencies-in-loops">Dependencies in Loops<a class="anchor" aria-label="anchor" href="#dependencies-in-loops"></a>
</h3>
<p>All those mechanisms discussed above may be used in implementing a
parallel computing package. As a user, what we really need to know is
when can a section of a program be parallelized. If you look at the
loops where the most computational time is being spent, what you need to
determine is whether each pass through the loop is independent of the
others, or whether each pass is dependent on the results of the previous
iteration. If each pass through a loop can be done independently of the
others, then we can do them at the same time. This is a simple
statement, but it does sometimes take more thinking to understand if
there are any dependencies involved. If you have any doubt, try writing
down all the variables that are needed as input for each iteration of
the loop, then see if any of those change throughout the loop.</p>
<p>If you have a program with nested loops, you may need to analyze each
loop level to see if it is parallelizable. Parallelizing the outer loop
means that there will be more computations for each thread or task,
which is referred to as being more coarse grained. This can lead to much
higher efficiencies, but it is not always possible. Often it is the
inner loop that is easiest to parallelize, and this is most often the
case with multi-threaded parallelism.</p>
</div>
</section><section><h2 class="section-heading" id="using-accelerators-like-gpus">Using Accelerators like GPUs<a class="anchor" aria-label="anchor" href="#using-accelerators-like-gpus"></a>
</h2>
<hr class="half-width">
<p>Some programs can be sped up by using a GPU as a computational
accelerator. A 32-bit GPU is the same as you would buy for a high-end
gaming computer and can cost $1000-$1500. These are ideal for
accelerating 32-bit codes like classical molecular dynamics simulations,
and have custom hardware that is great for training AI (Artificial
Intelligence) neural networks or machine learning models. The more
expensive 64-bit GPUs are never intended for graphics at all. They are
custom designed as accelerators even though they are still called GPUs.
These currently cost around $11,000 for an NVIDIA A100 and around twice
that for a newer H100.</p>
<p>Writing a program to run on a GPU is very difficult. For NVIDIA GPUs,
you use a programming language called CUDA. There are many fewer codes
optimized for AMD GPUs at this point. They are programmed with Hip which
can be compiled to run on either AMD or NVIDIA GPUs. There are also
projects in development to convert native CUDA codes into executables
optimized for AMD GPUs.</p>
<p>Running a job with a GPU accelerator is not that difficult. If your
application can make use of one or more GPUs, there will be directions
on how to specify the number of GPUs. If you are on an HPC system, you
can request the number and type of GPUs you want for each job.</p>
</section><section><h2 class="section-heading" id="optimizing-input-and-output">Optimizing Input and Output<a class="anchor" aria-label="anchor" href="#optimizing-input-and-output"></a>
</h2>
<hr class="half-width">
<p>The first thing to understand about IO (Input and Output) is that it
can make a big difference as to what type of a file system you are
reading from or writing to. Local disk (usually /tmp) is temporary
storage and has size restrictions, and it isn’t as fast as a parallel
file server that stripes data across many disks at the same time, but it
is still sometimes the best to use if others are heavily using the main
file server and slowing it down. As good as parallel file severs are,
they also commonly need to lock a directory if more than one file is
being written at the same time. Any locking can slow the performance of
a code down immensely and should be avoided if at all possible. Many HPC
systems may have fast scratch space which is temporary storage often
purged every week or month but very large in size. This is designed for
use when you are running your job, and may also not suffer from the same
locking issues as on some parallel file servers.</p>
<p>On our HPC system at Kansas State University, our fast scratch is
about ten times as fast as the parallel file server system that our home
directories are on. So you would think that all you have to do is use
fast scratch all the time to make your IO ten times faster. It actually
is the case if you are streaming data in, by which we mean reading in
data in large chunks that do not need to be converted. Files with large
strings like genetic information fall into this category since the
strings can be hundreds or thousands of characters long and the
representation in the file is the same as in the program. Reading in
arrays of floats or integers from binary files also can go as fast as
the file server allows since the elements are stored in binary in both
the file and the program.</p>
<p>The problem comes when we want to store numbers for example in a text
file so we can see them ourselves. When we write them or read them, the
process goes slow since we have to convert each number from its binary
representation into a text string before reading or writing. With IO, it
is that conversion process which is slow, so it doesn’t matter how fast
the underlying file server is in these cases. So if you want to speed up
IO, think about streaming data in binary form if possible, and if so
then choose the fastest file server available.</p>
<div id="scaling-study-of-the-distributed-memory-dot-product-code" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="scaling-study-of-the-distributed-memory-dot-product-code" class="callout-inner">
<h3 class="callout-title">Scaling Study of the Distributed-Memory Dot
Product Code</h3>
<div class="callout-content">
<p>Measure the entire run-time for the dot_product_message_passing code
for the language you are working with for 1, 4, 8, and 16 cores if you
are on an HPC system with at least 2 compute nodes. You can try
different combinations of nodes and cores for each if you would like to
see the effects of the network (for the 4 cores, try 2 nodes 2 cores vs
4 nodes 1 core).</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>In this code we initialize the vectors locally so there is no
communication involved. The only communication is the global sum at the
end, so we expect the scaling to be close to ideal. In many practical
MPI codes, we would need to read data into one of the ranks, divide the
data up and send it out to each other node. Real MPI applications also
usually require communication mixed in with the computational part in
order to get data where it needs to be. All this communication can slow
down the job, and this usually gets worse as you spread a job over more
cores, and especially over more nodes.</p>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>What techniques can be used to speed up scalar code?</li>
<li>How to improve input and output?</li>
<li>Learn about the difference between multi-core and multi-node
programs.</li>
<li>Understand the fundamentals of locks, barriers, and forks.</li>
<li>Practice doing a scaling study.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-multi-threaded"><p>Content from <a href="multi-threaded.html">Multi-Threaded Programs</a></p>
<hr>
<p>Last updated on 2025-09-17 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/multi-threaded.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 30 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is the multi-threaded shared-memory programming model?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Learn about multi-threaded computing and how to use it.</li>
<li>Understand the strengths and limitations of this approach.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>Most computer languages have the ability to do multi-threaded
computing. C/C++ and Fortran use the OpenMP package which is by far the
most extensive and well developed. It uses pragma statements to control
the parallelization of loops so that multiple compute cores work at the
same time on different parts of the data. OpenMP is not only extremely
efficient, but it also provides very advanced features offering greater
control on how the parallelization is to be done, all without
encumbering the programmer too much. The <strong>pymp</strong> package
for Python is a stripped down version of OpenMP supporting just the
basic functionality. It is an actively developed project and is very
efficient and relatively easy to use as well. R takes a very different
approach in doing multi-threading using the <strong>mclapply()</strong>
function which is a multi-core replacement for the
<strong>lapply()</strong> function. This operates similarly to OpenMP
and pymp but uses a very different syntax. It is also not nearly as
efficient and requires some non-default choices to make it more perform
better. Matlab also uses a different syntax in its Parallel Computing
Toolbox where it uses a <strong>parfor</strong> command to do a parallel
<strong>for</strong> loop.</p>
<p>All of these methods behave basically the same by forking, or
splitting off, extra compute threads when called. Each thread gets its
own virtual memory space, meaning most large arrays are not copied
during the initialization stage. If any thread writes to an array, only
then is that array copied to that thread’s memory, and only the page of
memory (4096 Bytes) that has been changed. This is called a
<strong>copy-on-write</strong> method and is handled by the operating
system. Forking is very efficient in this way, only doing the work it
needs. For Python, this gets around the Global Interface Lock which is
designed to protect python objects. Unfortunately the Windows operating
system itself does not have support for the <strong>fork</strong>
function so you cannot run multi-threaded Python codes like
<strong>pymp</strong> on Windows, at least from the Power Shell.
However, if you have the Windows Subsystem for Linux (WSL) installed
this provides a robust Linux system that bypasses Windows and its
limitations so <strong>pymp</strong> codes can be run in this
manner.</p>
<p>The figure below illustrates how multi-threading works on a dot
product between two vectors. Since the program uses shared-memory, the
initialization is done entirely on the main thread of processor 1. Then
each of 4 threads in this example does a partial sum on the vector
elements it is responsible for, so all 4 threads are running at the same
time but operating on different parts of the data. After they have all
completed their parts of the computation, the master thread sums all the
partial sums into the dot product and prints it out.</p>
<figure><img src="../fig/multi-threaded-dot-product-0.jpg" alt="Shared-memory multi-threaded dot product showing the memory layout of both vectors" class="figure mx-auto d-block"><div class="figcaption">Diagram of a shared-memory multi-threaded dot
product</div>
</figure><div class="section level3">
<h3 id="the-multi-threaded-dot-product-code">The multi-threaded dot product code<a class="anchor" aria-label="anchor" href="#the-multi-threaded-dot-product-code"></a>
</h3>
<div class="tabs">
<nav><div id="nav-tab-1" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-1-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Python" type="button" role="tab" aria-controls="nav-tabpanel-1-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-1-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-R" type="button" role="tab" aria-controls="nav-tabpanel-1-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-C" type="button" role="tab" aria-controls="nav-tabpanel-1-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-1-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-1-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-1" class="tab-content">
<div id="nav-tabpanel-1-Python" class="tab-pane show active" aria-labelledby="nav-tab-1-Python" role="tabpanel">
<p>Let’s go through the multi-threaded version of the dot product code
below to illustrate the changes that had to be made to the code to
parallelize it. The <strong>pymp</strong> package needs to be installed
into our virtual environment by doing <strong>pip install
pymp-pypi</strong>. Once that is installed, the <strong>import
pymp</strong> line will bring those functions into the code.</p>
<p>When we run the code we will want to set the number of threads for it
to use. In the code below, this is being set internally using the number
of threads passed in as a command line argument. This is used to set the
number of threads using the <strong>pymp.config.num_threads</strong>
variable. The other method of setting the number of threads is to use
the environmental variable <strong>PYMP_NUM_THREADS</strong> externally.
For example, in your job script you can have a line <strong>export
PYMP_NUM_THREADS=4</strong> to tell the program to use 4 threads.</p>
<p>Right before the loop we must define our parallel environment with
the line <strong>with pymp.Parallel( nthreads ) as p:</strong> which
spins up the threads with the fork method. Then the for loop range is
changed so that each thread has a different range for the elements of
the loop that each thread is responsible for.</p>
<p>In the OpenMP multi-threading package used with C/C++ and Fortran,
you can use the same variable d_prod in the loop and just declare it as
a variable to be used locally within each thread then globally summed at
the end, which is called a <strong>reduction</strong>. This is very
convenient and requires fewer changes to the code, but the
<strong>pymp</strong> package does not support this added function by
choice opting for the Python way of doing it more explicitly, so in our
code we need to create a shared array of partial sums and manually sum
them together at the end. This is just as efficient computationally, it
just takes a little extra coding but is more explicit.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># Do the dot product between two vectors X and Y then print the result</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="co"># USAGE:  python dot_product_threaded.py 4       to run on 4 threads</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> sys</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">import</span> pymp</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>   <span class="co"># Get and set nthreads from the command line</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a>pymp.config.num_threads <span class="op">=</span> <span class="bu">int</span>( sys.argv[<span class="dv">1</span>] )</span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a>nthreads <span class="op">=</span> pymp.config.num_threads</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">100000000</span>      <span class="co"># Do a large enough test to reduce timing variance</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a>x <span class="op">=</span> [ <span class="bu">float</span>( i ) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N ) ]</span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a>y <span class="op">=</span> [ <span class="bu">float</span>( i ) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N ) ]</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>   <span class="co"># Now initialize a very large dummy array to force X and Y out of all levels of cache</span></span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>   <span class="co">#    so that our times are for pulling elements up from main memory.</span></span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a>dummy <span class="op">=</span> [ <span class="fl">0.0</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( <span class="dv">125000000</span> ) ]  <span class="co"># Initialize 1 GB of memory</span></span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" tabindex="-1"></a>   <span class="co"># Now we start our timer and do our calculation using multiple threads</span></span>
<span id="cb1-24"><a href="#cb1-24" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" tabindex="-1"></a>t_start <span class="op">=</span> time.perf_counter()</span>
<span id="cb1-26"><a href="#cb1-26" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" tabindex="-1"></a>psum <span class="op">=</span> pymp.shared.array( (nthreads,), dtype<span class="op">=</span><span class="st">'float'</span> )</span>
<span id="cb1-28"><a href="#cb1-28" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( nthreads ):</span>
<span id="cb1-29"><a href="#cb1-29" tabindex="-1"></a>   psum[i] <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb1-30"><a href="#cb1-30" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" tabindex="-1"></a>d_prod <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb1-32"><a href="#cb1-32" tabindex="-1"></a><span class="cf">with</span> pymp.Parallel( nthreads ) <span class="im">as</span> p:</span>
<span id="cb1-33"><a href="#cb1-33" tabindex="-1"></a>   <span class="cf">for</span> i <span class="kw">in</span> p.<span class="bu">range</span>( N ):</span>
<span id="cb1-34"><a href="#cb1-34" tabindex="-1"></a>      <span class="co">#d_prod += x[i] * y[i]</span></span>
<span id="cb1-35"><a href="#cb1-35" tabindex="-1"></a>      psum[p.thread_num] <span class="op">+=</span> x[i] <span class="op">*</span> y[i]</span>
<span id="cb1-36"><a href="#cb1-36" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( nthreads ):     <span class="co"># Explicitly do the reduction across threads</span></span>
<span id="cb1-38"><a href="#cb1-38" tabindex="-1"></a>   d_prod <span class="op">+=</span> psum[i]</span>
<span id="cb1-39"><a href="#cb1-39" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" tabindex="-1"></a>t_elapsed <span class="op">=</span> time.perf_counter() <span class="op">-</span> t_start</span>
<span id="cb1-41"><a href="#cb1-41" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" tabindex="-1"></a>   <span class="co"># The calculation is done and timer stopped so print out the answer</span></span>
<span id="cb1-43"><a href="#cb1-43" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'dot product = '</span>, d_prod, <span class="st">'took '</span>, t_elapsed, <span class="st">' seconds'</span> )<span class="op">;</span></span>
<span id="cb1-45"><a href="#cb1-45" tabindex="-1"></a><span class="bu">print</span>( <span class="fl">2.0</span><span class="op">*</span>N<span class="op">*</span><span class="fl">1.0e-9</span> <span class="op">/</span> t_elapsed, <span class="st">' Gflops (billion floating-point operations per second)'</span>)</span>
<span id="cb1-46"><a href="#cb1-46" tabindex="-1"></a><span class="bu">print</span>( <span class="fl">2.0</span><span class="op">*</span>N<span class="op">*</span><span class="fl">8.0</span><span class="op">/</span><span class="fl">1.0e9</span>, <span class="st">' GB memory used'</span> )</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-1-R" class="tab-pane" aria-labelledby="nav-tab-1-R" role="tabpanel">
<p>Let’s go through the multi-threaded version of the dot product code
below to illustrate the changes that had to be made to the code to
parallelize it. In R we need to define a virtual cluster that will be
used to spread the work from the <strong>for</strong> loops across the
CPU cores. This can be done in several ways in R and the choice should
come down to what works best for the problem you are coding up.</p>
<p>We start by loading the library <strong>parallel</strong> in the
first example code below to pull in the detectCores(), makeCluster(),
clusterExport(), and clusterApply() functions. We next detect the number
of cores accessible to the job then define the cluster with
<strong>makeCluster()</strong> spawning independent worker processes to
handle parts of the parallel processing. For this
<strong>parallel</strong> library we need the body of the loop to be put
into a function and any variables that need to be used inside this
function must be exported using <strong>clusterExport()</strong>
commands. The <strong>clusterApply()</strong> command uses the cluster
object, iteration range, and function name which then spawns multiple
processes to execute the function for the iteration loop, automatically
splitting them across the cores in the virtual cluster on a single
compute node. At the end there is a <strong>stopCluster()</strong>
statement that cleans up the virtual cluster before the program
ends.</p>
<p>This basic approach is simple and can be useful but also may be
inefficient since the overhead for dividing the work between threads may
be much greater than the work done within each iteration, as is clearly
the case in our simple example where there is only a single
multiplication for each pass through the loop. In the second part of
this code, the loop is instead divided over the number of threads with
the function then manually splitting the loop iterations internally.
This greatly limits the assignment-of-work overhead since only the
initial assignment is needed and you will see for yourself that the
resulting performance is enormously better.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Dot product in R using a loop and a vector summation</span></span>
<span><span class="co"># USAGE:  Rscript dot_product_multi_thread.R 100000 8   for 100,000 elements on 8 cores</span></span>
<span></span>
<span><span class="kw">library</span><span class="op">(</span> <span class="va">parallel</span> <span class="op">)</span></span>
<span></span>
<span>   <span class="co"># Get the vector size and nThreads from the command line</span></span>
<span></span>
<span><span class="va">args</span> <span class="op">&lt;-</span> <span class="fu">commandArgs</span><span class="op">(</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="kw">if</span><span class="op">(</span> <span class="fu">length</span><span class="op">(</span> <span class="va">args</span> <span class="op">)</span> <span class="op">==</span> <span class="fl">2</span> <span class="op">)</span> <span class="op">{</span></span>
<span>   <span class="va">n</span> <span class="op">&lt;-</span> <span class="fu">as.integer</span><span class="op">(</span> <span class="va">args</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">)</span></span>
<span>   <span class="va">nThreads</span> <span class="op">&lt;-</span> <span class="fu">as.integer</span><span class="op">(</span> <span class="va">args</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">)</span></span>
<span><span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>   <span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">100000</span></span>
<span>   <span class="va">nThreads</span> <span class="op">&lt;-</span> <span class="fu">detectCores</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">cl</span> <span class="op">&lt;-</span> <span class="fu">makeCluster</span><span class="op">(</span> <span class="va">nThreads</span> <span class="op">)</span></span>
<span></span>
<span></span>
<span>   <span class="co"># Allocate space for and initialize the arrays</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu">vector</span><span class="op">(</span> <span class="st">"double"</span>, <span class="va">n</span> <span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">vector</span><span class="op">(</span> <span class="st">"double"</span>, <span class="va">n</span> <span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span><span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span> <span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>   <span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">as.double</span><span class="op">(</span><span class="va">i</span><span class="op">)</span></span>
<span>   <span class="va">y</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">as.double</span><span class="op">(</span><span class="fl">3</span><span class="op">*</span><span class="va">i</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span>   <span class="co"># Export variables needed within the functions</span></span>
<span></span>
<span><span class="fu">clusterExport</span><span class="op">(</span> <span class="va">cl</span>, <span class="st">"x"</span> <span class="op">)</span></span>
<span><span class="fu">clusterExport</span><span class="op">(</span> <span class="va">cl</span>, <span class="st">"y"</span> <span class="op">)</span></span>
<span><span class="fu">clusterExport</span><span class="op">(</span> <span class="va">cl</span>, <span class="st">"n"</span> <span class="op">)</span></span>
<span><span class="fu">clusterExport</span><span class="op">(</span> <span class="va">cl</span>, <span class="st">"nThreads"</span> <span class="op">)</span></span>
<span></span>
<span>   <span class="co"># Time a multi-threaded dot product even though it's inefficient</span></span>
<span></span>
<span><span class="va">dot_product_function</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span> <span class="va">i</span> <span class="op">)</span> <span class="op">{</span></span>
<span></span>
<span>   <span class="kw">return</span><span class="op">(</span> <span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">*</span> <span class="va">y</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">)</span></span>
<span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">dummy</span> <span class="op">&lt;-</span> <span class="fu">matrix</span><span class="op">(</span> <span class="fl">1</span><span class="op">:</span><span class="fl">125000000</span> <span class="op">)</span>       <span class="co"># Clear the cache buffers before timing</span></span>
<span></span>
<span><span class="va">t_start</span> <span class="op">&lt;-</span> <span class="fu">proc.time</span><span class="op">(</span><span class="op">)</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span></span>
<span><span class="va">dot_product_list</span> <span class="op">&lt;-</span> <span class="fu">clusterApply</span><span class="op">(</span> <span class="va">cl</span>, <span class="fl">1</span><span class="op">:</span><span class="va">n</span>, <span class="va">dot_product_function</span> <span class="op">)</span></span>
<span><span class="va">dot_product</span> <span class="op">&lt;-</span> <span class="fu">sum</span><span class="op">(</span> <span class="fu">unlist</span><span class="op">(</span><span class="va">dot_product_list</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">t_end</span> <span class="op">&lt;-</span> <span class="fu">proc.time</span><span class="op">(</span><span class="op">)</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="fu">sprintf</span><span class="op">(</span><span class="st">"Threaded dot product by clusterApply took %6.3f seconds"</span>, <span class="va">t_end</span><span class="op">-</span><span class="va">t_start</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="fu">sprintf</span><span class="op">(</span><span class="st">"dot_product = %.6e on %i threads for vector size %i"</span>, <span class="va">dot_product</span>, <span class="va">nThreads</span>, <span class="va">n</span> <span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span></span>
<span>   <span class="co"># Now try dividing the iterations manually between workers</span></span>
<span></span>
<span><span class="va">dot_product_workers</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span> <span class="va">myThread</span> <span class="op">)</span> <span class="op">{</span></span>
<span></span>
<span>   <span class="va">mySum</span> <span class="op">&lt;-</span> <span class="fl">0.0</span></span>
<span>   <span class="kw">for</span><span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fu">seq</span><span class="op">(</span> <span class="va">myThread</span>, <span class="va">n</span>, by <span class="op">=</span> <span class="va">nThreads</span> <span class="op">)</span> <span class="op">)</span></span>
<span>   <span class="op">{</span></span>
<span>      <span class="va">mySum</span> <span class="op">&lt;-</span> <span class="va">mySum</span> <span class="op">+</span> <span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">*</span> <span class="va">y</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span>   <span class="op">}</span></span>
<span>   <span class="kw">return</span><span class="op">(</span> <span class="va">mySum</span> <span class="op">)</span></span>
<span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">dummy</span> <span class="op">&lt;-</span> <span class="fu">matrix</span><span class="op">(</span> <span class="fl">1</span><span class="op">:</span><span class="fl">125000000</span> <span class="op">)</span>       <span class="co"># Clear the cache buffers before timing</span></span>
<span></span>
<span><span class="va">t_start</span> <span class="op">&lt;-</span> <span class="fu">proc.time</span><span class="op">(</span><span class="op">)</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span></span>
<span><span class="va">dot_product_list</span> <span class="op">&lt;-</span> <span class="fu">clusterApply</span><span class="op">(</span> <span class="va">cl</span>, <span class="fl">1</span><span class="op">:</span><span class="va">nThreads</span>, <span class="va">dot_product_workers</span> <span class="op">)</span></span>
<span><span class="va">dot_product</span> <span class="op">&lt;-</span> <span class="fu">sum</span><span class="op">(</span> <span class="fu">unlist</span><span class="op">(</span><span class="va">dot_product_list</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">t_end</span> <span class="op">&lt;-</span> <span class="fu">proc.time</span><span class="op">(</span><span class="op">)</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="fu">sprintf</span><span class="op">(</span><span class="st">"Threaded dot product with nThreads workers took %6.3f seconds"</span>, <span class="va">t_end</span><span class="op">-</span><span class="va">t_start</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="fu">sprintf</span><span class="op">(</span><span class="st">"dot_product = %.6e on %i threads for vector size %i"</span>, <span class="va">dot_product</span>, <span class="va">nThreads</span>, <span class="va">n</span> <span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu">stopCluster</span><span class="op">(</span> <span class="va">cl</span> <span class="op">)</span></span></code></pre>
</div>
<p>This second multi-threaded example below uses the
<strong>foreach</strong> and <strong>doParallel</strong> libraries. This
code similarly defines and initiates a virtual cluster. The
<strong>foreach</strong> loop is similar to a <strong>for</strong> loop
but you can choose between different back ends. A <strong>%do%</strong>
back end would run the body in scalar, while the <strong>%dopar</strong>
will split the iterations across the cores of the virtual cluster, and
we will discuss later that there is a <strong>%doMPI%</strong> back end
that can split the work across cores on different compute nodes. While
similar to the previous example, the <strong>foreach</strong> approach
is cleaner programming in that you don’t have to create a separate
function for the body of the loop. You also don’t need to manually
export variables since the processes that are spawned inherit the
environment of the parent process. So we get more flexibility in the
back ends as well as a more convenient programming approach. You’ll be
asked to measure the performance of each approach in the exercise
below.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Dot product in R using a loop and a vector summation</span></span>
<span><span class="co"># USAGE:  Rscript dot_product_threaded_dopar.R 100000 8     for 100,000 elements on 8 threads</span></span>
<span></span>
<span><span class="kw">library</span><span class="op">(</span> <span class="va">foreach</span> <span class="op">)</span></span>
<span><span class="kw">library</span><span class="op">(</span> <span class="va">iterators</span> <span class="op">)</span></span>
<span><span class="kw">library</span><span class="op">(</span> <span class="va">parallel</span> <span class="op">)</span></span>
<span><span class="kw">library</span><span class="op">(</span> <span class="va">doParallel</span> <span class="op">)</span></span>
<span></span>
<span>   <span class="co"># Get the vector size and nThreads from the command line</span></span>
<span></span>
<span><span class="va">args</span> <span class="op">&lt;-</span> <span class="fu">commandArgs</span><span class="op">(</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="kw">if</span><span class="op">(</span> <span class="fu">length</span><span class="op">(</span> <span class="va">args</span> <span class="op">)</span> <span class="op">==</span> <span class="fl">2</span> <span class="op">)</span> <span class="op">{</span></span>
<span>   <span class="va">n</span> <span class="op">&lt;-</span> <span class="fu">as.integer</span><span class="op">(</span> <span class="va">args</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">)</span></span>
<span>   <span class="va">nThreads</span> <span class="op">&lt;-</span> <span class="fu">as.integer</span><span class="op">(</span> <span class="va">args</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">)</span></span>
<span><span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>   <span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">100000</span></span>
<span>   <span class="va">nThreads</span> <span class="op">&lt;-</span> <span class="fu">detectCores</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span>   <span class="co"># Initialize the vectors and our virtual cluster</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu">vector</span><span class="op">(</span> <span class="st">"double"</span>, <span class="va">n</span> <span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">vector</span><span class="op">(</span> <span class="st">"double"</span>, <span class="va">n</span> <span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span><span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span> <span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>   <span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">as.double</span><span class="op">(</span><span class="va">i</span><span class="op">)</span></span>
<span>   <span class="va">y</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">as.double</span><span class="op">(</span><span class="fl">3</span><span class="op">*</span><span class="va">i</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">cl</span> <span class="op">&lt;-</span> <span class="fu">makeCluster</span><span class="op">(</span> <span class="va">nThreads</span> <span class="op">)</span></span>
<span><span class="fu">registerDoParallel</span><span class="op">(</span> <span class="va">cl</span>, <span class="va">nThreads</span> <span class="op">)</span></span>
<span></span>
<span>   <span class="co"># Time the multi-threaded dot product foreach loop</span></span>
<span>   <span class="co">#   This returns a vector of size 'n' that will need to be summed</span></span>
<span>   <span class="co">#   so it is very inefficient.</span></span>
<span></span>
<span><span class="va">dummy</span> <span class="op">&lt;-</span> <span class="fu">matrix</span><span class="op">(</span> <span class="fl">1</span><span class="op">:</span><span class="fl">125000000</span> <span class="op">)</span>       <span class="co"># Clear the cache buffers before timing</span></span>
<span></span>
<span><span class="va">t_start</span> <span class="op">&lt;-</span> <span class="fu">proc.time</span><span class="op">(</span><span class="op">)</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span></span>
<span><span class="co">#dot_product_vector &lt;- foreach( i = 1:n, .combine = c, mc.preschedule = TRUE ) %dopar% {</span></span>
<span><span class="va">dot_product_vector</span> <span class="op">&lt;-</span> <span class="fu">foreach</span><span class="op">(</span> i <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="va">n</span>, .combine <span class="op">=</span> <span class="va">c</span> <span class="op">)</span> <span class="op">%dopar%</span> <span class="op">{</span></span>
<span></span>
<span>   <span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">*</span> <span class="va">y</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span></span>
<span><span class="op">}</span></span>
<span><span class="va">dot_product</span> <span class="op">&lt;-</span> <span class="fu">sum</span><span class="op">(</span> <span class="va">dot_product_vector</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">t_end</span> <span class="op">&lt;-</span> <span class="fu">proc.time</span><span class="op">(</span><span class="op">)</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="fu">sprintf</span><span class="op">(</span><span class="st">"dopar dot product took %6.3f seconds"</span>, <span class="va">t_end</span><span class="op">-</span><span class="va">t_start</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="fu">sprintf</span><span class="op">(</span><span class="st">"dot_product = %.6e on %i threads for vector size %i"</span>, <span class="va">dot_product</span>, <span class="va">nThreads</span>, <span class="va">n</span> <span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span>   <span class="co"># Now let's try a more complex but more efficient method where</span></span>
<span>   <span class="co">#    we manually divide the work between the threads.</span></span>
<span></span>
<span><span class="va">dummy</span> <span class="op">&lt;-</span> <span class="fu">matrix</span><span class="op">(</span> <span class="fl">1</span><span class="op">:</span><span class="fl">125000000</span> <span class="op">)</span>       <span class="co"># Clear the cache buffers before timing</span></span>
<span></span>
<span><span class="va">t_start</span> <span class="op">&lt;-</span> <span class="fu">proc.time</span><span class="op">(</span><span class="op">)</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span></span>
<span><span class="va">dot_product_vector</span> <span class="op">&lt;-</span> <span class="fu">foreach</span><span class="op">(</span> myThread <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="va">nThreads</span>, .combine <span class="op">=</span> <span class="va">c</span> <span class="op">)</span> <span class="op">%dopar%</span> <span class="op">{</span></span>
<span></span>
<span>   <span class="va">psum</span> <span class="op">&lt;-</span> <span class="fl">0.0</span></span>
<span>   <span class="kw">for</span><span class="op">(</span> <span class="va">j</span> <span class="kw">in</span> <span class="fu">seq</span><span class="op">(</span> <span class="va">myThread</span>, <span class="va">n</span>, <span class="va">nThreads</span> <span class="op">)</span> <span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="va">psum</span> <span class="op">&lt;-</span> <span class="va">psum</span> <span class="op">+</span> <span class="va">x</span><span class="op">[</span><span class="va">j</span><span class="op">]</span> <span class="op">*</span> <span class="va">y</span><span class="op">[</span><span class="va">j</span><span class="op">]</span></span>
<span>   <span class="op">}</span></span>
<span>   <span class="va">psum</span></span>
<span></span>
<span><span class="op">}</span></span>
<span><span class="va">dot_product</span> <span class="op">&lt;-</span> <span class="fu">sum</span><span class="op">(</span> <span class="va">dot_product_vector</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">t_end</span> <span class="op">&lt;-</span> <span class="fu">proc.time</span><span class="op">(</span><span class="op">)</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="fu">sprintf</span><span class="op">(</span><span class="st">"dopar dot product with nThreads workers took %6.3f seconds"</span>, <span class="va">t_end</span><span class="op">-</span><span class="va">t_start</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">print</span><span class="op">(</span><span class="fu">sprintf</span><span class="op">(</span><span class="st">"dot_product = %.6e on %i threads for vector size %i"</span>, <span class="va">dot_product</span>, <span class="va">nThreads</span>, <span class="va">n</span> <span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu">stopCluster</span><span class="op">(</span> <span class="va">cl</span> <span class="op">)</span></span></code></pre>
</div>
</div>
<div id="nav-tabpanel-1-C" class="tab-pane" aria-labelledby="nav-tab-1-C" role="tabpanel">
<p>Let’s go through the multi-threaded version of the dot product code
below to illustrate the changes that had to be made to the code to
parallelize it. In C/C++ we need a line <strong>#include
&lt;omp.h&gt;</strong> to bring the OpenMP headers, then the code needs
to be compiled with the <strong>-fopenmp</strong> flag for
<strong>gcc</strong> or the <strong>-qopenmp</strong> flag for
<strong>icc</strong>.</p>
<p>When we run the code we will want to set the number of threads for it
to use. In the code below, this is being set internally using the number
of threads passed in as a command line argument. This is used to set the
number of threads using the <strong>omp_set_num_threads()</strong>
function in C/C++. The other method of setting the number of threads is
to use the environmental variable <strong>OMP_NUM_THREADS</strong> for
C/C++/Fortran. For example, in your job script you can have a line
<strong>export OMP_NUM_THREADS=4</strong> to tell the program to use 4
threads.</p>
<p>Right before the loop we must tell the compiler to parallelize the
loop using a <strong>#pragma omp parallel for</strong> statement, plus
we need to indicate that there is a summation reduction of
<strong>dprod</strong> taking place where the partial sums calculated by
each thread get globally summed at the end. Then the for loop range is
changed so that each thread has a different range for the elements of
the loop that each thread is responsible for.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">C<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode c" tabindex="0"><code class="sourceCode c"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co">// Dot product in C using OpenMP</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="co">// USAGE:  dot_product_openmp 4   to run with 4 cores</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;stdlib.h&gt;</span></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;time.h&gt;</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;sys/time.h&gt;</span></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;omp.h&gt;</span></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a><span class="dt">void</span> main <span class="op">(</span><span class="dt">int</span> argc<span class="op">,</span> <span class="dt">char</span> <span class="op">**</span>argv<span class="op">)</span></span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>   <span class="dt">int</span> i<span class="op">,</span> N<span class="op">;</span></span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>   <span class="dt">double</span> dprod<span class="op">,</span> <span class="op">*</span>X<span class="op">,</span> <span class="op">*</span>Y<span class="op">;</span></span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>   <span class="dt">double</span> t_elapsed<span class="op">;</span></span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a>   <span class="kw">struct</span> timespec ts<span class="op">,</span> tf<span class="op">;</span></span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a>      <span class="co">// Get the number of threads from the command line</span></span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a>   <span class="dt">char</span> <span class="op">*</span>a <span class="op">=</span> argv<span class="op">[</span><span class="dv">1</span><span class="op">];</span></span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a>   <span class="dt">int</span> nthreads <span class="op">=</span> atoi<span class="op">(</span> a <span class="op">);</span></span>
<span id="cb4-21"><a href="#cb4-21" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" tabindex="-1"></a>   N <span class="op">=</span> <span class="dv">100000000</span><span class="op">;</span></span>
<span id="cb4-23"><a href="#cb4-23" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" tabindex="-1"></a>      <span class="co">// Allocate space for the X and Y vectors</span></span>
<span id="cb4-25"><a href="#cb4-25" tabindex="-1"></a></span>
<span id="cb4-26"><a href="#cb4-26" tabindex="-1"></a>   X <span class="op">=</span> malloc<span class="op">(</span> N <span class="op">*</span> <span class="kw">sizeof</span><span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">);</span></span>
<span id="cb4-27"><a href="#cb4-27" tabindex="-1"></a>   Y <span class="op">=</span> malloc<span class="op">(</span> N <span class="op">*</span> <span class="kw">sizeof</span><span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">);</span></span>
<span id="cb4-28"><a href="#cb4-28" tabindex="-1"></a></span>
<span id="cb4-29"><a href="#cb4-29" tabindex="-1"></a>      <span class="co">// Initialize the X and Y vectors</span></span>
<span id="cb4-30"><a href="#cb4-30" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" tabindex="-1"></a>   <span class="cf">for</span><span class="op">(</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> N<span class="op">;</span> i<span class="op">++</span> <span class="op">)</span> <span class="op">{</span></span>
<span id="cb4-32"><a href="#cb4-32" tabindex="-1"></a>      X<span class="op">[</span>i<span class="op">]</span> <span class="op">=</span> <span class="op">(</span><span class="dt">double</span><span class="op">)</span> i<span class="op">;</span></span>
<span id="cb4-33"><a href="#cb4-33" tabindex="-1"></a>      Y<span class="op">[</span>i<span class="op">]</span> <span class="op">=</span> <span class="op">(</span><span class="dt">double</span><span class="op">)</span> i<span class="op">;</span></span>
<span id="cb4-34"><a href="#cb4-34" tabindex="-1"></a>   <span class="op">}</span></span>
<span id="cb4-35"><a href="#cb4-35" tabindex="-1"></a></span>
<span id="cb4-36"><a href="#cb4-36" tabindex="-1"></a>      <span class="co">// Allocate and innitialize a dummy array to clear cache</span></span>
<span id="cb4-37"><a href="#cb4-37" tabindex="-1"></a></span>
<span id="cb4-38"><a href="#cb4-38" tabindex="-1"></a>   <span class="dt">double</span> <span class="op">*</span>dummy <span class="op">=</span> malloc<span class="op">(</span> <span class="dv">125000000</span> <span class="op">*</span> <span class="kw">sizeof</span><span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">);</span></span>
<span id="cb4-39"><a href="#cb4-39" tabindex="-1"></a>   <span class="cf">for</span><span class="op">(</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> <span class="dv">125000000</span><span class="op">;</span> i<span class="op">++</span> <span class="op">)</span> <span class="op">{</span> dummy<span class="op">[</span>i<span class="op">]</span> <span class="op">=</span> <span class="fl">0.0</span><span class="op">;</span> <span class="op">}</span></span>
<span id="cb4-40"><a href="#cb4-40" tabindex="-1"></a></span>
<span id="cb4-41"><a href="#cb4-41" tabindex="-1"></a></span>
<span id="cb4-42"><a href="#cb4-42" tabindex="-1"></a>      <span class="co">// Now we start the timer and do our calculation</span></span>
<span id="cb4-43"><a href="#cb4-43" tabindex="-1"></a></span>
<span id="cb4-44"><a href="#cb4-44" tabindex="-1"></a>   clock_gettime<span class="op">(</span>CLOCK_REALTIME<span class="op">,</span> <span class="op">&amp;</span>ts<span class="op">);</span></span>
<span id="cb4-45"><a href="#cb4-45" tabindex="-1"></a></span>
<span id="cb4-46"><a href="#cb4-46" tabindex="-1"></a>   omp_set_num_threads<span class="op">(</span> nthreads <span class="op">);</span></span>
<span id="cb4-47"><a href="#cb4-47" tabindex="-1"></a></span>
<span id="cb4-48"><a href="#cb4-48" tabindex="-1"></a>   dprod <span class="op">=</span> <span class="fl">0.0</span><span class="op">;</span></span>
<span id="cb4-49"><a href="#cb4-49" tabindex="-1"></a><span class="pp">#pragma omp parallel for reduction( +:dprod)</span></span>
<span id="cb4-50"><a href="#cb4-50" tabindex="-1"></a>   <span class="cf">for</span><span class="op">(</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> N<span class="op">;</span> i<span class="op">++</span> <span class="op">)</span> <span class="op">{</span></span>
<span id="cb4-51"><a href="#cb4-51" tabindex="-1"></a>      dprod <span class="op">+=</span> X<span class="op">[</span>i<span class="op">]</span> <span class="op">*</span> Y<span class="op">[</span>i<span class="op">];</span></span>
<span id="cb4-52"><a href="#cb4-52" tabindex="-1"></a>   <span class="op">}</span></span>
<span id="cb4-53"><a href="#cb4-53" tabindex="-1"></a></span>
<span id="cb4-54"><a href="#cb4-54" tabindex="-1"></a>   clock_gettime<span class="op">(</span>CLOCK_REALTIME<span class="op">,</span> <span class="op">&amp;</span>tf<span class="op">);</span></span>
<span id="cb4-55"><a href="#cb4-55" tabindex="-1"></a>   t_elapsed <span class="op">=</span>  <span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">(</span> tf<span class="op">.</span>tv_sec <span class="op">-</span> ts<span class="op">.</span>tv_sec <span class="op">);</span></span>
<span id="cb4-56"><a href="#cb4-56" tabindex="-1"></a>   t_elapsed <span class="op">+=</span> <span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">(</span>tf<span class="op">.</span>tv_nsec <span class="op">-</span> ts<span class="op">.</span>tv_nsec<span class="op">)</span> <span class="op">*</span> <span class="fl">1e-9</span><span class="op">;</span></span>
<span id="cb4-57"><a href="#cb4-57" tabindex="-1"></a></span>
<span id="cb4-58"><a href="#cb4-58" tabindex="-1"></a>   printf<span class="op">(</span><span class="st">"dot product = </span><span class="sc">%e</span><span class="st"> on </span><span class="sc">%d</span><span class="st"> threads took </span><span class="sc">%lf</span><span class="st"> seconds</span><span class="sc">\n</span><span class="st">"</span><span class="op">,</span> dprod<span class="op">,</span> nthreads<span class="op">,</span> t_elapsed <span class="op">);</span></span>
<span id="cb4-59"><a href="#cb4-59" tabindex="-1"></a>   printf<span class="op">(</span><span class="st">"</span><span class="sc">%lf</span><span class="st"> Gflops (billion floating-point operations per second)</span><span class="sc">\n</span><span class="st">"</span><span class="op">,</span></span>
<span id="cb4-60"><a href="#cb4-60" tabindex="-1"></a>          <span class="fl">2.0</span><span class="op">*</span>N<span class="op">*</span><span class="fl">1.0e-9</span> <span class="op">/</span> t_elapsed<span class="op">);</span></span>
<span id="cb4-61"><a href="#cb4-61" tabindex="-1"></a>   printf<span class="op">(</span> <span class="st">"</span><span class="sc">%lf</span><span class="st"> GB memory used</span><span class="sc">\n</span><span class="st">"</span><span class="op">,</span> <span class="fl">2.0</span><span class="op">*</span>N<span class="op">*</span><span class="fl">8.0</span><span class="op">/</span><span class="fl">1.0e9</span><span class="op">);</span></span>
<span id="cb4-62"><a href="#cb4-62" tabindex="-1"></a><span class="op">}</span></span></code></pre>
</div>
</div>
<div id="nav-tabpanel-1-Fortran" class="tab-pane" aria-labelledby="nav-tab-1-Fortran" role="tabpanel">
<p>Let’s go through the multi-threaded version of the dot product code
below to illustrate the changes that had to be made to the code to
parallelize it. In Fortran we need a line <strong>USE omp_lib</strong>
to bring the OpenMP functions, then the code needs to be compiled with
the <strong>-fopenmp</strong> flag for <strong>gfortran</strong> or the
<strong>-qopenmp</strong> flag for <strong>ifort</strong>.</p>
<p>When we run the code we will want to set the number of threads for it
to use. In the code below, this is being set internally using the number
of threads passed in as a command line argument. This is used to set the
number of threads using the <strong>OMP_SET_NUM_THREADS()</strong>
subroutine in Fortran. The other method of setting the number of threads
is to use the environmental variable <strong>OMP_NUM_THREADS</strong>
for C/C++/Fortran. For example, in your job script you can have a line
<strong>export OMP_NUM_THREADS=4</strong> to tell the program to use 4
threads.</p>
<p>Right before the loop we must tell the compiler to parallelize the
loop using a <strong>!$OMP PARALLEL DO</strong> statement, plus we need
to indicate that there is a summation reduction of
<strong>dprod</strong> taking place where the partial sums calculated by
each thread get globally summed at the end. Then the <strong>DO</strong>
loop range is changed so that each thread has a different range for the
elements of the loop that each thread is responsible for.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">FORTRAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode fortran" tabindex="0"><code class="sourceCode fortranfixed"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co">! Dot product in Fortran using OpenMP</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="kw">PROGRAM</span> dot_product_fortran_openmp</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>   <span class="kw">USE</span> omp_lib</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>   <span class="dt">INTEGER</span> <span class="dt">::</span> i, n, nthreads</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>   <span class="dt">CHARACTER(100)</span> <span class="dt">::</span> arg1</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>   <span class="dt">DOUBLE PRECISION</span> <span class="dt">::</span> <span class="bu">dprod</span>, t_start, t_elapsed</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>   <span class="dt">DOUBLE PRECISION</span>, <span class="dt">ALLOCATABLE</span> <span class="dt">::</span> x(:), y(:)</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>   <span class="dt">DOUBLE PRECISION</span>, <span class="dt">ALLOCATABLE</span> <span class="dt">::</span> dummy(:)</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>      <span class="co">! Dynamically allocate large arrays to avoid overflowing the stack</span></span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a>   n <span class="kw">=</span> <span class="dv">100000000</span></span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a>   <span class="kw">ALLOCATE</span>( x(n) )</span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a>   <span class="kw">ALLOCATE</span>( y(n) )</span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a>   <span class="kw">ALLOCATE</span>( dummy(<span class="dv">125000000</span>) )</span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a>      <span class="co">! Set the number of threads from the command line argument</span></span>
<span id="cb5-21"><a href="#cb5-21" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" tabindex="-1"></a>   <span class="kw">CALL</span> GET_COMMAND_ARGUMENT( <span class="dv">1</span>, arg1 )</span>
<span id="cb5-23"><a href="#cb5-23" tabindex="-1"></a>   <span class="fu">READ(</span> arg1, <span class="fu">*)</span> nthreads</span>
<span id="cb5-24"><a href="#cb5-24" tabindex="-1"></a>   <span class="kw">CALL</span> OMP_SET_NUM_THREADS( nthreads )   <span class="co">! Set the number of threads</span></span>
<span id="cb5-25"><a href="#cb5-25" tabindex="-1"></a></span>
<span id="cb5-26"><a href="#cb5-26" tabindex="-1"></a>      <span class="co">! Initialize the vectors</span></span>
<span id="cb5-27"><a href="#cb5-27" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" tabindex="-1"></a>   <span class="kw">DO</span> i <span class="kw">=</span> <span class="dv">1</span>, n</span>
<span id="cb5-29"><a href="#cb5-29" tabindex="-1"></a>      x(i) <span class="kw">=</span> i</span>
<span id="cb5-30"><a href="#cb5-30" tabindex="-1"></a>      y(i) <span class="kw">=</span> i</span>
<span id="cb5-31"><a href="#cb5-31" tabindex="-1"></a>   <span class="kw">END DO</span></span>
<span id="cb5-32"><a href="#cb5-32" tabindex="-1"></a></span>
<span id="cb5-33"><a href="#cb5-33" tabindex="-1"></a>      <span class="co">! Initialize a dummy array to clear cache</span></span>
<span id="cb5-34"><a href="#cb5-34" tabindex="-1"></a></span>
<span id="cb5-35"><a href="#cb5-35" tabindex="-1"></a>   <span class="kw">DO</span> i <span class="kw">=</span> <span class="dv">1</span>, <span class="dv">125000000</span></span>
<span id="cb5-36"><a href="#cb5-36" tabindex="-1"></a>      dummy(i) <span class="kw">=</span> <span class="fl">0.0</span></span>
<span id="cb5-37"><a href="#cb5-37" tabindex="-1"></a>   <span class="kw">END DO</span></span>
<span id="cb5-38"><a href="#cb5-38" tabindex="-1"></a></span>
<span id="cb5-39"><a href="#cb5-39" tabindex="-1"></a>      <span class="co">! Now start the timer and do the calculations</span></span>
<span id="cb5-40"><a href="#cb5-40" tabindex="-1"></a></span>
<span id="cb5-41"><a href="#cb5-41" tabindex="-1"></a>t_start <span class="kw">=</span> OMP_GET_WTIME()</span>
<span id="cb5-42"><a href="#cb5-42" tabindex="-1"></a></span>
<span id="cb5-43"><a href="#cb5-43" tabindex="-1"></a>   <span class="bu">dprod</span> <span class="kw">=</span> <span class="fl">0.0</span></span>
<span id="cb5-44"><a href="#cb5-44" tabindex="-1"></a><span class="co">!$OMP PARALLEL DO REDUCTION(+:dprod)</span></span>
<span id="cb5-45"><a href="#cb5-45" tabindex="-1"></a>   <span class="kw">DO</span> i <span class="kw">=</span> <span class="dv">1</span>, n</span>
<span id="cb5-46"><a href="#cb5-46" tabindex="-1"></a>      <span class="bu">dprod</span> <span class="kw">=</span> <span class="bu">dprod</span> <span class="kw">+</span> x(i) <span class="kw">*</span> y(i)</span>
<span id="cb5-47"><a href="#cb5-47" tabindex="-1"></a>   <span class="kw">END DO</span></span>
<span id="cb5-48"><a href="#cb5-48" tabindex="-1"></a></span>
<span id="cb5-49"><a href="#cb5-49" tabindex="-1"></a>t_elapsed <span class="kw">=</span> OMP_GET_WTIME() <span class="kw">-</span> t_start</span>
<span id="cb5-50"><a href="#cb5-50" tabindex="-1"></a></span>
<span id="cb5-51"><a href="#cb5-51" tabindex="-1"></a>   <span class="fu">WRITE(*</span>,<span class="fu">*)</span> <span class="st">"dot product = "</span>, <span class="bu">dprod</span>, <span class="st">" took "</span>, <span class="kw">&amp;</span></span>
<span id="cb5-52"><a href="#cb5-52" tabindex="-1"></a>      t_elapsed, <span class="st">" seconds  on "</span>, nthreads, <span class="st">" threads"</span></span>
<span id="cb5-53"><a href="#cb5-53" tabindex="-1"></a></span>
<span id="cb5-54"><a href="#cb5-54" tabindex="-1"></a><span class="kw">END PROGRAM</span> dot_product_fortran_openmp</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-1-Matlab" class="tab-pane" aria-labelledby="nav-tab-1-Matlab" role="tabpanel">
<p>Not implemented yet.</p>
</div>
</div>
</div>
<p>So parallelizing this program really only requires us to change
around 11 lines of code, and from that we get the benefit of being able
to apply much greater computing power. In Python for example we do have
some control over how the parallelization works internally. Using
<strong>p.range(N)</strong> in our for loop will use static scheduling
where each thread is responsible for a pre-determined set of indices at
regular intervals as in the figure above. If instead we use
<strong>p.xrange(N)</strong> then dynamic scheduling will be used where
each index will be assigned to the next available thread. This can be
very useful if the amount of work in each pass through the loop varies
greatly. Dynamic scheduling can produce much more efficient results in
cases where there is a great load imbalance.</p>
</div>
<div class="section level3">
<h3 id="understanding-what-can-cause-inefficient-scaling">Understanding what can cause inefficient scaling<a class="anchor" aria-label="anchor" href="#understanding-what-can-cause-inefficient-scaling"></a>
</h3>
<p>A scaling study is designed to expose inefficiencies in a parallel
code and to determine how many cores to use for a given problem size.
That last part is important to understand. If there is too little work
in each iteration of a loop, then loop overhead can limit scaling.
Calculations on larger data sets usually scale better.</p>
<p>A loop may be very scalable in itself, but if there is too much time
spent in the scalar part of the code like initialization, doing the
reductions, or doing input at the beginning and output at the end, then
the entire code may not scale well. Load imbalance can also be a
problem. If the time it takes to pass through a loop varies, then using
dynamic scheduling is very important.</p>
<p>Shared arrays are an extremely important part of multi-threaded
packages. Since they do involve the copy-on-write mechanism, they can
lead to inefficiency in the loop. In general this is minimal but
something to be aware of.</p>
<p>Multi-threading packages like <strong>OpenMP</strong> and
<strong>pymp</strong> provide mechanisms that force loops in the
algorithm out of multi-threaded operation and back into single-threaded
operation. This always leads to terrible scaling and should almost never
be used.</p>
<div id="scaling-study-of-the-multi-threaded-dot-product-code" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="scaling-study-of-the-multi-threaded-dot-product-code" class="callout-inner">
<h3 class="callout-title">Scaling Study of the Multi-Threaded Dot
Product Code</h3>
<div class="callout-content">
<div class="tabs">
<nav><div id="nav-tab-2" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-2-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Python" type="button" role="tab" aria-controls="nav-tabpanel-2-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-2-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-R" type="button" role="tab" aria-controls="nav-tabpanel-2-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-C" type="button" role="tab" aria-controls="nav-tabpanel-2-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-2-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-2-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-2" class="tab-content">
<div id="nav-tabpanel-2-Python" class="tab-pane show active" aria-labelledby="nav-tab-2-Python" role="tabpanel">
<p>Measure the execution time for the
<strong>dot_product_threaded.py</strong> code for 1, 4, 8, and 16 cores.
If possible, use a job script requesting 16 cores and do all runs in the
same job. You can look at the job scripts like
<strong>sb.ddot_py</strong> in the <strong>code</strong> directory as an
example but your job script will probably be different. Then calculate
the speedup compared to the scalar (single-core) run to see how close to
ideal the performance is.</p>
</div>
<div id="nav-tabpanel-2-R" class="tab-pane" aria-labelledby="nav-tab-2-R" role="tabpanel">
<p>Measure the performance of <strong>dot_product_threaded.R</strong>
and <strong>dot_product_threaded_dopar.R</strong> for a given number of
threads like 8 if you have that many cores available. You should be able
to run both in a few minutes using 100,000 elements.</p>
<p>If you have time, try running a scaling study using a job script
similar to <strong>sb.ddot_R</strong> in the <strong>code</strong>
directory. This will allow us to see how each code scales with the
number of cores used. Then calculate the speedup compared to the scalar
(single-core) run to see how close to ideal the performance is.</p>
</div>
<div id="nav-tabpanel-2-C" class="tab-pane" aria-labelledby="nav-tab-2-C" role="tabpanel">
<p>Measure the execution time for the
<strong>dot_product_c_openmp.c</strong> code for 1, 4, 8, and 16 cores.
If possible, use a job script requesting 16 cores and do all runs in the
same job. You can look at the job scripts like
<strong>sb.ddot_c</strong> in the <strong>code</strong> directory as an
example but your job script will probably be different. Then calculate
the speedup compared to the scalar (single-core) run to see how close to
ideal the performance is.</p>
</div>
<div id="nav-tabpanel-2-Fortran" class="tab-pane" aria-labelledby="nav-tab-2-Fortran" role="tabpanel">
<p>Measure the execution time for the
<strong>dot_product_fortran_openmp.f90</strong> code for 1, 4, 8, and 16
cores. If possible, use a job script requesting 16 cores and do all runs
in the same job. You can look at the job scripts like
<strong>sb.ddot_c</strong> in the <strong>code</strong> directory as an
example but your job script will probably be different. Then calculate
the speedup compared to the scalar (single-core) run to see how close to
ideal the performance is.</p>
</div>
<div id="nav-tabpanel-2-Matlab" class="tab-pane" aria-labelledby="nav-tab-2-Matlab" role="tabpanel">
<p>Not implemented yet.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<div class="tabs">
<nav><div id="nav-tab-3" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-3-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-Python" type="button" role="tab" aria-controls="nav-tabpanel-3-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-3-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-R" type="button" role="tab" aria-controls="nav-tabpanel-3-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-C" type="button" role="tab" aria-controls="nav-tabpanel-3-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-3-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-3-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-3" class="tab-content">
<div id="nav-tabpanel-3-Python" class="tab-pane show active" aria-labelledby="nav-tab-3-Python" role="tabpanel">
<p>For this very simple problem, each thread can do its computations
totally independently. There is only a global sum of all the partial
sums at the end, so we would expect the scaling to be close to ideal. In
my measurements, I saw a 3.1x speedup on 4 cores, a 5.3x speedup on 8
cores, and a 7.8x speedup on 16 cores. For this problem, there just are
so few computations being done in each loop iteration, only 2
floating-point operations, that the loop overhead is preventing better
scaling. A C/C++ version of this code using OpenMP for multi-threading
runs 170 times faster because it is a compiled language, but likewise
does not scale well due to the few computations being done in each pass
through the loop.</p>
</div>
<div id="nav-tabpanel-3-R" class="tab-pane" aria-labelledby="nav-tab-3-R" role="tabpanel">
<p>For 8 cores on a modern Intel processor I get 4.7 seconds for the
first loop and 33 ms for the second loop in
<strong>dot_product_threaded.R</strong>. Manually dividing the workload
between our processes greatly reduces the overhead compared to letting R
handle it. The extra programming we did is an absolute necessity in this
case since we don’t have much work in the body of the loop. It may be
less necessary in more realistic applications but this illustrates that
the difference in overhead is enormous.</p>
<p>For the <strong>dot_product_threaded_dopar.R</strong> code, I measure
18.6 seconds for the first loop and 70 ms for the second, so again there
is an enormous saving in overhead by manually dividing the work among
the threads to limit the overhead from R scheduling the iterations
across the workers.</p>
<p>If you have time you can try increasing the workload greatly. Comment
out the first loop in each code since that would take too long, then
increase the number of elements by 100 to 10,000,000. My scaling studies
now show <strong>dot_product_threaded.R</strong> getting a 3.65 times
speedup on 4 cores, a 6.5 times speedup on 8 cores, and a 9.3 times
speedup on 16 cores. These are now very reasonable. However, for
<strong>dot_product_threaded_dopar.R</strong> I still measure over a
second for a single core and the time increases as I add more cores, so
the overhead for this method is still dominating the computations inside
the loop. You can also measure the performance difference using the
matrix multiplication codes if you wish.</p>
<p>The conclusion from all this is that while using a
<strong>foreach</strong> is simple and clean code, the
<strong>clusterApply()</strong> approach or <strong>foreach</strong>
over the number of threads with manually splitting the iterations
internally provides much greater performance. If each iteration is doing
enough calculations then the overhead may not matter.</p>
</div>
<div id="nav-tabpanel-3-C" class="tab-pane" aria-labelledby="nav-tab-3-C" role="tabpanel">
<p>For this very simple problem, each thread can do its computations
totally independently. There is only a global sum of all the partial
sums at the end, so we would expect the scaling to be close to ideal. In
my measurements, I saw a 2.3x speedup on 4 cores, a 3.3x speedup on 8
cores, and a 3.9x speedup on 16 cores. For this problem, there just are
so few computations being done in each loop iteration, only 2
floating-point operations, that the loop overhead is preventing better
scaling.</p>
</div>
<div id="nav-tabpanel-3-Fortran" class="tab-pane" aria-labelledby="nav-tab-3-Fortran" role="tabpanel">
<p>For this very simple problem, each thread can do its computations
totally independently. There is only a global sum of all the partial
sums at the end, so we would expect the scaling to be close to ideal. In
my measurements, I saw a 3.5x speedup on 4 cores, a 6.6x speedup on 8
cores.</p>
</div>
<div id="nav-tabpanel-3-Matlab" class="tab-pane" aria-labelledby="nav-tab-3-Matlab" role="tabpanel">
<p>Not implemented yet.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Multi-threaded computing is powerful and fairly easy to use but only
works on one compute node.</li>
<li>Understand key factors that can limit the efficient scaling of
multi-threaded programs.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="links-for-additional-information">Links for additional information<a class="anchor" aria-label="anchor" href="#links-for-additional-information"></a>
</h3>
<ul>
<li><a href="https://hpc-tutorials.llnl.gov/openmp/" class="external-link">LLNL OpenMP
tutorial</a></li>
<li><a href="https://github.com/classner/pymp" class="external-link">github pymp</a></li>
</ul>
</div></section><section id="aio-message-passing"><p>Content from <a href="message-passing.html">Message-Passing Programs</a></p>
<hr>
<p>Last updated on 2025-09-17 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/message-passing.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 30 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is the distributed-memory programming model?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Learn about message-passing in distributed-memory computing.</li>
<li>Understand the strengths and limitations of this approach.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="the-message-passing-paradigm">The Message-Passing Paradigm<a class="anchor" aria-label="anchor" href="#the-message-passing-paradigm"></a>
</h2>
<hr class="half-width">
<p>While multi-threaded parallelization is very efficient when running
on a single compute node, at times we need to apply even more compute
power to a single job. Since this will involve more than one compute
node, we will need a separate but identical program running on each
computer which leads us to a new programming paradigm. This is known by
various descriptive names including MPMD or Multiple Program Multiple
Data, but is more commonly known as message-passing which is how data is
exchanged between multiple identical copies of a program that each
operate on different data. There is a common syntax used which is
<strong>MPI</strong> or the <strong>Message-Passing Initiative</strong>
standard. C/C++ and Fortran have several MPI implementations including
free <strong>OpenMPI</strong> and <strong>MPICH</strong> libraries and
commercial <strong>Intel MPI</strong>, while Python uses
<strong>mpi4py</strong> which implements a stripped down version of the
MPI standard. R does not have any message-passing implementation though
there was work on <strong>Rmpi</strong> in the past that was never
completed.</p>
<p>The diagram below shows what a distributed-memory dot product looks
like on a multi-node computer in contrast to the shared-memory program
in the diagram in the previous chapter. In this case, our job is running
on 4 cores on node 1 and 4 cores on node 2. Distributed-memory means
that there will be 8 identical programs running, with 4 on each node,
but each will have responsibility for doing one eighth of the
calculations. We will need to use the <strong>mpirun</strong> or
<strong>mpiexec</strong> commands to launch eight copies of the program
on the two nodes then start them running. The jobs will handshake then
decide which part of the data each is responsible for. After all nodes
have calculated their partial sums, they will be globally summed across
all 8 tasks using the network if needed then the program with lowest
rank will print out the results.</p>
<div class="tabs">
<nav><div id="nav-tab-1" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-1-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Python" type="button" role="tab" aria-controls="nav-tabpanel-1-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-1-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-R" type="button" role="tab" aria-controls="nav-tabpanel-1-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-C" type="button" role="tab" aria-controls="nav-tabpanel-1-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-1-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-1-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-1" class="tab-content">
<div id="nav-tabpanel-1-Python" class="tab-pane show active" aria-labelledby="nav-tab-1-Python" role="tabpanel">
<figure><img src="../fig/distributed-memory-dot-product-0.jpg" alt="Distributed-memory dot product showing the layout of both vectors on both computers" class="figure mx-auto d-block"><div class="figcaption">Diagram of a distributed-memory multi-node dot
product on two computers</div>
</figure>
</div>
<div id="nav-tabpanel-1-R" class="tab-pane" aria-labelledby="nav-tab-1-R" role="tabpanel">
<figure><img src="../fig/distributed-memory-dot-product-1.jpg" alt="Distributed-memory dot product showing the layout of both vectors on both computers" class="figure mx-auto d-block"><div class="figcaption">Diagram of a distributed-memory multi-node dot
product on two computers</div>
</figure>
</div>
<div id="nav-tabpanel-1-C" class="tab-pane" aria-labelledby="nav-tab-1-C" role="tabpanel">
<figure><img src="../fig/distributed-memory-dot-product-0.jpg" alt="Distributed-memory dot product showing the layout of both vectors on both computers" class="figure mx-auto d-block"><div class="figcaption">Diagram of a distributed-memory multi-node dot
product on two computers</div>
</figure>
</div>
<div id="nav-tabpanel-1-Fortran" class="tab-pane" aria-labelledby="nav-tab-1-Fortran" role="tabpanel">
<figure><img src="../fig/distributed-memory-dot-product-1.jpg" alt="Distributed-memory dot product showing the layout of both vectors on both computers" class="figure mx-auto d-block"><div class="figcaption">Diagram of a distributed-memory multi-node dot
product on two computers</div>
</figure>
</div>
<div id="nav-tabpanel-1-Matlab" class="tab-pane" aria-labelledby="nav-tab-1-Matlab" role="tabpanel">
<figure><img src="../fig/distributed-memory-dot-product-1.jpg" alt="Distributed-memory dot product showing the layout of both vectors on both computers" class="figure mx-auto d-block"><div class="figcaption">Diagram of a distributed-memory multi-node dot
product on two computers</div>
</figure>
</div>
</div>
</div>
<p>In parallel computing, the programmer must decide how to divide the
data between the processes. In this case, we could have just as easily
decided that rank 0 is responsible for the first 1/8<sup>th</sup> of the
elements, rank 1 for the next 1/8<sup>th</sup>, etc. If we were reading
in the data and distributing it in blocks to each other process then
this would be better since we wouldn’t have to move the data around
before sending out each block of data. In this case for the dot product,
it simply doesn’t matter. Regardless of how the work is divided, it
sometimes does not come out evenly so you do have to make sure that all
work is accounted for even if some processes have to do slightly
more.</p>
<div class="section level3">
<h3 id="the-message-passing-dot-product-code">The message-passing dot product code<a class="anchor" aria-label="anchor" href="#the-message-passing-dot-product-code"></a>
</h3>
<p>Let’s look at how the message-passing version of the code differs
from the original scalar version and contrast it to the multi-threaded
version. If you are using Python, you first need to <strong>pip install
mpi4py</strong> into your virtual environment then you can
<strong>import mpi4py as MPI</strong> to bring the package into your
code. The compiled languages C/C++/Fortran need an
<strong>#include&lt;mpi.h&gt;</strong> to pull in the headers for MPI,
then you compile with <strong>mpicc</strong> or
<strong>mpifort</strong>.</p>
<p>Since a message-passing job is many identical copies of the same
program working on different data, we need to use the <strong>mpirun -np
4</strong> command for example to launch 4 copies of the code. If you
are running the job using a scheduler like Slur, this will run on the 4
cores that you requested. If you are not running through using a
scheduler, you can specify different compute node names such as
<strong>mpirun –host node1,node1,node2,node2</strong> to run on 2 cores
of node1 and 2 cores of node2. You can also specify a hostfile and
number of slots using <strong>mpirun –hostfile hostfilename</strong>
where the host file contains lines having the node name and number of
slots on that node (node1 slots=2).</p>
<p>All message-passing programs start with an initialization routine
which for Python is the <strong>comm = MPI.COMM_WORLD</strong> statement
and C/C++/Fortran is <strong>MPI_COMM_WORLD</strong>. This says that our
communicator includes all ranks available (COMM_WORLD), and it connects
with all the other programs. The other two lines that are at the start
of every message-passing program are functions to get the number of
ranks, the message-passing word for threads, and the rank for each
program which ranges from 0 to the number of ranks minus 1. This rank is
what the programmer uses to decide which data each copy of the program
will work on, and is also used to identify which copy of the program to
pass messages to.</p>
<p>Each rank is responsible for doing the dot product on part of the
data, and the programmer must decide on how to divide this work up. For
this code, we are going to divide the work up in a similar way to how
the multi-threaded program worked, where the rank 0 is responsible for
indices 0, nranks, 2<em>nranks, 3</em>nranks, etc. The initialization of
the X and Y vectors shows how we are now just dealing with N_elements
each (N/nranks) but we still want the initialization to be the same so
we have to change that a bit.</p>
<p>We do a barrier command before starting the timer so that all the
ranks are synchronized. Normally it is good practice to avoid barriers
in codes, but in our case we are doing it so we get a more accurate
timing.</p>
<p>Each rank calculates a partial sum of the indices that it is
responsible for. Then all ranks must participate in a reduction to
globally sum the partial sums. Notice at the end that we only have the
lowest print its results. If we didn’t protect the print statements like
this, we would get <strong>nranks</strong> copies of each print
statement.</p>
<div class="tabs">
<nav><div id="nav-tab-2" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-2-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Python" type="button" role="tab" aria-controls="nav-tabpanel-2-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-2-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-R" type="button" role="tab" aria-controls="nav-tabpanel-2-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-C" type="button" role="tab" aria-controls="nav-tabpanel-2-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-2-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-2-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-2" class="tab-content">
<div id="nav-tabpanel-2-Python" class="tab-pane show active" aria-labelledby="nav-tab-2-Python" role="tabpanel">
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># Do the dot product between two vectors X and Y then print the result</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="co"># USAGE:  mpirun -np 4 python dot_product_message_passing.py       to run on 4 tasks</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="co"># pip install mpi4py      in your virtual environment before you run this code</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">import</span> sys</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="im">from</span> mpi4py <span class="im">import</span> MPI</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>   <span class="co"># Get my rank and the number of ranks - (MPI talks about ranks instead of threads)</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a>comm <span class="op">=</span> MPI.COMM_WORLD       <span class="co"># Handshake with other ranks</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>nranks <span class="op">=</span> comm.Get_size()    <span class="co"># The number of ranks (threads)</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>myrank <span class="op">=</span> comm.Get_rank()    <span class="co"># Which rank am I ( 0 .. nranks-1 )</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">100000000</span>      <span class="co"># Do a large enough test to reduce timing variance</span></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a>N_elements <span class="op">=</span> <span class="bu">int</span>( N<span class="op">/</span>nranks )</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a><span class="cf">if</span> ( N <span class="op">%</span> nranks <span class="op">!=</span> <span class="dv">0</span> ):</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>   <span class="bu">print</span>(<span class="st">"Please use an even number of ranks"</span>)</span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a>   exit</span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a>x <span class="op">=</span> [ <span class="bu">float</span>( myrank <span class="op">+</span> i<span class="op">*</span>nranks ) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N_elements ) ]</span>
<span id="cb1-23"><a href="#cb1-23" tabindex="-1"></a>y <span class="op">=</span> [ <span class="bu">float</span>( myrank <span class="op">+</span> i<span class="op">*</span>nranks ) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N_elements ) ]</span>
<span id="cb1-24"><a href="#cb1-24" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" tabindex="-1"></a>   <span class="co"># Now initialize a very large dummy array to force X and Y out of all levels of cache</span></span>
<span id="cb1-26"><a href="#cb1-26" tabindex="-1"></a>   <span class="co">#    so that our times are for pulling elements up from main memory.</span></span>
<span id="cb1-27"><a href="#cb1-27" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" tabindex="-1"></a>dummy <span class="op">=</span> [ <span class="fl">0.0</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( <span class="dv">125000000</span> ) ]  <span class="co"># Initialize 1 GB of memory</span></span>
<span id="cb1-29"><a href="#cb1-29" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" tabindex="-1"></a>   <span class="co"># Now we start our timer and do our calculation using multiple threads</span></span>
<span id="cb1-31"><a href="#cb1-31" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" tabindex="-1"></a>comm.barrier()    <span class="co"># Sync all ranks before starting the timer</span></span>
<span id="cb1-33"><a href="#cb1-33" tabindex="-1"></a>t_start <span class="op">=</span> time.perf_counter()</span>
<span id="cb1-34"><a href="#cb1-34" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" tabindex="-1"></a>psum <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb1-36"><a href="#cb1-36" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N_elements ):</span>
<span id="cb1-37"><a href="#cb1-37" tabindex="-1"></a>   psum <span class="op">+=</span> x[i] <span class="op">*</span> y[i]</span>
<span id="cb1-38"><a href="#cb1-38" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" tabindex="-1"></a>d_prod <span class="op">=</span> comm.<span class="bu">reduce</span>( psum, op<span class="op">=</span>MPI.SUM )</span>
<span id="cb1-40"><a href="#cb1-40" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" tabindex="-1"></a>t_elapsed <span class="op">=</span> time.perf_counter() <span class="op">-</span> t_start</span>
<span id="cb1-42"><a href="#cb1-42" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" tabindex="-1"></a>   <span class="co"># The calculation is done and timer stopped so print out the answer</span></span>
<span id="cb1-44"><a href="#cb1-44" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" tabindex="-1"></a><span class="cf">if</span> ( myrank <span class="op">==</span> <span class="dv">0</span> ):    <span class="co"># Only rank 0 will print results</span></span>
<span id="cb1-46"><a href="#cb1-46" tabindex="-1"></a>   <span class="bu">print</span>(<span class="st">'dot product = '</span>, d_prod, <span class="st">'took '</span>, t_elapsed, <span class="st">' seconds on '</span>, nranks, <span class="st">' ranks'</span> )<span class="op">;</span></span>
<span id="cb1-47"><a href="#cb1-47" tabindex="-1"></a>   <span class="bu">print</span>( <span class="fl">2.0</span><span class="op">*</span>N<span class="op">*</span><span class="fl">1.0e-9</span> <span class="op">/</span> t_elapsed, <span class="st">' Gflops (billion floating-point operations per second)'</span>)</span>
<span id="cb1-48"><a href="#cb1-48" tabindex="-1"></a>   <span class="bu">print</span>( <span class="fl">2.0</span><span class="op">*</span>N<span class="op">*</span><span class="fl">8.0</span><span class="op">/</span><span class="fl">1.0e9</span>, <span class="st">' GB memory used'</span> )</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-2-R" class="tab-pane" aria-labelledby="nav-tab-2-R" role="tabpanel">
<ul>
<li><a href="https://cran.r-project.org/web/packages/Rmpi/Rmpi.pdf" class="external-link">Rmpi
documentations</a></li>
</ul>
<p>The <strong>Rmpi</strong> package was developed about 20 years ago
but has been updated every few years to be compatible with current
versions of R and OpenMPI (except my tests failed with OpenMPI 5.0.3 so
I had to use an older OpenMPI 4.1.6 version). This package provides a
<strong>doMPI</strong> back end that can be easily slipped into a
program using <strong>foreach</strong> loops with
<strong>%dopar%</strong> allowing the code to run on cores on multiple
compute nodes. <strong>Rmpi</strong> also provides wrapped MPI commands
for programmers who wish to write explicit MPI programs in R.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Do the dot product between two vectors X and Y then print the result</span></span>
<span><span class="co"># USAGE:  mpirun -np 4 Rscript dot_product_message_passing.R 100000</span></span>
<span><span class="co">#    This will run 100,000 elements on 4 cores, possibly spread on multiple compute nodes</span></span>
<span><span class="co"># must install.packages("Rmpi") first</span></span>
<span></span>
<span><span class="kw">library</span><span class="op">(</span> <span class="va">Rmpi</span> <span class="op">)</span>     <span class="co"># This does the MPI_Init() behind the scenes</span></span>
<span></span>
<span>   <span class="co"># Get the vector size from the command line</span></span>
<span></span>
<span><span class="va">args</span> <span class="op">&lt;-</span> <span class="fu">commandArgs</span><span class="op">(</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="kw">if</span><span class="op">(</span> <span class="fu">length</span><span class="op">(</span> <span class="va">args</span> <span class="op">)</span> <span class="op">==</span> <span class="fl">1</span> <span class="op">)</span> <span class="op">{</span></span>
<span>   <span class="va">n</span> <span class="op">&lt;-</span> <span class="fu">as.integer</span><span class="op">(</span> <span class="va">args</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">)</span></span>
<span><span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>   <span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">100000</span></span>
<span><span class="op">}</span></span>
<span></span>
<span>   <span class="co"># Get my rank and the number of ranks - (MPI talks about ranks instead of threads)</span></span>
<span></span>
<span><span class="va">com</span> <span class="op">&lt;-</span> <span class="fl">0</span>     <span class="co"># MPI_COMM_WORLD or all ranks</span></span>
<span><span class="va">nRanks</span> <span class="op">&lt;-</span> <span class="fu">mpi.comm.size</span><span class="op">(</span> <span class="va">com</span> <span class="op">)</span>    <span class="co"># The number of ranks (threads)</span></span>
<span><span class="va">myRank</span> <span class="op">&lt;-</span> <span class="fu">mpi.comm.rank</span><span class="op">(</span> <span class="va">com</span> <span class="op">)</span>    <span class="co"># Which rank am I ( 1 .. nRanks )</span></span>
<span></span>
<span><span class="kw">if</span><span class="op">(</span> <span class="op">(</span><span class="va">n</span> <span class="op">%%</span> <span class="va">nRanks</span><span class="op">)</span> <span class="op">!=</span> <span class="fl">0</span> <span class="op">)</span> <span class="op">{</span></span>
<span>   <span class="fu">print</span><span class="op">(</span><span class="st">"Please ensure vector size is divisable by the number of ranks"</span><span class="op">)</span></span>
<span>   <span class="fu">quit</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="va">myElements</span> <span class="op">&lt;-</span> <span class="va">n</span> <span class="op">/</span> <span class="va">nRanks</span></span>
<span></span>
<span>   <span class="co"># Allocate space and initialize the reduced arrays for each rank</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu">vector</span><span class="op">(</span> <span class="st">"double"</span>, <span class="va">myElements</span> <span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">vector</span><span class="op">(</span> <span class="st">"double"</span>, <span class="va">myElements</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">j</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span><span class="kw">for</span><span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fu">seq</span><span class="op">(</span> <span class="va">myRank</span><span class="op">+</span><span class="fl">1</span>, <span class="va">n</span>, <span class="va">nRanks</span> <span class="op">)</span> <span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>   <span class="va">j</span> <span class="op">&lt;-</span> <span class="va">j</span> <span class="op">+</span> <span class="fl">1</span></span>
<span>   <span class="va">x</span><span class="op">[</span><span class="va">j</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">as.double</span><span class="op">(</span><span class="va">i</span><span class="op">)</span></span>
<span>   <span class="va">y</span><span class="op">[</span><span class="va">j</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">as.double</span><span class="op">(</span><span class="fl">3</span><span class="op">*</span><span class="va">i</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span>   <span class="co"># Clear cache then barrier sync so all ranks are ready then time</span></span>
<span></span>
<span><span class="va">dummy</span> <span class="op">&lt;-</span> <span class="fu">matrix</span><span class="op">(</span> <span class="fl">1</span><span class="op">:</span><span class="fl">125000000</span> <span class="op">)</span>       <span class="co"># Clear the cache buffers before timing</span></span>
<span></span>
<span><span class="va">ret</span> <span class="op">&lt;-</span> <span class="fu">mpi.barrier</span><span class="op">(</span> <span class="va">com</span> <span class="op">)</span>            <span class="co"># mpi.barrier() returns 1 if successful</span></span>
<span></span>
<span><span class="va">t_start</span> <span class="op">&lt;-</span> <span class="fu">proc.time</span><span class="op">(</span><span class="op">)</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span></span>
<span><span class="va">p_sum</span> <span class="op">&lt;-</span> <span class="fl">0.0</span></span>
<span><span class="kw">for</span><span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">myElements</span> <span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>   <span class="va">p_sum</span> <span class="op">&lt;-</span> <span class="va">p_sum</span> <span class="op">+</span> <span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">*</span> <span class="va">y</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">dot_product</span> <span class="op">&lt;-</span> <span class="fu">mpi.allreduce</span><span class="op">(</span> <span class="va">p_sum</span>, type <span class="op">=</span> <span class="fl">2</span>, op <span class="op">=</span> <span class="st">"sum"</span>, comm <span class="op">=</span> <span class="va">com</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">t_end</span> <span class="op">&lt;-</span> <span class="fu">proc.time</span><span class="op">(</span><span class="op">)</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span></span>
<span><span class="kw">if</span><span class="op">(</span> <span class="va">myRank</span> <span class="op">==</span> <span class="fl">0</span> <span class="op">)</span> <span class="op">{</span></span>
<span>   <span class="fu">print</span><span class="op">(</span><span class="fu">sprintf</span><span class="op">(</span><span class="st">"Rmpi dot product with nRanks workers took %6.3f seconds"</span>, <span class="va">t_end</span><span class="op">-</span><span class="va">t_start</span><span class="op">)</span><span class="op">)</span></span>
<span>   <span class="fu">print</span><span class="op">(</span><span class="fu">sprintf</span><span class="op">(</span><span class="st">"dot_product = %.6e on %i MPI ranks for vector size %i"</span>, <span class="va">dot_product</span>, <span class="va">nRanks</span>, <span class="va">n</span> <span class="op">)</span> <span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="fu">mpi.quit</span><span class="op">(</span> <span class="op">)</span></span></code></pre>
</div>
</div>
<div id="nav-tabpanel-2-C" class="tab-pane" aria-labelledby="nav-tab-2-C" role="tabpanel">
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">C<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode c" tabindex="0"><code class="sourceCode c"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;stdlib.h&gt;</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;time.h&gt;</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;sys/time.h&gt;</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;mpi.h&gt;</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="dt">void</span> main <span class="op">(</span><span class="dt">int</span> argc<span class="op">,</span> <span class="dt">char</span> <span class="op">**</span>argv<span class="op">)</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>   <span class="dt">int</span> i<span class="op">,</span> j<span class="op">,</span> N<span class="op">,</span> myrank<span class="op">,</span> nranks<span class="op">,</span> n_elements<span class="op">;</span></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>   <span class="dt">double</span> psum<span class="op">,</span> dprod<span class="op">,</span> <span class="op">*</span>X<span class="op">,</span> <span class="op">*</span>Y<span class="op">;</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a>   <span class="dt">double</span> t_elapsed<span class="op">;</span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>   <span class="kw">struct</span> timespec ts<span class="op">,</span> tf<span class="op">;</span></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>   MPI_Init<span class="op">(</span> NULL<span class="op">,</span> NULL<span class="op">);</span></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>   MPI_Comm_rank<span class="op">(</span> MPI_COMM_WORLD<span class="op">,&amp;</span>myrank <span class="op">);</span></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>   MPI_Comm_size<span class="op">(</span> MPI_COMM_WORLD<span class="op">,&amp;</span>nranks <span class="op">);</span></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a>   N <span class="op">=</span> <span class="dv">100000000</span><span class="op">;</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>   n_elements <span class="op">=</span> N <span class="op">/</span> nranks<span class="op">;</span></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a>   <span class="cf">if</span><span class="op">(</span> N <span class="op">%</span> nranks <span class="op">!=</span> <span class="dv">0</span> <span class="op">)</span> <span class="op">{</span></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a>      printf<span class="op">(</span><span class="st">"Please use an even number of ranks</span><span class="sc">\n</span><span class="st">"</span><span class="op">);</span></span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a>      exit<span class="op">(</span><span class="dv">0</span><span class="op">);</span></span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a>   <span class="op">}</span></span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a></span>
<span id="cb3-25"><a href="#cb3-25" tabindex="-1"></a>      <span class="co">// Allocate space for my parts of the X and Y vectors</span></span>
<span id="cb3-26"><a href="#cb3-26" tabindex="-1"></a></span>
<span id="cb3-27"><a href="#cb3-27" tabindex="-1"></a>   X <span class="op">=</span> malloc<span class="op">(</span> n_elements <span class="op">*</span> <span class="kw">sizeof</span><span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">);</span></span>
<span id="cb3-28"><a href="#cb3-28" tabindex="-1"></a>   Y <span class="op">=</span> malloc<span class="op">(</span> n_elements <span class="op">*</span> <span class="kw">sizeof</span><span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">);</span></span>
<span id="cb3-29"><a href="#cb3-29" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" tabindex="-1"></a>      <span class="co">// Initialize the X and Y vectors</span></span>
<span id="cb3-31"><a href="#cb3-31" tabindex="-1"></a></span>
<span id="cb3-32"><a href="#cb3-32" tabindex="-1"></a>   j <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb3-33"><a href="#cb3-33" tabindex="-1"></a>   <span class="cf">for</span><span class="op">(</span> i <span class="op">=</span> myrank<span class="op">;</span> i <span class="op">&lt;</span> N<span class="op">;</span> i <span class="op">+=</span> nranks <span class="op">)</span> <span class="op">{</span></span>
<span id="cb3-34"><a href="#cb3-34" tabindex="-1"></a>      j<span class="op">++;</span></span>
<span id="cb3-35"><a href="#cb3-35" tabindex="-1"></a>      X<span class="op">[</span>j<span class="op">]</span> <span class="op">=</span> <span class="op">(</span><span class="dt">double</span><span class="op">)</span> i<span class="op">;</span></span>
<span id="cb3-36"><a href="#cb3-36" tabindex="-1"></a>      Y<span class="op">[</span>j<span class="op">]</span> <span class="op">=</span> <span class="op">(</span><span class="dt">double</span><span class="op">)</span> i<span class="op">;</span></span>
<span id="cb3-37"><a href="#cb3-37" tabindex="-1"></a>   <span class="op">}</span></span>
<span id="cb3-38"><a href="#cb3-38" tabindex="-1"></a></span>
<span id="cb3-39"><a href="#cb3-39" tabindex="-1"></a>      <span class="co">// Allocate and innitialize a dummy array to clear cache</span></span>
<span id="cb3-40"><a href="#cb3-40" tabindex="-1"></a></span>
<span id="cb3-41"><a href="#cb3-41" tabindex="-1"></a>   <span class="dt">double</span> <span class="op">*</span>dummy <span class="op">=</span> malloc<span class="op">(</span> <span class="dv">125000000</span> <span class="op">*</span> <span class="kw">sizeof</span><span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">);</span></span>
<span id="cb3-42"><a href="#cb3-42" tabindex="-1"></a>   <span class="cf">for</span><span class="op">(</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> <span class="dv">125000000</span><span class="op">;</span> i<span class="op">++</span> <span class="op">)</span> <span class="op">{</span> dummy<span class="op">[</span>i<span class="op">]</span> <span class="op">=</span> <span class="fl">0.0</span><span class="op">;</span> <span class="op">}</span></span>
<span id="cb3-43"><a href="#cb3-43" tabindex="-1"></a></span>
<span id="cb3-44"><a href="#cb3-44" tabindex="-1"></a></span>
<span id="cb3-45"><a href="#cb3-45" tabindex="-1"></a>      <span class="co">// Now we sync then start the timer and do our calculation</span></span>
<span id="cb3-46"><a href="#cb3-46" tabindex="-1"></a></span>
<span id="cb3-47"><a href="#cb3-47" tabindex="-1"></a>   MPI_Barrier<span class="op">(</span> MPI_COMM_WORLD <span class="op">);</span></span>
<span id="cb3-48"><a href="#cb3-48" tabindex="-1"></a>   clock_gettime<span class="op">(</span>CLOCK_REALTIME<span class="op">,</span> <span class="op">&amp;</span>ts<span class="op">);</span></span>
<span id="cb3-49"><a href="#cb3-49" tabindex="-1"></a></span>
<span id="cb3-50"><a href="#cb3-50" tabindex="-1"></a>   psum <span class="op">=</span> <span class="fl">0.0</span><span class="op">;</span></span>
<span id="cb3-51"><a href="#cb3-51" tabindex="-1"></a>   <span class="cf">for</span><span class="op">(</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> n_elements<span class="op">;</span> i<span class="op">++</span> <span class="op">)</span> <span class="op">{</span></span>
<span id="cb3-52"><a href="#cb3-52" tabindex="-1"></a>      psum <span class="op">+=</span> X<span class="op">[</span>i<span class="op">]</span> <span class="op">*</span> Y<span class="op">[</span>i<span class="op">];</span></span>
<span id="cb3-53"><a href="#cb3-53" tabindex="-1"></a>   <span class="op">}</span></span>
<span id="cb3-54"><a href="#cb3-54" tabindex="-1"></a></span>
<span id="cb3-55"><a href="#cb3-55" tabindex="-1"></a>   dprod <span class="op">=</span> <span class="fl">0.0</span><span class="op">;</span></span>
<span id="cb3-56"><a href="#cb3-56" tabindex="-1"></a>   MPI_Allreduce<span class="op">(</span> <span class="op">&amp;</span>psum<span class="op">,</span> <span class="op">&amp;</span>dprod<span class="op">,</span> <span class="dv">1</span><span class="op">,</span> MPI_DOUBLE<span class="op">,</span> MPI_SUM<span class="op">,</span> MPI_COMM_WORLD<span class="op">);</span></span>
<span id="cb3-57"><a href="#cb3-57" tabindex="-1"></a></span>
<span id="cb3-58"><a href="#cb3-58" tabindex="-1"></a>   clock_gettime<span class="op">(</span>CLOCK_REALTIME<span class="op">,</span> <span class="op">&amp;</span>tf<span class="op">);</span></span>
<span id="cb3-59"><a href="#cb3-59" tabindex="-1"></a>   t_elapsed <span class="op">=</span>  <span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">(</span> tf<span class="op">.</span>tv_sec <span class="op">-</span> ts<span class="op">.</span>tv_sec <span class="op">);</span></span>
<span id="cb3-60"><a href="#cb3-60" tabindex="-1"></a>   t_elapsed <span class="op">+=</span> <span class="op">(</span><span class="dt">double</span><span class="op">)</span> <span class="op">(</span>tf<span class="op">.</span>tv_nsec <span class="op">-</span> ts<span class="op">.</span>tv_nsec<span class="op">)</span> <span class="op">*</span> <span class="fl">1e-9</span><span class="op">;</span></span>
<span id="cb3-61"><a href="#cb3-61" tabindex="-1"></a></span>
<span id="cb3-62"><a href="#cb3-62" tabindex="-1"></a>   <span class="cf">if</span><span class="op">(</span> myrank <span class="op">==</span> <span class="dv">0</span> <span class="op">)</span> <span class="op">{</span></span>
<span id="cb3-63"><a href="#cb3-63" tabindex="-1"></a>      printf<span class="op">(</span><span class="st">"dot product = </span><span class="sc">%lf</span><span class="st">  took </span><span class="sc">%lf</span><span class="st"> seconds on </span><span class="sc">%d</span><span class="st"> tasks</span><span class="sc">\n</span><span class="st">"</span><span class="op">,</span> dprod<span class="op">,</span> t_elapsed<span class="op">,</span> nranks <span class="op">);</span></span>
<span id="cb3-64"><a href="#cb3-64" tabindex="-1"></a>      printf<span class="op">(</span><span class="st">"</span><span class="sc">%lf</span><span class="st"> Gflops (billion floating-point operations per second)</span><span class="sc">\n</span><span class="st">"</span><span class="op">,</span></span>
<span id="cb3-65"><a href="#cb3-65" tabindex="-1"></a>            <span class="fl">2.0</span><span class="op">*</span>N<span class="op">*</span><span class="fl">1.0e-9</span> <span class="op">/</span> t_elapsed<span class="op">);</span></span>
<span id="cb3-66"><a href="#cb3-66" tabindex="-1"></a>      printf<span class="op">(</span> <span class="st">"</span><span class="sc">%lf</span><span class="st"> GB memory used</span><span class="sc">\n</span><span class="st">"</span><span class="op">,</span> <span class="fl">2.0</span><span class="op">*</span>N<span class="op">*</span><span class="fl">8.0</span><span class="op">/</span><span class="fl">1.0e9</span><span class="op">);</span></span>
<span id="cb3-67"><a href="#cb3-67" tabindex="-1"></a>   <span class="op">}</span></span>
<span id="cb3-68"><a href="#cb3-68" tabindex="-1"></a></span>
<span id="cb3-69"><a href="#cb3-69" tabindex="-1"></a>   MPI_Finalize<span class="op">(</span> <span class="op">);</span></span>
<span id="cb3-70"><a href="#cb3-70" tabindex="-1"></a><span class="op">}</span></span></code></pre>
</div>
</div>
<div id="nav-tabpanel-2-Fortran" class="tab-pane" aria-labelledby="nav-tab-2-Fortran" role="tabpanel">
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">FORTRAN<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode fortran" tabindex="0"><code class="sourceCode fortranfixed"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co">! Do product in Fortran using MPI message-passing</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="kw">PROGRAM</span> dot_product_fortran_mpi</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>   <span class="kw">USE</span> mpi</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>   <span class="dt">INTEGER</span> <span class="dt">::</span> i, n, myrank, nranks, n_elements, ierr</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>   <span class="dt">DOUBLE PRECISION</span> <span class="dt">::</span> psum, <span class="bu">dprod</span>, t_start, t_elapsed</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>   <span class="dt">DOUBLE PRECISION</span>, <span class="dt">ALLOCATABLE</span> <span class="dt">::</span> x(:), y(:)</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>   <span class="dt">DOUBLE PRECISION</span>, <span class="dt">ALLOCATABLE</span> <span class="dt">::</span> dummy(:)</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>      <span class="co">! Initialize the MPI environment</span></span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>   <span class="kw">CALL</span> MPI_Init( ierr )</span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a>   <span class="kw">CALL</span> MPI_Comm_rank( MPI_COMM_WORLD, myrank, ierr )</span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a>   <span class="kw">CALL</span> MPI_Comm_size( MPI_COMM_WORLD, nranks, ierr )</span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a>      <span class="co">! Dynamically allocate large arrays to avoid overflowing the stack</span></span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a>   n <span class="kw">=</span> <span class="dv">100000000</span></span>
<span id="cb4-21"><a href="#cb4-21" tabindex="-1"></a>   n_elements <span class="kw">=</span> n <span class="kw">/</span> nranks</span>
<span id="cb4-22"><a href="#cb4-22" tabindex="-1"></a>   <span class="kw">IF</span>( <span class="bu">MOD</span>( n, nranks) <span class="op">.NE.</span> <span class="dv">0</span> ) <span class="kw">THEN</span></span>
<span id="cb4-23"><a href="#cb4-23" tabindex="-1"></a>      <span class="fu">WRITE(*</span>,<span class="fu">*)</span> <span class="st">"Please use an even number of ranks"</span></span>
<span id="cb4-24"><a href="#cb4-24" tabindex="-1"></a>      <span class="kw">CALL</span> <span class="kw">EXIT</span>(<span class="dv">0</span>)</span>
<span id="cb4-25"><a href="#cb4-25" tabindex="-1"></a>   <span class="kw">END IF</span></span>
<span id="cb4-26"><a href="#cb4-26" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" tabindex="-1"></a>   <span class="kw">ALLOCATE</span>( x(n_elements) )</span>
<span id="cb4-28"><a href="#cb4-28" tabindex="-1"></a>   <span class="kw">ALLOCATE</span>( y(n_elements) )</span>
<span id="cb4-29"><a href="#cb4-29" tabindex="-1"></a>   <span class="kw">ALLOCATE</span>( dummy(<span class="dv">125000000</span>) )</span>
<span id="cb4-30"><a href="#cb4-30" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" tabindex="-1"></a>      <span class="co">! Initialize the vectors</span></span>
<span id="cb4-32"><a href="#cb4-32" tabindex="-1"></a></span>
<span id="cb4-33"><a href="#cb4-33" tabindex="-1"></a>   j <span class="kw">=</span> <span class="dv">0</span></span>
<span id="cb4-34"><a href="#cb4-34" tabindex="-1"></a>   <span class="kw">DO</span> i <span class="kw">=</span> myrank<span class="kw">+</span><span class="dv">1</span>, n, nranks    <span class="co">! Initialize to match non-MPI vectors</span></span>
<span id="cb4-35"><a href="#cb4-35" tabindex="-1"></a>      j <span class="kw">=</span> j <span class="kw">+</span> <span class="dv">1</span></span>
<span id="cb4-36"><a href="#cb4-36" tabindex="-1"></a>      x(j) <span class="kw">=</span> i</span>
<span id="cb4-37"><a href="#cb4-37" tabindex="-1"></a>      y(j) <span class="kw">=</span> i</span>
<span id="cb4-38"><a href="#cb4-38" tabindex="-1"></a>   <span class="kw">END DO</span></span>
<span id="cb4-39"><a href="#cb4-39" tabindex="-1"></a></span>
<span id="cb4-40"><a href="#cb4-40" tabindex="-1"></a>      <span class="co">! Initialize a dummy array to clear cache</span></span>
<span id="cb4-41"><a href="#cb4-41" tabindex="-1"></a></span>
<span id="cb4-42"><a href="#cb4-42" tabindex="-1"></a>   <span class="kw">DO</span> i <span class="kw">=</span> <span class="dv">1</span>, <span class="dv">125000000</span></span>
<span id="cb4-43"><a href="#cb4-43" tabindex="-1"></a>      dummy(i) <span class="kw">=</span> <span class="fl">0.0</span></span>
<span id="cb4-44"><a href="#cb4-44" tabindex="-1"></a>   <span class="kw">END DO</span></span>
<span id="cb4-45"><a href="#cb4-45" tabindex="-1"></a></span>
<span id="cb4-46"><a href="#cb4-46" tabindex="-1"></a>      <span class="co">! Now start the timer and do the calculations</span></span>
<span id="cb4-47"><a href="#cb4-47" tabindex="-1"></a></span>
<span id="cb4-48"><a href="#cb4-48" tabindex="-1"></a>   <span class="kw">CALL</span> MPI_Barrier( MPI_COMM_WORLD, ierr )  <span class="co">! Sync before starting timer</span></span>
<span id="cb4-49"><a href="#cb4-49" tabindex="-1"></a>   t_start <span class="kw">=</span> MPI_Wtime( )</span>
<span id="cb4-50"><a href="#cb4-50" tabindex="-1"></a></span>
<span id="cb4-51"><a href="#cb4-51" tabindex="-1"></a>   psum <span class="kw">=</span> <span class="fl">0.0</span></span>
<span id="cb4-52"><a href="#cb4-52" tabindex="-1"></a>   <span class="kw">DO</span> i <span class="kw">=</span> <span class="dv">1</span>, n_elements</span>
<span id="cb4-53"><a href="#cb4-53" tabindex="-1"></a>      psum <span class="kw">=</span> psum <span class="kw">+</span> x(i) <span class="kw">*</span> y(i)</span>
<span id="cb4-54"><a href="#cb4-54" tabindex="-1"></a>   <span class="kw">END DO</span></span>
<span id="cb4-55"><a href="#cb4-55" tabindex="-1"></a></span>
<span id="cb4-56"><a href="#cb4-56" tabindex="-1"></a>   <span class="bu">dprod</span> <span class="kw">=</span> <span class="fl">0.0</span></span>
<span id="cb4-57"><a href="#cb4-57" tabindex="-1"></a>   <span class="kw">CALL</span> MPI_Allreduce( psum, <span class="bu">dprod</span>, <span class="dv">1</span>, MPI_DOUBLE_PRECISION, MPI_SUM, <span class="kw">&amp;</span></span>
<span id="cb4-58"><a href="#cb4-58" tabindex="-1"></a>        MPI_COMM_WORLD, ierr )</span>
<span id="cb4-59"><a href="#cb4-59" tabindex="-1"></a></span>
<span id="cb4-60"><a href="#cb4-60" tabindex="-1"></a>   t_elapsed <span class="kw">=</span> MPI_Wtime( ) <span class="kw">-</span> t_start</span>
<span id="cb4-61"><a href="#cb4-61" tabindex="-1"></a></span>
<span id="cb4-62"><a href="#cb4-62" tabindex="-1"></a>   <span class="kw">IF</span>( myrank <span class="op">.eq.</span> <span class="dv">0</span> ) <span class="kw">THEN</span></span>
<span id="cb4-63"><a href="#cb4-63" tabindex="-1"></a>      <span class="fu">WRITE(*</span>,<span class="fu">*)</span> <span class="st">"dot product = "</span>, <span class="bu">dprod</span>, <span class="st">" took "</span>, <span class="kw">&amp;</span></span>
<span id="cb4-64"><a href="#cb4-64" tabindex="-1"></a>         t_elapsed, <span class="st">" seconds  on "</span>, nranks, <span class="st">" tasks"</span></span>
<span id="cb4-65"><a href="#cb4-65" tabindex="-1"></a>   <span class="kw">END IF</span></span>
<span id="cb4-66"><a href="#cb4-66" tabindex="-1"></a></span>
<span id="cb4-67"><a href="#cb4-67" tabindex="-1"></a>   <span class="kw">CALL</span> MPI_Finalize( ierr )</span>
<span id="cb4-68"><a href="#cb4-68" tabindex="-1"></a></span>
<span id="cb4-69"><a href="#cb4-69" tabindex="-1"></a><span class="kw">END PROGRAM</span> dot_product_fortran_mpi</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-2-Matlab" class="tab-pane" aria-labelledby="nav-tab-2-Matlab" role="tabpanel">
<p>Not implemented yet.</p>
</div>
</div>
</div>
<p>If you want to try other examples of MPI code, the scalar algorithm
for a matrix multiply is very simple but you can compare that to the
<strong>MPI</strong> versions in the links below. These algorithms are
much more complicated since you need to have particular columns and rows
in the same rank in order to perform the vector operations. This
involves a great deal of communication and the programmer must determine
the optimal way to handle the message passing to minimize the
communication costs and memory usage.</p>
<ul>
<li><a href="https://github.com/JordiCorbilla/mpi4py-examples/blob/master/src/examples/matrix%20multiplication/matrixmultiplication.py" class="external-link">MPI
matrix multiply in Python</a></li>
<li><a href="https://gist.github.com/AshanthaLahiru/bfa1a631f6af05af93e98538eeca3018" class="external-link">MPI
matrix multiply in C</a></li>
</ul>
<p>We see from all this that parallelizing a program using
message-passing requires much more work. This is especially true in more
complex programs where often you need to read input in on the lowest
rank and broadcast the data out to the other ranks. Most of the time
there is also a lot of communication needed during a calculation that
requires sending data from one rank to the other. In these cases, there
must be a pair of send and receive statements to specify the starting
data, what node to send it to, and on the receiving rank you must
specify the source rank and where to put the data. The nice thing about
message-passing is that the libraries do all the work of interacting
with the underlying communication system for you.</p>
<p>So while message-passing is more difficult to program, the supporting
libraries are very sophisticated in simplifying the process. With
multi-threading, your algorithm is limited to the number of cores on a
single compute node, but the message-passing model has no limits. People
have run message-passing codes on millions of cores on supercomputers
worth as much as half a billion dollars.</p>
</div>
<div class="section level3">
<h3 id="understanding-what-can-cause-inefficient-scaling">Understanding what can cause inefficient scaling<a class="anchor" aria-label="anchor" href="#understanding-what-can-cause-inefficient-scaling"></a>
</h3>
<p>In many practical message-passing codes, we would need to read data
into one of the ranks, divide the data up and send it out to each other
node. This extra communication is necessary but does lead to some
inefficiency to be aware of. Real message-passing applications also
usually require communication mixed in with the computational part in
order to move data to where it needs to be for the calculations.
Advanced programmers can try to minimize this by hiding the
communications behind the calculations using asynchronous communication
calls. All this communication can slow down the job, and this usually
gets worse as you spread a job over more cores, and especially over more
compute nodes. It is therefore usually best to keep the processes in a
run on as few compute nodes as possible so that most of the
communication is being done within a node by memory copies that are
faster than sending data between nodes across network cards.</p>
<p>Networks in cluster supercomputers like those typical in universities
are usually not uniform. Performance within a switch which may connect
32-40 compute nodes may be very fast, but if your job is spread on
different network switches it can be much slower since switches may be
connected to each other at much lower aggregate bandwidths. In Slurm you
can request that your job be run on just one switch by using
<strong>–switches=1</strong> but this is not always honored.</p>
<p>All of this does sound more complicated as message-passing
programming is definitely more complex than the multi-threaded approach.
But if you really need to apply more computing power to your job, it is
the only way to go.</p>
<div id="scaling-study-of-the-distributed-memory-dot-product-code" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="scaling-study-of-the-distributed-memory-dot-product-code" class="callout-inner">
<h3 class="callout-title">Scaling Study of the Distributed-Memory Dot
Product Code</h3>
<div class="callout-content">
<div class="tabs">
<nav><div id="nav-tab-3" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-3-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-Python" type="button" role="tab" aria-controls="nav-tabpanel-3-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-3-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-R" type="button" role="tab" aria-controls="nav-tabpanel-3-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-C" type="button" role="tab" aria-controls="nav-tabpanel-3-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-3-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-3-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-3" class="tab-content">
<div id="nav-tabpanel-3-Python" class="tab-pane show active" aria-labelledby="nav-tab-3-Python" role="tabpanel">
<p>Measure the execution time for the dot_product_message_passing.py
code for 1, 4, 8, and 16 cores if you are on an HPC system with at least
2 compute nodes. You can try different combinations of nodes and cores
for each if you would like to see the effects of the network (for the 4
core test, try 2 nodes 2 cores vs 4 nodes 1 core).</p>
<p>If you want a more challenging exercise you can <strong>git
clone</strong> the Python matrix multiply code and test the scaling.</p>
</div>
<div id="nav-tabpanel-3-R" class="tab-pane" aria-labelledby="nav-tab-3-R" role="tabpanel">
<p>Measure the execution time for the
<strong>dot_product_message_passing.R</strong> code for 1, 4, 8, and 16
cores on a single compute node to compare with other parallelization
methods available in R. If you are on an HPC system with multiple nodes,
try running the same tests on 2 or 4 compute nodes to compare. You can
also try running the <strong>dot_product_doMPI.R</strong> code to see
how it compares to using explicit <strong>MPI</strong> programming in
R.</p>
</div>
<div id="nav-tabpanel-3-C" class="tab-pane" aria-labelledby="nav-tab-3-C" role="tabpanel">
<p>Measure the execution time for the dot_product_c_mpi.c code for 1, 4,
8, and 16 cores if you are on an HPC system with at least 2 compute
nodes. You can try different combinations of nodes and cores for each if
you would like to see the effects of the network (for the 4 core test,
try 2 nodes 2 cores vs 4 nodes 1 core).</p>
<p>If you want a more challenging exercise you can <strong>git
clone</strong> the C matrix multiply code and test the scaling.</p>
</div>
<div id="nav-tabpanel-3-Fortran" class="tab-pane" aria-labelledby="nav-tab-3-Fortran" role="tabpanel">
<p>Measure the execution time for the dot_product_fortran_mpi.f90 code
for 1, 4, 8, and 16 cores if you are on an HPC system with at least 2
compute nodes. You can try different combinations of nodes and cores for
each if you would like to see the effects of the network (for the 4 core
test, try 2 nodes 2 cores vs 4 nodes 1 core).</p>
</div>
<div id="nav-tabpanel-3-Matlab" class="tab-pane" aria-labelledby="nav-tab-3-Matlab" role="tabpanel">
<p>Not implemented yet.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<div class="tabs">
<nav><div id="nav-tab-4" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-4-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-4-Python" type="button" role="tab" aria-controls="nav-tabpanel-4-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-4-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-4-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-4-R" type="button" role="tab" aria-controls="nav-tabpanel-4-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-4-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-4-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-4-C" type="button" role="tab" aria-controls="nav-tabpanel-4-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-4-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-4-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-4-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-4-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-4-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-4-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-4-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-4-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-4-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-4" class="tab-content">
<div id="nav-tabpanel-4-Python" class="tab-pane show active" aria-labelledby="nav-tab-4-Python" role="tabpanel">
<p>In this code we initialize the vectors locally so there is no
communication involved. The only communication is the global sum at the
end, so we expect the scaling to be close to ideal. In my tests I
measured the single core run at 18.2 seconds, the 4 core run at 4.9
seconds for a 3.7 times speedup, the 8 core run at 2.3 seconds for a 7.9
times speedup, the 16 core run at 1.5 seconds for a 12 times speedup,
and the 32 core run at 0.73 seconds for a 25 times speedup. Theses are
all close to ideal which is great. The inefficiency in the
multi-threaded code comes from there being too little work in each loop
when the parallelization comes in the loop overhead, while for the
message-passing code there is no difference in the loop overhead, it’s
just the added global summation after the loop.</p>
</div>
<div id="nav-tabpanel-4-R" class="tab-pane" aria-labelledby="nav-tab-4-R" role="tabpanel">
<p>For the single node tests I used 10,000,000 element vectors to get a
good result with enough work to expect better scaling. Smaller vector
tests will illustrate the difference in overhead better but be less
indicative of the performance of most real applications.</p>
<p>For the <strong>dot_product_message_passing.R</strong> code I got 481
ms for 1 core, 132 ms for 4 cores, 68 ms for 8 cores, and 49 ms for 16
cores showing good performance and scaling which is expected given the
only communication is for the global summation at the end. The
<strong>dot_product_doMPI.R</strong> code had 1.1 seconds, 0.85 seconds,
4.8 seconds, and 8.4 seconds respectively showing much poorer
performance and actually got worse as more cores were used. The overhead
was just too great, so while using a <strong>doMPI</strong> back end is
much easier than using explicit MPI commands, the performance and
scaling are much worse.</p>
<p>Running on 4 nodes 4 cores each I got 53 ms for
<strong>dot_product_message_passing.R</strong> compared to 49 ms on a
single node which is very good but again the only communication is the
global summation at the end. I did not manage to get the
<strong>dot_product_doMPI.R</strong> code to run on multiple nodes
yet.</p>
</div>
<div id="nav-tabpanel-4-C" class="tab-pane" aria-labelledby="nav-tab-4-C" role="tabpanel">
<p>In this code we initialize the vectors locally so there is no
communication involved. The only communication is the global sum at the
end, so we expect the scaling to be close to ideal. In my tests on a
single compute node I measured the single core run at 0.158 seconds, the
4 core run at 0.038 seconds for a 4.2 times speedup, the 8 core run at
0.019 seconds for a 8.3 times speedup, the 16 core run at 0.013 seconds
for a 12.1 times speedup, and the 32 core run at 0.023 seconds for a 6.9
times speedup. While the 4 and 8 task runs are close to ideal, the
scaling is not as great for the 16 and 32 core runs. Compiled
C/C++/Fortran code is much faster than other interpreted languages so
there isn’t as much work to overcome the overhead. The inefficiency in
the multi-threaded code comes from there being too little work in each
loop when the parallelization comes in the loop overhead, while for the
message-passing code there is no difference in the loop overhead, it’s
just the added global summation after the loop.</p>
</div>
<div id="nav-tabpanel-4-Fortran" class="tab-pane" aria-labelledby="nav-tab-4-Fortran" role="tabpanel">
<p>In this code we initialize the vectors locally so there is no
communication involved. The only communication is the global sum at the
end, so we expect the scaling to be close to ideal. In my tests on a
single compute node I measured the single core run at 0.166 seconds, the
4 core run at 0.038 seconds for a 4.4 times speedup, the 8 core run at
0.019 seconds for a 8.5 times speedup, the 16 core run at 0.016 seconds
for a 10.1 times speedup, and the 32 core run took much longer. While
the 4 and 8 task runs are close to ideal, the scaling is not great for
16 cores. Compiled C/C++/Fortran code is much faster than other
interpreted languages so there isn’t as much work to overcome the
overhead. The inefficiency in the multi-threaded code comes from there
being too little work in each loop when the parallelization comes in the
loop overhead, while for the message-passing code there is no difference
in the loop overhead, it’s just the added global summation after the
loop.</p>
</div>
<div id="nav-tabpanel-4-Matlab" class="tab-pane" aria-labelledby="nav-tab-4-Matlab" role="tabpanel">
<p>Not implemented yet.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Distributed-memory computing is very flexible, extremely scalable,
but more difficult to program.</li>
<li>Understand key factors that can limit the efficient scaling of
message-passing programs.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="links-for-additional-information">Links for additional information<a class="anchor" aria-label="anchor" href="#links-for-additional-information"></a>
</h3>
<ul>
<li><a href="https://hpc-tutorials.llnl.gov/mpi/" class="external-link">LLNL MPI
tutorial</a></li>
<li><a href="https://www.mpich.org/documentation/guides/" class="external-link">MPICH user
guides</a></li>
<li><a href="https://www.open-mpi.org/doc/" class="external-link">OpenMPI function man
pages</a></li>
<li><a href="https://mpi4py.readthedocs.io/" class="external-link">mpi4py</a></li>
<li><a href="https://cran.r-universe.dev/Rmpi" class="external-link">CRAN Rmpi</a></li>
</ul>
</div>
</section></section><section id="aio-language-survey"><p>Content from <a href="language-survey.html">Language Survey</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/language-survey.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 10 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are the strengths and weaknesses of each computer
language?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand the criteria we will use to evaluate each language.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>People choose a programming language for a given project for many
reasons. Sometimes they choose a language because it is the only one
they know, or because it is the only one their advisor knows. Many
languages are easier to learn and use, and some can be used
interactively.</p>
<p>In the next few sections, we want to do a survey of some of the more
common languages being used in science so that we can compare and
contrast each. When we first choose a language to use for a project, it
is common to only consider the capabilities of that language. For
example, R has great access to statistical analysis routines so it is a
great choice when those capabilities are needed. R and Python both can
be used interactively which appeals to many. But when we start talking
needing performance as well, then we have to balance the capabilities
that each language offers with the need to get great performance. This
performance can come in the form of scalar or single-core performance,
but also involves the ability to apply multiple cores or multiple
compute nodes.</p>
<p>Capability, ease of programming, performance, and parallelizability
are all attributes that we will need to consider. Capability refers to
the routines each language has access to like all the statistical
functions in R, the wide variety of artificial intelligence packages
programmed in Python, and the mathematical toolboxes in Matlab.
Usability means the ease of programming and the productivity of the
programmer. A low level language like C is incredibly flexible and
efficient but is more difficult to program and debug so that program
development takes longer. Performance is unimportant for simple
calculations but everything as we scale up to more complex and
computationally costly runs. This is why people may start a project in a
less efficient language and end up needing to switch languages when
performance begins to limit the science that can be done.
Parallelizability refers to how many compute cores we can apply to a
given job. This again ultimately limits the size of the science we can
achieve. We must understand how each language measures up for each of
these merits in order to choose an effective approach for each project
we are interested in.</p>
<ul>
<li>Capability - Access to the routines and data structures you
need</li>
<li>Usability - Ease of programming and productivity</li>
<li>Performance - How fast is the final code going to run?</li>
<li>Parallelizability - How many cores or compute nodes can be
used?</li>
</ul>
<p>Compute cycles on NERSC (National Energy Research Scientific
Computing) supercomputers are dominated by the compiled languages C/C++
and Fortran. Python is involved in one quarter of all jobs, but in a job
control role rather than a computational one. When you run jobs on large
$100 million supercomputers, you have to choose your language for
performance reasons even if that means putting extra effort into the
programming.</p>
<p>In a university environment it is very common to have less efficient
languages supported for computations such as Python, R, and Matlab. Even
though these are far from efficient computationally, they are typically
easier to program and can provide greater functionality. These factors
are often more important in cases where you may have a single programmer
writing a custom code for a particular project. So the choice of a
language can depend on the circumstances which may include factors like
how long an application is expected to be used versus how much effort it
will take to be developed.</p>
<p>It is useful to know a little bit about each language so you can
decide which is best for a given project or even which languages you
want to be proficient at for your career. The next sections will present
the strengths and weaknesses of many languages commonly used in
scientific computing. Some languages have common practices that are
performance bottlenecks that need to be avoided, so these will be
discussed and alternative approaches presented.</p>
<section><h2 class="section-heading" id="overview">Overview<a class="anchor" aria-label="anchor" href="#overview"></a>
</h2>
<hr class="half-width">
<ul>
<li><p>C/C++ and Python are row-major languages with arrays starting at
0.</p></li>
<li><p>Fortran, R, and Matlab are column-major languages with arrays
starting at 1.</p></li>
<li><p>C/C++ and Fortran are compiled languages for
high-performance.</p></li>
<li><p>Python, R, and Matlab have some optimized libraries to help with
performance.</p></li>
</ul>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Performance is just one criteria we need to understand when choosing
the best language for a given project.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-c-cpp"><p>Content from <a href="c-cpp.html">C and C++ Languages</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/c-cpp.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 30 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are the strengths and weaknesses of programming in C and
C++?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Analyze the merits of the C/C++ language.</li>
<li>Learn how to compile and run C/C++ programs.</li>
<li>Try compiling and running OpenMP and MPI versions.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="the-c-programming-language">The C Programming Language<a class="anchor" aria-label="anchor" href="#the-c-programming-language"></a>
</h2>
<hr class="half-width">
<p>C is a very low level language that is extremely flexible and
efficient. It is the language used to program the Linux operating system
and the Python, Matlab, and much of the R languages. But all this power
comes at a price; it is more difficult to debug.</p>
<p>C files end in <strong>.c</strong> with header files ending in
<strong>.h</strong>. It is a row-major language meaning that a matrix is
stored by rows with elements of each row next to each other. Arrays are
numbered starting with zero same as with Python.</p>
<p>In C, variable types are less strict to allow for greater
flexibility, but this makes it more difficult for compilers to catch
errors before run time. Memory is dynamically allocated in a raw form
and assigned with a pointer to the first element, but there is little
control after that on how the programmer accesses the memory. If the
program tries to write to memory past what is allocated to that array,
there is no protection to prevent it from happening. So the programmer
is responsible for a lot more since the compiler cannot check much of
the code and provide detailed warnings. This is just the cost of the low
level access and flexibility of C.</p>
<p>Part of the power of C as well as C++ and Fortran is the access to
massive numbers of highly-optimized libraries of routines that have been
developed over the past 60 years. These involve scalar, vector, and
matrix algorithms in the BLAS (Basic Linear Algebra Subroutines)
libraries, sparse matrix libraries, Linear Algebra Package of LaPack and
its multi-processor version ScaLapack, FFT (Fast Fourier Analysis)
routines, and many others.</p>
<p><strong>OpenMP</strong> is the premier multi-threaded package
available for scientific computing. There are other methods of doing
multi-threaded computing like <strong>pThreads</strong> that are just as
efficient but harder to use. <strong>MPI</strong> is likewise developed
specifically for C/C++ and Fortran. While other languages have stripped
down versions implemented, none can rival the rich set of functionality
that the OpenMPI and MPICH packages provide with the full MPI
standard.</p>
<p>C doesn’t have as much access to statistical package that have been
developed for R, nor the mathematical toolboxes of Matlab and the wide
variety of artificial intelligence toolkits of Python. But it is
unrivaled in power, performance and flexibility.</p>
</section><section><h2 class="section-heading" id="the-c-language">The C++ Language<a class="anchor" aria-label="anchor" href="#the-c-language"></a>
</h2>
<hr class="half-width">
<p>C++ is a super set of C, meaning that it starts with C and adds
functionality beyond. Since C can be embedded with C++ code you get the
best of both worlds with access to the low level capabilities of C along
with the high level data structures and programming functionality of
C++. C++ files end with <strong>.cpp</strong> and use the same header
files ending in <strong>.h</strong>.</p>
<p>It is an object-oriented language, with objects having data that can
be private (hidden) or public (exposed) along with definitions of how
that object is created and interacts with other objects. This is good in
a sense since much of the work in creating an object is hidden from the
programmer, but hiding this process also means it is more difficult to
track memory usage and computations, both of which are very important in
understanding performance issues.</p>
<p>In C++ you also have overloaded operators, meaning that a
multiplication sign can have different meaning depending on the data
types it is applied to. If it is between 2 scalar variables then a
scalar multiplication is done, while the same operator between 2
matrices would do a matrix multiplication. This is why C++ is great for
programming other languages like R since the programmer can define what
each operator does and have that be dependent on the variable types
involved.</p>
<p>Much of what makes C++ so powerful is also what makes it more
difficult to work with where performance is concerned. The ability to
hide object initialization means that memory allocation is also hidden.
Operator overloading also can obscure the computations being done, as a
multiplication between two variables as in the example code below may
represent a single floating-point operation or a triply-nested loop if
the operands are both matrices. Memory and computations are simply less
explicit in C++ by design, and that can make it more difficult to
identify where performance issues may lie.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">CPP<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode cpp" tabindex="0"><code class="sourceCode cpp"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>C <span class="op">=</span> A <span class="op">*</span> B<span class="op">;</span></span></code></pre>
</div>
</section><section><h2 class="section-heading" id="cc-compilers">C/C++ Compilers<a class="anchor" aria-label="anchor" href="#cc-compilers"></a>
</h2>
<hr class="half-width">
<p>Unlike interpreted languages like Python, R, and Matlab, you have to
compile C and C++ code into an executable before running. The compiler
analyzes the code and optimizes it in ways that cannot be done on the
fly with interpreted languages making the resulting executable much more
efficient.</p>
<p>The most common compilers are the Gnu compiler <strong>gcc</strong>
with the C++ version <strong>g++</strong> and the exceptional commercial
Intel compilers <strong>icc</strong> and <strong>icpc</strong>. There
are many compiler options available but you can’t go wrong using
<strong>-g</strong> to generate a symbol table which will provide a line
number where the error occurred in case of a crash and
<strong>-O3</strong> for high-level optimization. You compile in the
OpenMP pragmas using <strong>-fopenmp</strong> for the Gnu compiles and
<strong>-openmp</strong> for the Intel compilers.</p>
</section><section><h2 class="section-heading" id="makefiles-for-compiling">Makefiles for compiling<a class="anchor" aria-label="anchor" href="#makefiles-for-compiling"></a>
</h2>
<hr class="half-width">
<p>Compilation is actually done in two stages although for single file
applications it is typically done in one step. Source files get compiled
into binary object files with a <strong>.o</strong> suffix then all
those are linked together with any optimization libraries to produce the
executable.</p>
<p>Large applications may divide the source code into many smaller
source files for organizational reasons. A <strong>Makefile</strong> can
be developed that has all the logical directions to compile a single
application with a single <strong>make</strong> command. These
dependencies have many advantages, such as speeding up the compilation
process by allowing only those source files that have changed to be
recompiled into new object files. You will get a chance to examine a
small makefile in the exercise at the end of this lesson.</p>
</section><section><h2 class="section-heading" id="installing-large-software-packages">Installing large software packages<a class="anchor" aria-label="anchor" href="#installing-large-software-packages"></a>
</h2>
<hr class="half-width">
<p>To install any large software package you will need to read the
documentation and follow the directions. Having said that, many well
designed packages follow a similar approach of running a
<strong>configure</strong> script, then compiling the package with
<strong>make</strong> and installing it with <strong>make
install</strong>. The <strong>configure</strong> script usually requires
at least a <strong>–prefix=</strong> argument to tell it where to
install the software. While you will see many variations on this
approach it is good to at least understand this as a starting point.</p>
<ul>
<li>./configure –prefix=/path/to/installation/directory</li>
<li>make</li>
<li>make install</li>
</ul>
<div id="practice-compiling-and-running-c-codes" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="practice-compiling-and-running-c-codes" class="callout-inner">
<h3 class="callout-title">Practice compiling and running C codes</h3>
<div class="callout-content">
<p>The most common compiler for C is the Gnu C Compiler
<strong>gcc</strong>. This may be available by default on your system,
so try <strong>gcc –version</strong> to check. If not then you’ll need
to figure out how to gain access to it. You can also try the Intel C
Compiler <strong>icc</strong> if you have it available on your
system.</p>
<p>Try compiling the <strong>dot_product_c.c</strong> file using
<strong>gcc -g -O3 -o dot_product_c dot_product_c.c</strong> which tells
the compiler to use optimization level 3 and create the executable
dot_product_c from the source code dot_product_c.c. Once compiled you
can run this using <strong>./dot_product_c</strong> or submit a job to
the batch queue. Try also to compile with <strong>icc</strong> if it is
available.</p>
<p>Next try to compile the OpenMP multi-threaded version. You will need
to tell it to access the OpenMP library using a
<strong>-fopenmp</strong> flag for the <strong>gcc</strong> compiler or
<strong>-openmp</strong> for <strong>icc</strong>. Try a few runs with
different numbers of threads to get comfortable with running on multiple
cores.</p>
<p>If you have an MPI package installed, try compiling the
message-passing version using <strong>mpicc -g -O3 -o dot_product_c_mpi
dot_product_c_mpi.c</strong> and running some tests with <strong>mpirun
-np 4 dot_product_c_mpi</strong> for example.</p>
<p>If you want more practice you may try running the matmult_c.c code
and the optimized version matmult_cblas.c.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>On a modern Intel system the raw scalar code ran in 0.14 seconds as
did the single-threaded OpenMP and single-task MPI runs. The test on 4
threads took 0.06 seconds which is quite a bit off the 4x speedup we are
looking for. This again is due to how little work is being done during
each pass through the loop compared to the loop overhead. The MPI test
on 4 tasks is better at 0.047 seconds and is a little faster at 0.034
seconds on 8 tasks since the parallelization is done in a different
manner. How do your results compare to these?</p>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Learn about the characteristics of C/C++</li>
</ul>
</div>
</div>
</div>
<div class="section level3">
<h3 id="links-for-additional-information">Links for additional information<a class="anchor" aria-label="anchor" href="#links-for-additional-information"></a>
</h3>
<ul>
<li><a href="https://www.guru99.com/c-programming-tutorial.html" class="external-link">C
Tutorial</a></li>
</ul>
</div>
</section></section><section id="aio-fortran"><p>Content from <a href="fortran.html">The Fortran Language</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/fortran.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 20 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are the strengths and weaknesses of Fortran?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Analyze the merits of Fortran.</li>
<li>Learn how to compile and run a Fortran program.</li>
<li>Identify source files for different versions of Fortran.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div id="accordionInstructor1" class="accordion instructor-note accordion-flush">
<div class="accordion-item">
<button class="accordion-button instructor-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseInstructor1" aria-expanded="false" aria-controls="collapseInstructor1">
  <h3 class="accordion-header" id="headingInstructor1">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="edit-2"></i></div> Instructor Note </h3>
</button>
<div id="collapseInstructor1" class="accordion-collapse collapse" data-bs-parent="#accordionInstructor1" aria-labelledby="headingInstructor1">
<div class="accordion-body">
<p>This Fortran section can certainly be skipped if time is limited. If
so, I’d suggest at least saying a few lines from the first paragraph
below.</p>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="modern-fortran">Modern Fortran<a class="anchor" aria-label="anchor" href="#modern-fortran"></a>
</h2>
<hr class="half-width">
<p>Fortran is one of the oldest computer languages used for scientific
computing. One reason it is still heavily used is for historic reasons
since there are just so many lines of Fortran code out there that are
hard to replace. The good news is that this code base is extremely
efficient. The Fortran language has also continued to modernize adding
much of the same advanced functionality of C++.</p>
<p>Historically people used the f77 or Fortran 77 standard for a long
time (defined in 1977). Modern Fortran has made great strides from this
old standard in adding object oriented programming capabilities and a
less stringent form. Fortran code is identified by the
<strong>.f</strong> suffix or <strong>.F</strong> if there are
pre-processor commands embedded. You may also see the
<strong>.f90</strong> or <strong>.f95</strong> suffix to denote that the
code adheres to the fluid formatting of the Fortran 90 and 95 standard
defined in 1990 and 1995 respectively. Files with the
<strong>.mod</strong> suffix are modules.</p>
<p>All these newer standards have added capabilities similar to C++ like
dynamic memory allocation, object-oriented programming, and operator
overloading. More recent work has been geared toward adding more
parallel capabilities like the <strong>Coarray Fortran</strong> parallel
execution model and the <strong>Do concurrent</strong> construct for
identifying that a loop has no interdependencies and is therefore
capable of being parallelized.</p>
<p>The primary value of Fortran will always be its efficiency and the
same access to all the scientific and mathematical packages shared with
C/C++. It is a column-major language like R and Matlab, and starts
arrays at one instead of zero just like both of those as well. OpenMP
and MPI packages likewise have full support for Fortran.</p>
<p>So Fortran is every bit as powerful and efficient as C/C++, but it is
slowly being taken over by C/C++ on large supercomputers.</p>
<div class="section level3">
<h3 id="language-characteristics-to-avoid-gotchas">Language characteristics to avoid (gotchas)<a class="anchor" aria-label="anchor" href="#language-characteristics-to-avoid-gotchas"></a>
</h3>
<p>While most memory in C/C++ is dynamically allocated, it is very
common to have Fortran arrays statically allocated to a given size
especially in older codes. This memory comes from what internally is
called the <strong>stack</strong> which is a variable defined on each
system. In our cluster at Kansas State University the default stack size
as seen by doing <strong>ulimit -a</strong> is set to only a little over
8 MB while data arrays can easily exceed gigabyte sizes at times. When
you exceed the stack size, your job crashes with a segfault that will
not give you any useful information on what went wrong. If you think the
stack size may be an issue, you can include a command <strong>ulimit -s
unlimited</strong> before running your application to remove the stack
size limit entirely.</p>
</div>
<div class="section level3">
<h3 id="compiling-fortran-code">Compiling Fortran code<a class="anchor" aria-label="anchor" href="#compiling-fortran-code"></a>
</h3>
<p>Fortran is compiled with many of the same arguments and libraries
used for C/C++. The Gnu version is <strong>gfortran</strong> and the
Intel compiler is <strong>ifort</strong>. When using the OpenMP
multi-threading package you will add the <strong>-fopenmp</strong> or
<strong>-openmp</strong> flag respectively. To compile a Fortran MPI
code you will use <strong>mpifort</strong>.</p>
<p>While there are many compilation options for each of these, you can
general get by with <strong>-O3</strong> level 3 optimization. I also
strongly suggest always compiling with <strong>-g</strong>. This creates
a symbol table so that if your code crashes you at least get the line
number where it failed. Without this you get a pretty meaningless
onslaught of information that won’t really give you a clue as to the
problem. Compiling with <strong>-g</strong> should not slow down your
code as long as you also use <strong>-O3</strong>, and the extra size of
the executable should not matter.</p>
<p>Compiling source code to get an executable is again a two step
process where source code is compiled into binary object files which are
combined with any libraries needed in the linking stage. For simple
applications this may all be done in a single step. For more complex
codes involving many individual source files and modules it is common to
have a <strong>Makefile</strong> handle everything. The
<strong>Makefile</strong> provides the logic to compile only the parts
of an application code base that have changed, then link everything
together to produce the executable.</p>
<div id="practice-compiling-and-running-fortran-codes" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="practice-compiling-and-running-fortran-codes" class="callout-inner">
<h3 class="callout-title">Practice compiling and running Fortran
codes</h3>
<div class="callout-content">
<p>Try compiling the <strong>dot_product_fortran.f90</strong> code with
the <strong>gfortran</strong> compiler, then try with
<strong>ifort</strong> if you have access to it. Do the same with the
optimized code <strong>dot_product_fortran_opt.f90</strong> to see the
difference that the built-in <strong>dot_product( x, y )</strong>
function can have. You can then compile the OpenMP version
<strong>dot_product_fortran_openmp.f90</strong> and do a scaling study,
and if you are on a system with MPI installed then try compiling and
running the MPI version <strong>dot_product_fortran_mpi.f90</strong>
using <strong>mpifort</strong>. Once you have compiled these codes
manually take a look at the <strong>Makefile</strong>. This contains all
the commands necessary to compile all the codes above with a single
command <strong>make all_fortran</strong>.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>Each computer system may be set up differently with regard to what
compilers are available and how they need to be accessed. You may need
to contact your administrator for help if you are unsure whether you
have the Intel compiler suite installed, and how to access an MPI
package if available. In my tests on a modern Intel system the raw
Fortran code and optimized both took 0.14 seconds as did the OpenMP
using 1 thread and the MPI version using 1 task. OpenMP using 4 threads
took 0.063 seconds which is a little more than twice as fast and then
performance flattened out for more threads. The MPI version using 4
tasks took 0.05 seconds which is slightly better than the OpenMP
version, and 0.027 seconds for 8 tasks showing better scaling.</p>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Learn about the characteristics of modern Fortran</li>
</ul>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="links-for-additional-information">Links for additional information<a class="anchor" aria-label="anchor" href="#links-for-additional-information"></a>
</h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Fortran" class="external-link">Fortran
wiki</a></li>
<li><a href="https://fortran-lang.org/learn/" class="external-link">Fortran tutorials</a></li>
</ul>
</div>
</section></section><section id="aio-python"><p>Content from <a href="python.html">The Python Language</a></p>
<hr>
<p>Last updated on 2025-10-07 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/python.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 40 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are the strengths and weaknesses of programming with
Python?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Analyze the merits of programming in Python.</li>
<li>Learn how to work with virtual environments.</li>
<li>Learn about common performance-oriented libraries.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="python-performance">Python performance<a class="anchor" aria-label="anchor" href="#python-performance"></a>
</h3>
<p>Python is a high-level and extremely flexible language that has broad
acceptance within the high-performance computing community and even more
broadly with scientific and technical programmers. However, it isn’t a
performance language in the same manner as the compiled languages C/C++
and Fortran. It is an interpreted language that executes the code line
by line while compiled languages optimize larger blocks of code before
execution. At the Department of Energy supercomputing center NERSC
Python is involved in 25% of the code bases for the complex
applications, but only accounts for 4% of the CPU time on their systems.
This means that Python has a high level control role while the compiled
languages are used to do the performance computations.</p>
<p>A matrix multiplication algorithm implemented with raw Python code is
more than a hundred times slower than raw C code that is compiled. You
can achieve decent performance with Python only when your code uses the
highly-optimized libraries, and fortunately there is a rich set
available such as <strong>NumPy</strong> and <strong>SciPy</strong>
among many others. Even these can be slower than their compiled language
counterparts though, as a <strong>NumPy</strong> matrix multiplication
is still 50%-25% the speed depending on the matrix size compared to a
<strong>BLAS</strong> library <strong>DGEMM</strong> function available
for C/C++/Fortran.</p>
<p>While Python is not intended to be a performance language, there are
very good options available for parallelization. The
<strong>pymp</strong> library is a multi-threaded package based on a
stripped down version of the much more extensive <strong>OpenMP</strong>
library available for the compiled languages. <strong>pymp</strong> is
actively developed and maintained and provides the basic functionality
of OpenMP to the Python environment in an easy to use manner. The
<strong>mpi4py</strong> package likewise provides a stripped down MPI
environment for Python users. While neither of these is anywhere near as
complex nor complete as their compiled language cousins, both provide
the basics that most programmers will need.</p>
<p><strong>Dask</strong> is another option that extends Python in two
ways. If your data set is too large for the memory on one computer, it
provides the framework to use packages like <strong>NumPy</strong>,
<strong>Pandas</strong>, and Python iterators on data that is
distributed across multiple compute nodes in a cluster. It also provides
a dynamic task scheduler for parallelizing code.</p>
<p><strong>Numba</strong> is designed to speed up raw Python code by
compiling blocks of code programmed as functions that are tagged by the
programmer with <strong><span class="citation">@jit</span>(nopython=True,cache=True)</strong>. This
uses the industry standard <strong>LLVM</strong> compiler library, but
the compilation is not being done once ahead of the runtime as with
C/C++ and Fortran, it is being done at runtime in what is referred to as
a <strong>just-in-time</strong> or JIT manner. How effective this
approach can be will depend on how much the compilation can be done in
advance of when it is needed, and how much optimization it can do on the
fly, but there also is the option to save the compiled functions so that
they don’t need to be recompiled for subsequent runs. There are also
multi-threading options for parallelizing functions.</p>
<p><strong>Parsl</strong> is a parallelization library for Python that
very easily allows that programmer to define functions as separate apps
or applications that can be run on different cores or compute nodes.
This approach is especially useful in expressing multi-step workflows.
The link below provides more information on this approach.</p>
<p><a href="https://github.com/Parsl/parsl" class="external-link">Parsl python package
github</a></p>
<p><strong>memory_profiler</strong> is a Python package that allows easy
profiling of the memory usage of the code. If run externally using the
<strong>mprof</strong> command it reports the full memory usage of the
executable which can also be easily plotted. You can also add
<strong><span class="citation">@profile</span></strong> statements
before functions to provide line by line memory profiling to help
identify exactly where in your code your large memory allocations are
occurring. The link below provides a more detailed explanation with
examples.</p>
<p><a href="https://pypi.org/project/memory-profiler/" class="external-link">Python
memory-profiler package documentation</a></p>
<p>The <strong>line_profiler</strong> package in Python similarly can
run externally or internally, but provides timing information in a
line-by-line manner. Further information can be found at the link
below:</p>
<p><a href="https://github.com/pyutils/line_profiler" class="external-link">Python
line_profiler package github</a></p>
</div>
<div class="section level3">
<h3 id="python-capabilities">Python capabilities<a class="anchor" aria-label="anchor" href="#python-capabilities"></a>
</h3>
<p>For what Python lacks in raw performance as an interpreted language
it more than makes up for in its flexibility and easy of use. It is
common to develop code in an interactive environment like a Jupyter
Notebook which provides a very quick cycle from changing code to testing
it. It is a high level language that is easy to read, write, and learn,
and with advantages like dynamic variable typing. All this makes Python
a high productivity language enabling programmers to produce code more
quickly than in many lower level, more computationally efficient
languages.</p>
<p>Where this language really shines is in the extensive selection of
software packages that have been developed for the Python environment.
Some important examples are the TensorFlow and Scikit packages for doing
Artificial Intelligence and Machine Learning, but Python is commonly
used in fields as diverse as video processing, data mining, game and
language development, finance, and general programming.</p>
</div>
<div class="section level3">
<h3 id="technical-aspects">Technical aspects<a class="anchor" aria-label="anchor" href="#technical-aspects"></a>
</h3>
<p>Python is a row-major language like C/C++ where 2-dimensional arrays
or matrices are stored by row with elements in each row being next to
each other in memory. Python is also like C/C++ in that arrays are
numbered starting with 0. Languages like Fortran, R, and Matlab are the
opposite of Python and C in both these respects.</p>
<p>Python is an interpreted language like R and Matlab. It can be
compiled but not in the same way as C/C++ and Fortran where the compiler
optimizes whole blocks of code. The Python compiler simply packages the
code up so that it can run independent of Python or any installed
packages. This means the user running the ‘compiled’ python executable
does not need access to the same version of Python nor any virtual
environment with the python packages installed since everything is
packaged up in the executable. There will be an exercise at the end of
this section where you will be able to test this for yourself.</p>
</div>
<div class="section level3">
<h3 id="advantages-of-using-a-virtual-environment">Advantages of using a virtual environment<a class="anchor" aria-label="anchor" href="#advantages-of-using-a-virtual-environment"></a>
</h3>
<p>If you are on your own laptop or desktop computer you can install
Python packages system wide if you would like. On HPC systems there may
be some Python packages installed as loadable modules. You can also
install packages locally on your home directory using the
<strong>–user</strong> flag to <strong>pip install</strong>.</p>
<p>It is strongly advised however that you use a different virtual
environment for each new project. While you may need to re-install some
common packages like <strong>NumPy</strong>, having a clean virtual
environment for each project helps avoid problems with conflicting
versions of dependency packages. Quite often if users are having trouble
installing Python software, I’ll advise them to start with a clean
virtual environment and that fixes everything.</p>
<p>Creating a virtual environment is not very difficult. Below is an
example of creating one called <strong>env-py-3.7.4</strong> where I
labeled it after the version of Python being used. Once activated the
prompt will change to show that you are working in the
<strong>env-py-3.7.4</strong> environment. You can install any packages
you need, run your python code, then deactivate the environment when you
are done. The dollar sign is the command prompt to illustrate how the
prompt changes while the virtual environment is active.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="ex">$</span> mkdir <span class="at">-p</span> ~/virtualenvs</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="ex">$</span> cd ~/virtualenvs</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="ex">$</span> python <span class="at">-m</span> venv <span class="at">--system-site-packages</span> python-hpc-user</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="ex">$</span> source ~/virtualenvs/python-hpc-user/bin/activate</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="kw">(</span><span class="ex">python-hpc-user$</span> pip install numpy scipy</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="kw">(</span><span class="ex">python-hpc-user</span><span class="kw">)</span><span class="ex">$</span> python python_code.py</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="kw">(</span><span class="ex">python-hpc-user</span><span class="kw">)</span><span class="ex">$</span> deactivate</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="ex">$</span></span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="compiling-python">Compiling Python<a class="anchor" aria-label="anchor" href="#compiling-python"></a>
</h3>
<p>Compiling Python code does not do the same type of code loop analysis
that compiling C/C++ or Fortran does, so there really isn’t any speedup
involved. It does create a self-contained executable that no longer
needs to have a matching Python version or installed package virtual
environment available. It is therefore most useful when you are done
developing the code and want to distribute it as a binary.</p>
<p>Compiling Python code does vary depending on the operating system you
are on. In Linux you can compile code by adding a flag <strong>-m
py_compile</strong> which will create an executable in a
<strong><strong>pycache</strong></strong> directory.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="ex">python</span> <span class="at">-m</span> py_compile python_code.py</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="fu">mv</span>  __pycache__/python_code.cpython-37.pyc  compiled_python_code.pyc</span></code></pre>
</div>
<p>The executable <strong>compiled_python_code.pyc</strong> will then
run on systems where Python is not installed and you have no virtual
environment activated.</p>
</div>
<div class="section level3">
<h3 id="language-characteristics-to-be-aware-of-gotchas">Language characteristics to be aware of (gotchas)<a class="anchor" aria-label="anchor" href="#language-characteristics-to-be-aware-of-gotchas"></a>
</h3>
<p>One of Python’s greatest strengths is that it is a simple high-level
language that is interpreted and easy to use. This is also its biggest
disadvantage when it comes to performance. Simply put, when you need
performance you need to use the highly-optimized numeric libraries.
Unfortunately compiling Python code really doesn’t help when there are
no optimized library codes available.</p>
<p>Virtual environments provide an excellent way to manage the
installation of software packages, and it is easy to use the <strong>pip
install</strong> command which installs the desired package and any
dependencies. You do always need to have the active virtual environment
match the Python version number used to install all those packages, so
if you want to use a newer version of Python you will have to reinstall
all the packages too.</p>
<p>Python2 was deprecated on January 1 of 2020. Everyone should be
programming in Python3 now, and these codes are not backwards compatible
with Python2. This means that if you encounter any Python2 code you
would either need to convert the code to Python3 or find an old and
deprecated version of Python2 and hope that still works. Basically if
you run into old python code at this point, expect to have some errors
to deal with.</p>
<p>Python uses a Global Interpreter Lock (GIL) to ensure that only one
thread can control the interpreter at any given time. This basically
defines Python as being single-threaded which simplifies everything
internally. The problem comes when a programmer wants to do
multi-threading to apply more power to solve a problem faster. The
<strong>pymp</strong> package gets around the GIL by forking off
separate processes and therefore each essentially has its own GIL. The
<strong>mpi4py</strong> package for message-passing is not affected
since with MPI each task is a separate copy of the same program. In
general, the GIL is something to be aware of but packages like
<strong>pymp</strong> have already done the work of getting around the
issue.</p>
<div id="play-with-the-python-dot-product-examples" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="play-with-the-python-dot-product-examples" class="callout-inner">
<h3 class="callout-title">Play with the Python dot product examples</h3>
<div class="callout-content">
<p>Take a look at the Python versions of the dot product code to see how
they differ from the C and Fortran versions. Also compare the
<strong>pymp</strong> multi-threaded and <strong>mpi4py</strong>
message-passing versions to the scalar version to see what changes were
made. If you haven’t already, run the scalar code and do scaling studies
with the multi-threaded and message-passing versions to see how they
compare with versions written in other languages.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>While the syntax is different, the code is basically the same in each
language. Performance is much slower for raw Python code than the
compiled language. From looking at the same code in various languages,
which do you think would be easiest to write from scratch?</p>
</div>
</div>
</div>
</div>
<div id="compare-the-raw-matrix-multiply-code-to-a-numpy-version" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="compare-the-raw-matrix-multiply-code-to-a-numpy-version" class="callout-inner">
<h3 class="callout-title">Compare the raw matrix multiply code to a
<strong>NumPy</strong> version</h3>
<div class="callout-content">
<p>Do a scaling study of the <strong>matmult.py</strong> code for
various matrix sizes of 10, 100, and 1000. Compare this to the
<strong>matmult_numpy.py</strong> version to see how much of a
difference the highly-tuned library function makes.</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>If you have already run the optimized C version, you may notice that
the compiled code still beats the optimized <strong>NumPy</strong>
routine by 2-4 times in my tests. Using the <strong>NumPy</strong>
routine closes the performance gap enormously but the C version is still
better.</p>
</div>
</div>
</div>
</div>
<div id="optional-exercise---try-compiling-a-python-code" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="optional-exercise---try-compiling-a-python-code" class="callout-inner">
<h3 class="callout-title">Optional Exercise - Try compiling a Python
code</h3>
<div class="callout-content">
<p>If you have time, try compiling one of the Python test codes supplied
like <strong>matmult_numpy.py</strong>. Then try running it without an
active virtual environment meaning that there is no
<strong>NumPy</strong> library installed.</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Show me the solution </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" aria-labelledby="headingSolution3" data-bs-parent="#accordionSolution3">
<div class="accordion-body">
<p>Once compiled you should be able to run this with a command like:
<strong>./matmult.pyc 100</strong>.</p>
</div>
</div>
</div>
</div>
<div id="optional-exercise---try-implementing-memory-profiler-or-line_profiler" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="optional-exercise---try-implementing-memory-profiler-or-line_profiler" class="callout-inner">
<h3 class="callout-title">Optional Exercise - Try implementing
memory-profiler or line_profiler</h3>
<div class="callout-content">
<p>If you have time, try implementing memory-profiler or line_profiler
in one of the Python test codes supplied like
<strong>matmult_numpy.py</strong>. Then try running the code to see the
memory or timing output.</p>
</div>
</div>
</div>
<div id="accordionSolution4" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution4" aria-expanded="false" aria-controls="collapseSolution4">
  <h4 class="accordion-header" id="headingSolution4"> Show me the solution </h4>
</button>
<div id="collapseSolution4" class="accordion-collapse collapse" aria-labelledby="headingSolution4" data-bs-parent="#accordionSolution4">
<div class="accordion-body">

</div>
</div>
</div>
</div>
<div id="optional-homework---test-the-numba-version-of-the-dot-product-code" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="optional-homework---test-the-numba-version-of-the-dot-product-code" class="callout-inner">
<h3 class="callout-title">Optional Homework - Test the
<strong>Numba</strong> version of the dot product code</h3>
<div class="callout-content">
<p>Do a <strong>pip install numba</strong> then time the
<strong>dot_product_numba.py</strong> performance and compare to the raw
code. Does the performance change if you cache the compilation by adding
<strong>cache=True</strong>? You will need to run twice so that the
second time takes advantage of the cached compilation code.</p>
</div>
</div>
</div>
<div id="accordionSolution5" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution5" aria-expanded="false" aria-controls="collapseSolution5">
  <h4 class="accordion-header" id="headingSolution5"> Show me the solution </h4>
</button>
<div id="collapseSolution5" class="accordion-collapse collapse" aria-labelledby="headingSolution5" data-bs-parent="#accordionSolution5">
<div class="accordion-body">
<p>Notice that in this code we needed to rewrite the computationally
intensive loops into functions. This does not take much effort but does
disrupt the program flow somewhat, but if it speeds up the runtime it is
usually worth it. Unfortunately in the case of the dot product the
<strong>Numba</strong> version takes 13 seconds compared to only 90
milliseconds for the raw code. Adding <strong>cache=True</strong> to
cache the compiled code does reduce the runtime down to 3.7 seconds but
this is still substantially worse than the original code. There are also
warnings about lists being deprecated as input arguments in the near
future. Switching our algorithm to use <strong>NumPy</strong> arrays may
be necessary but this also defeats the purpose of using
<strong>Numba</strong> since <strong>NumPy</strong> already has
optimized routines for the algorithms we are testing. So in short this
isn’t a really good test of the capabilities of <strong>Numba</strong>,
but is a good example of how these things don’t always work as hoped,
and it illustrates that <strong>Numba</strong> does not support all
aspects of Python. Forcing the computational parts of an algorithm into
functions is also detracts from the flow of any program, and is
definitely not what is considered as the Python way.</p>
</div>
</div>
</div>
</div>
<div id="optional-homework---write-a-pi-calculation-program-using-numba" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="optional-homework---write-a-pi-calculation-program-using-numba" class="callout-inner">
<h3 class="callout-title">Optional Homework - Write a Pi calculation
program using <strong>Numba</strong>
</h3>
<div class="callout-content">
<p>Write a Python version of the Pi calculation program and time raw
Python code versus <strong>Numba</strong> optimized. If you want to have
more fun try out <strong>Numba</strong> multi-threading compared to
<strong>pymp</strong> for this same algorithm. This is a much fairer
test of the capabilities of <strong>Numba</strong> since we are not
comparing it to optimized functions in <strong>NumPy</strong>.</p>
</div>
</div>
</div>
<div id="accordionSolution6" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution6" aria-expanded="false" aria-controls="collapseSolution6">
  <h4 class="accordion-header" id="headingSolution6"> Show me the solution </h4>
</button>
<div id="collapseSolution6" class="accordion-collapse collapse" aria-labelledby="headingSolution6" data-bs-parent="#accordionSolution6">
<div class="accordion-body">
<p>If you do this please contribute your code and timings.</p>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Learn about the characteristics of the Python language.</li>
<li>When performance is important always use optimized libraries!!!</li>
</ul>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="links-for-additional-information">Links for additional information<a class="anchor" aria-label="anchor" href="#links-for-additional-information"></a>
</h3>
<ul>
<li><a href="https://docs.python.org/3/tutorial/" class="external-link">Python
tutorial</a></li>
<li><a href="https://github.com/classner/pymp" class="external-link">pymp multi-threading
package</a></li>
<li><a href="https://github.com/mpi4py/mpi4py" class="external-link">mpi4py on github</a></li>
<li><a href="https://mpi4py.readthedocs.io/" class="external-link">mpi4py
documentations</a></li>
<li><a href="">TensorFlow</a></li>
<li><a href="">Scikit</a></li>
<li><a href="https://dask.org" class="external-link">Dask</a></li>
<li><a href="https://numba.pydata.org" class="external-link">Numba</a></li>
<li><a href="https://carpentries-incubator.github.io/lesson-parallel-python/" class="external-link">Software
Carpentry Incubator lesson with Dask and Numba</a></li>
<li><a href="https://github.com/Parsl/parsl" class="external-link">Parsl python
package</a></li>
</ul>
</div></section><section id="aio-r"><p>Content from <a href="r.html">The R Language</a></p>
<hr>
<p>Last updated on 2025-09-12 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/r.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 50 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are the strengths and weaknesses of the R programming
language?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Analyze the merits of the R Language.</li>
<li>Learn what to avoid in R when performance is important.</li>
<li>Learn a little about how to parallelize R code.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="programming-in-the-r-language">Programming in the R Language<a class="anchor" aria-label="anchor" href="#programming-in-the-r-language"></a>
</h2>
<hr class="half-width">
<p>R is a high level programming language with an extremely rich set of
internal functions and add-on packages for statistical analysis and
other scientific programming. It is an interpretive language and
therefore the raw performance is not great. While there are ways to
write R code that performs better, it does take more work than in other
languages due to the many performance pitfalls inherent in the language,
and often you have to sift through the the many external packages to
find ones that work well for your needs. This section will try to
identify those pitfalls and present higher-performing alternatives.</p>
<p>R code is identified with the <strong>.R</strong> ending. External
add-on packages are installed into the user’s base directory under a
sub-directory also named <strong>R</strong>. These packages can be
easily installed from the <strong>CRAN</strong> mirrors using commands
like <strong>install.packages(“data.table”)</strong> then referenced in
the code with a similar statement like
<strong>library(data.table)</strong>. The wide range of scientific and
code packages available in R and their ease of installation and use are
the language’s real strengths.</p>
<p>R programs can be run through the Linux command line interface (CLI),
submitted to batch queues, or run interactively from the CLI or the
popular graphical user interface Rstudio. The package Rshiny also makes
it easy to build interactive web applications from R.</p>
<p>R is like Python in that both are interpretive languages and both can
easily be used interactively which is helpful for minimizing the code
development cycle. The programmer is constantly changing the code and
immediately seeing the results. This strength in easing the development
cycle is also one source of its weaknesses in performance as
interpretive languages only execute a single line of code at a time
while compiled languages take whole blocks of code like the bodies of
loops and highly optimize them before execution time, but this is the
same trade-off that many languages face.</p>
<p>You can run R codes on multiple cores, but the parallel capabilities
of R are much more limited than the compiled languages C/C++ and Fortran
and even compared to Python. The basic parallel model for R is that
loops whether from <strong>lapply()</strong> or <strong>foreach</strong>
return an object that is either a list or a data frame with one entry
for the results from each pass through the loop. If your code uses the
loops in this manner then parallelizing them is relatively easy as you
just need to choose a back-end package to use, tell it how many cores
you want to use, then change the <strong>lapply()</strong> to an
<strong>mclapply()</strong> or the <strong>%do%</strong> in the
<strong>foreach</strong> to a <strong>%%dopar%</strong>.</p>
<p>There are many multi-threaded back end options to choose from. The
<strong>parallel</strong> library is now built into R and is a merger of
the <strong>multicore</strong> and <strong>snow</strong> libraries. The
<strong>dot_product_threaded.R</strong> code shows that the programming
approach is a little clunky in that the body of the loop needs to be put
in a function, but the efficiency is comparable to other back ends. The
<strong>doParallel</strong> library is a merger of the
<strong>doSNOW</strong> and <strong>doMC</strong> libraries. The
<strong>foreach</strong> command with <strong>dopar</strong> make for
cleaner programming that looks more like traditional loops. The
<strong>dot_product_threaded_dopar.R</strong> code shows that a little
extra programming can be used to greatly reduced the overhead even for
loops with little computatotions.</p>
<p>However, it is very common in scientific codes to want to instead
have all parallel tasks operate on a shared-memory object like the
resulting matrix in our matrix multiplication example. People in the R
community often refer to back-end methods that use a
<strong>fork</strong> as shared-memory since the data structures can be
referenced in place in a shared manner as long as they are not written
to. This is quite different than what the HPC community refers to as
shared-memory, where all threads can write to a common data structure
and it is up to the programmer to ensure that threads don’t obstruct
each other.</p>
<p>Our matrix multiplication example illustrates this difference as the
source matrices A and B can be shared in R since they are read-only,
saving great time when a back-end that uses a virtual-memory fork is
used, but the elements of the result matrix C needs to be filled in by
each thread. In R this is very difficult while it is common place in the
compiled languages C/C++/Fortran as well as in Python. I have not found
any example code yet to do this in R though I have seen references that
it can be done with a <strong>bigmemory</strong> package and a lot of
jumping through hoops that goes well beyond the scope of this course.
There are also some methods of altering the default matrix
multiplication package used in the **%*%** operation but these are very
operating-system dependent.</p>
<p>There is extensive support for running C/C++/Fortran code across
multiple nodes using the message-passing interface MPI, and Python has a
stripped down version of this with the <strong>mpi4py</strong> package.
There is a package for R called <strong>Rmpi</strong> that provides
wrappers around some of the common MPI functions, but it old code that
is being updated every few years and it can be difficult to get working
as you need certain versions of R and OpenMPI for everything to work.
Under Windows you must compile with Microsoft MPI, and there are some
limitations in functionality.</p>
<p>The doMPI back-end to <strong>foreach</strong> runs on this Rmpi
package. This perfectly fits into the R parallelization model where the
programmer can just slip in a different back end to fit their needs, but
this often results in poor parallel performance which is the case with
doMPI. The <strong>dot_product_doMPI.R</strong> code can be used to test
the performance for a simple application compared multi-core back ends.
There’s also a newer package called <strong>Rhpc</strong> which
supposedly provides better performance but it was removed from the CRAN
repository some years ago.</p>
<p>There is a newer package called <strong>pdbMPI</strong> where the
<em>pbd</em> stands for Programming with Big Data. This is an interface
to the Message-Passing Initiative that is the foundation for distributed
parallel computing in the HPC community, and also is a dependency for
the <strong>pdbDMAT</strong> and <strong>kazaam</strong> packages for
working with matrices across multiple compute nodes. These packages are
much more recently developed and while still having 0.x version numbers
they are actively managed and being used on large supercomputer systems.
These provide true interfaces to MPI functions, not a back-end to
<strong>mclapply()</strong> or <strong>dopar</strong>, so they are more
difficult to use but also much more powerful.</p>
</section><section><h2 class="section-heading" id="performance-pitfalls-in-r">Performance Pitfalls in R<a class="anchor" aria-label="anchor" href="#performance-pitfalls-in-r"></a>
</h2>
<hr class="half-width">
<p>While all languages take effort to optimize and parallelize when
performance becomes important, with R it is often more about what
aspects of the language need to be avoided that are inhibiting
performance.</p>
<div class="section level3">
<h3 id="profiling-function">Profiling function<a class="anchor" aria-label="anchor" href="#profiling-function"></a>
</h3>
<p>As with most languages there are many methods that can be used to
time sections of code in order to understand where time is being spent.
For R the best options are to bracket the code of interest with calls
like <strong>t_start &lt;- proc.time()[[3]]</strong> and <strong>t_end
&lt;- proc.time()[[3]]</strong> then take the difference. The
<strong>proc.time()</strong> function will provide the best clock
available and the <strong>[[3]]</strong> part takes the elapsed or real
time that we want. The <strong>system.time()</strong> function can also
be used which returns the time taken to execute the function put in the
parentheses. This uses the same <strong>proc.time()</strong> clock but
may provide a more convenient method in some cases.</p>
<p>Another common approach that should be avoided is to use the
<strong>Sys.time()</strong> function. This similarly reports the time
between the bracketed code, but it by default auto-adjusts the units to
the length of the interval. So if your code takes 59 seconds it will
report 59, but if the same code takes 60 seconds it will auto-adjust to
minutes and report 1 instead. You can and always should manually specify
the units if you choose to use this function.</p>
</div>
<div class="section level3">
<h3 id="dataframes-and-the-rbind-function">Dataframes and the rbind() function<a class="anchor" aria-label="anchor" href="#dataframes-and-the-rbind-function"></a>
</h3>
<p>Dataframes are a very valuable and integral part of the R language.
The results from loops or functions are often returned in the form of
dataframes, and the input and output of data is built more on dumping
out whole dataframes to files than the line-by-line approaches that
other languages use. Dataframes in R are designed internally to be very
flexible to enable all of this, but this same design choice makes them
extremely inefficient from a computational view when working with larger
data sets.</p>
<p>The best example of this is the <strong>rbind()</strong> function
which is used to build a dataframe. It is very common to build a row of
data using <strong>cbind()</strong>then use <strong>rbind()</strong> to
add the row to the dataframe table, but internally R must allocate an
entirely new area of memory and copy all the existing data over as well
as the new data. This is because R is a column-major language so
elements in a column are stored next to each other. If R was row-major
then other alternatives would be present like having an array pointing
to each row in memory.</p>
<p>Having to recopy the entire dataframe each time a row is added is an
enormous performance penalty. I was approached with an R code and asked
to optimize and parallelize it since it was going to take a month of
runtime to complete. We generated a test case that took one hour, and
after commenting out only the <strong>rbind()</strong> function the
calculations took only 5 seconds. All the rest of the time was spent
copying the dataframe data to newly allocated memory each time a row was
added to the bottom.</p>
<p>If the code is building the dataframe just to dump it out to a file,
then one option is to simply print each row to file. R isn’t really
designed as well for this so it isn’t always optimal, but often is a
huge improvement over the <strong>rbind()</strong> inefficiency.</p>
<p>A better option is to use the <strong>data.table</strong> package
which is a drop in alternative to a dataframe. It is not as easy to use,
but is immensely more efficient than a dataframe since you can
pre-allocate the structure and insert values rather than having to
constantly rebuild the dataframe structure. There will be an exercise at
the end of this section that will allow you to see the difference in the
code and measure the performance of each approach.</p>
</div>
</section><section><h2 class="section-heading" id="parallelizing-r-code">Parallelizing R code<a class="anchor" aria-label="anchor" href="#parallelizing-r-code"></a>
</h2>
<hr class="half-width">
<p>As mentioned above, when a loop is parallelizable it is conceptually
fairly easy to accomplish this. The <strong>lapply()</strong> function
has a multi-core version <strong>mclapply()</strong> that spawns
multiple threads on a single compute node. The <strong>foreach</strong>
command can be parallelized by changing the <strong>%do%</strong> to
<strong>%dopar%</strong>. Both of these commands are part of the core
<strong>parallel</strong> library in R, but to make them work you need
to decide which of the many back-end library packages to use.</p>
<p>Considerations include whether you may need to run on Windows OS
which does not support the <strong>fork()</strong> function that is the
more efficient way to implement the needed functionality, whether you
may need to run a job across multiple compute nodes, and whether you
need to use shared-memory in your threads to enable working on a common
data set. Packages based on the <strong>fork()</strong> mechanism use
virtual memory rather than redundantly copying all data structures
needed. This can be enormously more efficient when dealing with large
data structures as each thread only gets a copy of the pages in memory
that it needs to alter. In our matrix multiplication example, that means
that the two matrices that only need to be read never get copied to each
thread, and the for matrix that is being calculated only the parts that
each thread is modifying get copied. For this reason it is always
recommended to use a back-end library based on <strong>fork()</strong>,
but Windows does not support this functionality so you may need to
consider other options that fully copy all data structures at the start
or even a socket-based cluster if you think your code might need to run
on Windows. Another option would be to install the Windows Subsystem for
Linux (WSL) which supports the <strong>fork)</strong> function.</p>
<p>The basic parallelization model for both approaches is the same, to
have each pass through the loop executed on different cores with one
line of data being returned for each iteration in the form of a list or
data frame. When the goal is to instead operate on a common data set
such as in our matrix multiplication example, then shared-memory is
needed. There are not very many back-end packages that support this
approach even though it is a very common need. In our matrix
multiplication example code we use the <strong>mcparallel</strong>
back-end and the <strong>bigmemory</strong> package. These are designed
to work on matrices, but would not work if you for example wanted all
threads to work on a different data structure like a shared-memory
data.table.</p>
<div class="section level3">
<h3 id="mclapply-pitfalls">mclapply() pitfalls<a class="anchor" aria-label="anchor" href="#mclapply-pitfalls"></a>
</h3>
<p>The <strong>mclapply()</strong> function is fairly straight forward
to use since you mostly need to supply the number of cores through the
<strong>mc.cores=</strong> argument. There are options to tune the way
the parallelization is done. The <strong>mc.preschedule=mRUE</strong>
argument is the default, and this means that the number of iterations is
divided among the available cores at the start. This is highly
recommended since if this is turned off the system will fork a new
process for each iteration, do the work, then collapse that fork. This
can be incredibly inefficient since it means copying data structures
many times over so it should in general be avoided. If you do try this,
make sure to check the performance for both options as this choice can
drastically effect the efficiency of the resulting parallel
implementation.</p>
<div id="compare-raw-and-optimized-performance-of-matmult.r" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="compare-raw-and-optimized-performance-of-matmult.r" class="callout-inner">
<h3 class="callout-title">Compare raw and optimized performance of
matmult.R</h3>
<div class="callout-content">
<p>Run matmult_loops.R, matmult_foreach.R, and matmult_builtin.R for
matrix sizes 100 and 1000 to compare the performance of a raw loop to
the built-in matrix multiplication function. Also compare these numbers
to other languages.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>I measured 500 seconds for the raw loop in R and 0.10 seconds for the
optimized built-in matrix multiplication function. Be aware that the
built-in function may use all the cores it has access to, so this may
not be a fair comparison unless you submit a batch scheduler job with
only 1 core allocated. Python for comparison took 300 seconds for raw
loops and 0.13 seconds for the <strong>numpy</strong> optimized routine,
but a larger run for size 10,000 had <strong>numpy</strong> at 46
seconds compared to <strong>R</strong> at 72 seconds. So in general, R
and Python are similar in speed for both raw and optimized code, but
Python is a little faster.</p>
</div>
</div>
</div>
</div>
<div id="test-the-scaling-of-the-rbind-function" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="test-the-scaling-of-the-rbind-function" class="callout-inner">
<h3 class="callout-title">Test the scaling of the rbind() function</h3>
<div class="callout-content">
<p>Profile the run time for using rbind() as the number of rows in the
data frame increases. Time runs of <strong>rbind.R</strong> for 10, 100,
1000, and 10000 rows.</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<p>While rbind() is convenient and works well for small data frames, the
time to add rows begins to increase exponentially for data frames around
10,000 rows. I measured 1 second for 1000 rows, 48 seconds for 10,000
rows, and 5100 seconds for 100,000 rows. <strong>rbind()</strong> works
well for small data frames, but it is very inefficient when you scale up
to larger data sets of over 10,000 rows. This is because R copies the
entire data frame over each time it adds a new row.</p>
</div>
</div>
</div>
</div>
<div id="investigate-the-data-table-performance." class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="investigate-the-data-table-performance." class="callout-inner">
<h3 class="callout-title">Investigate the data table performance.</h3>
<div class="callout-content">
<p>Test the <strong>datatable.R</strong> code for 100, 1000, and 10000
rows and compare to the rbind() results.</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Show me the solution </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" data-bs-parent="#accordionSolution3" aria-labelledby="headingSolution3">
<div class="accordion-body">
<p>For 1,000 rows I measured 0.12 seconds for a data table set()
compared to 5.4 seconds for a data table assignment and 1.1 second for a
data frame rbind(). For 10,000 rows the performance really starts to
differ with 0.53 seconds for a data table set() compared to 50 seconds
for a data table assignment and 48 seconds for a data frame rbind(). For
a large test of 100,000 rows the data table set() still only took 5
seconds while the data table assignment took 485 seconds and the data
frame rbind() took 5100 seconds, or 1000x longer. This again shows that
while data frames can be convenient, when you scale up to larger sizes
you have to use data tables and the set() function.</p>
</div>
</div>
</div>
</div>
<div id="optional-homework---test-the-io-performance-in-r." class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="optional-homework---test-the-io-performance-in-r." class="callout-inner">
<h3 class="callout-title">Optional Homework - Test the IO performance in
R.</h3>
<div class="callout-content">
<p>Test the <strong>fread.R</strong> code to see the speedup of the
<strong>fread()</strong> function from the optimized
<strong>data.table</strong> package compared to the standard
<strong>read.csv()</strong>. Time runs of <strong>fread.R</strong> for
10,000 rows, 100,000 rows, and 1,000,000 rows.</p>
</div>
</div>
</div>
<div id="accordionSolution4" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution4" aria-expanded="false" aria-controls="collapseSolution4">
  <h4 class="accordion-header" id="headingSolution4"> Show me the solution </h4>
</button>
<div id="collapseSolution4" class="accordion-collapse collapse" data-bs-parent="#accordionSolution4" aria-labelledby="headingSolution4">
<div class="accordion-body">
<p>For 10,000 rows I saw similar results for each function, but for
100,000 rows <strong>fread()</strong> was 10 times faster than
<strong>read.csv()</strong> and for 1,000,000 rows it was 100 times
faster. This is another example illustrating when to avoid the core R
functionality and use the external add-on packages to achieve
performance in your code.</p>
</div>
</div>
</div>
</div>
<div id="advanced-homework---use-the-pdbmpi-package-to-code-and-run-a-parallel-hello-world-program" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="advanced-homework---use-the-pdbmpi-package-to-code-and-run-a-parallel-hello-world-program" class="callout-inner">
<h3 class="callout-title">Advanced Homework - Use the
<strong>pdbMPI</strong> package to code and run a parallel Hello World
program</h3>
<div class="callout-content">
<p>For those who want a challenge, follow the <strong>pdbMPI</strong>
link at the end of this lesson an write, run, and test the Hello World
program.</p>
</div>
</div>
</div>
<div id="accordionSolution5" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution5" aria-expanded="false" aria-controls="collapseSolution5">
  <h4 class="accordion-header" id="headingSolution5"> Show me the solution </h4>
</button>
<div id="collapseSolution5" class="accordion-collapse collapse" data-bs-parent="#accordionSolution5" aria-labelledby="headingSolution5">
<div class="accordion-body">
<p>I would love to have a pdbMPI-based matrix multiply code available
for people to look at and test if anyone finds one.</p>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="summary">Summary<a class="anchor" aria-label="anchor" href="#summary"></a>
</h2>
<hr class="half-width">
<p>R is a very powerful language because of the enormous set of
statistical and external scientific libraries that have been developed
for it. It can however be difficult to program in since much effort
involves programming in supplemental packages rather than the core
language. Users need to therefore know not only the core R language, but
be familiar with which external programming packages to use when more
performance or flexibility is needed, and this can be an ever changing
target.</p>
<p>It is often very challenging to get good performance out of R code.
Elements of the core language like dataframes have inherent performance
and scaling problems. Parallelization seems as easy as registering the
desired number of cores and changing the <strong>%do%</strong> in a
<strong>foreach</strong> loop to <strong>%dopar%</strong>, but setting
up writable shared-memory is difficult to impossible. Each back-end
package has different capabilities and efficiencies so it can be
difficult to decide which approach is best. While it is possible to
achieve good performance with R code, much of the work involves
programming around the built-in capabilities using optimized add-on
libraries, and you have to understand which of the many packages to
utilize. It is hoped that this section can at least steer people in the
correct direction with some of these performance oriented issues.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Learn about the characteristics of the R language.</li>
</ul>
</div>
</div>
</div>
<div class="section level3">
<h3 id="links-for-additional-information">Links for additional information<a class="anchor" aria-label="anchor" href="#links-for-additional-information"></a>
</h3>
<ul>
<li><a href="https://www.r-project.org/other-docs.html" class="external-link">R
documentation</a></li>
<li><a href="https://cran.r-project.org/web/packages/foreach/vignettes/foreach.html" class="external-link">Foreach
function</a></li>
<li><a href="https://www.rdocumentation.org/packages/parallel/versions/3.4.0/topics/mclapply" class="external-link">mclapply
function</a></li>
<li><a href="https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html" class="external-link">data.table
package</a></li>
<li><a href="https://github.com/snoweye/pbdMPI" class="external-link">Programming with Big
Data - MPI package</a></li>
<li><a href="https://github.com/RBigData/pbdDMAT" class="external-link">pdbDMAT
package</a></li>
<li><a href="https://www.rstudio.com" class="external-link">Rstudio</a></li>
<li><a href="https://shiny.rstudio.com" class="external-link">Rshiny</a></li>
</ul>
</div>
</section></section><section id="aio-matlab"><p>Content from <a href="matlab.html">The Matlab Language</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/matlab.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 30 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are the strengths and weaknesses of the Matlab language?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand the performance and parallelization characteristics of
Matlab.</li>
<li>Learn the practicality of using the Matlab compiler on HPC
systems.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="programming-in-the-matlab-language">Programming in the Matlab Language<a class="anchor" aria-label="anchor" href="#programming-in-the-matlab-language"></a>
</h2>
<hr class="half-width">
<p>Matlab is a commercial programming language designed for broad use in
science and mathematics. The obvious drawback of it being commercial
software is that it costs money and has licensing restrictions when you
use it. The more positive aspect is that it is professionally developed
and maintained with lots of advanced science modules.</p>
<p>The core Matlab code is interpreted which limits its speed but there
are lots of highly optimized and parallelized low level operations that
often lead to very good performance. Users can also parallelize code
manually using <strong>parfor</strong> loops which are easy to implement
but difficult to make efficient. Many modules are also programmed to run
on NVIDIA GPUs for acceleration.</p>
<p>There is a free language <strong>GNU Octave</strong> that runs much
of raw Matlab code. Some of the more advanced features are not
supported, but some like parallelization simply have a different format.
Octave also has lots of user-contributed modules covering a broad range
of science and mathematics.</p>
<div class="section level3">
<h3 id="matlab-toolboxes">Matlab Toolboxes<a class="anchor" aria-label="anchor" href="#matlab-toolboxes"></a>
</h3>
<p>The Matlab core can be enhanced with a very wide variety of add-on
toolboxes. Some are more generic while others are very specific to
certain areas of science. Some of the more common ones include:</p>
<ul>
<li>Parallel Computing Toolbox</li>
<li>Simulink - Simulation and Model-Based Design</li>
<li>Statistics and Machine Learning</li>
<li>Curve Fitting</li>
<li>Control Systems</li>
<li>Signal Processing</li>
<li>Mapping</li>
<li>System Identification</li>
<li>Deep Learning</li>
<li>DSP System</li>
<li>Datafeed</li>
<li>Financial</li>
<li>Image Processing</li>
<li>Text Analytics</li>
<li>Predictive Maintenance</li>
</ul>
<p>There are many domain-specific toolboxes that include Bioinformatics,
Aerospace, Wavelets, and Econometrics to name a few.</p>
</div>
<div class="section level3">
<h3 id="commercial-licensing-restrictions-and-costs">Commercial licensing restrictions and costs<a class="anchor" aria-label="anchor" href="#commercial-licensing-restrictions-and-costs"></a>
</h3>
<p>Matlab has a base cost with toolboxes being extra. There are annual
and perpetual licenses with all pricing being in U.S. dollars.</p>
<p><a href="https://www.mathworks.com/pricing-licensing.html?prodcode=ML&amp;intendeduse=student" class="external-link">click
here for pricing</a></p>
<p>There are huge educational discounts with students paying under a
hundred U.S. dollars for Matlab, Simulink, and 10 add-on toolboxes.
Teachers and researchers also get large discounts, but add-on toolboxes
can increase the cost quickly as the more common ones can run a few
hundred dollars and more specialized toolboxes even more.</p>
<p>Licenses for HPC clusters can be floating meaning that each license
can be checked out by an authorized user and used on a given number of
processors or nodes. This does require a license server to be set up
which can be done on the HPC cluster or handled remotely. Just be aware
that with commercial software there is additional setup required as well
as costs.</p>
</div>
<div class="section level3">
<h3 id="using-the-matlab-compiler">Using the Matlab compiler<a class="anchor" aria-label="anchor" href="#using-the-matlab-compiler"></a>
</h3>
<p>When we talk about compiling for C/C++ and Fortran, we are talking
about analyzing a block of code like the body of a loop to optimize the
code so that it runs faster. Matlab and Python both have compilers but
neither does this. In both cases the compiler packages up the code,
interpreter, and libraries into an executable that can be run
independently. The compiled code therefore does not run any faster.</p>
<p>A programmer will always start by developing and running their code
in raw form which requires checking out a Matlab license. If you need to
share your Matlab code with others who do not have access to a Matlab
license, then you would want to compile the code to package it into an
executable that doesn’t need Matlab to run. In an HPC cluster context,
you still want to develop your code in raw Matlab but when it is time to
run you want to again compile it into an executable so that many copies
can be run without needing a separate Matlab license for each. In this
way, an HPC center only needs as many Matlab licenses as they want to
have simultaneous users developing code rather than needing to support
the number of jobs run.</p>
<div class="section level4">
<h4 id="minor-compiler-mcc-gotcha">Minor compiler mcc gotcha<a class="anchor" aria-label="anchor" href="#minor-compiler-mcc-gotcha"></a>
</h4>
<p>When you run the Matlab compiler, it does check the license out for a
half hour at a time so if you just have a single license for a cluster
users may end up waiting a bit for access.</p>
</div>
</div>
<div class="section level3">
<h3 id="performance">Performance<a class="anchor" aria-label="anchor" href="#performance"></a>
</h3>
<p>Matlab is not a compiled language so raw code is much slower than
C/C++/Fortran. It is however faster than Python and R as shown in the
serial matrix multiply of 1000x1000 matrices taking 5 seconds compared
to Python at 306 seconds. The built-in routines that are optimized and
parallelized are going to be similar in the different languages, and in
this case Matlab takes 0.7 seconds while the Numpy version in Python
takes 0.13 seconds in the same test.</p>
<p>Matlab does have very strong integration with optimized and
parallelized library routines throughout its modules which brings
automatic efficiency and parallelization when available.</p>
</div>
</section><section><h2 class="section-heading" id="parallelization-methods">Parallelization methods<a class="anchor" aria-label="anchor" href="#parallelization-methods"></a>
</h2>
<hr class="half-width">
<p>The <strong>Parallel Computing Toolbox</strong> is the source of most
of the parallel computing capabilities in Matlab. It provides the
ability to program using multiple cores, multiple nodes, and GPUs
without explicitly using CUDA or MPI. Matlab also includes a wide
variety of parallelized numerical libraries at its core to automatically
take advantage of the hardware you allocate to your job. The
<strong>Simulink</strong> toolkit allows the user to set up and run
multiple simulations of a model in parallel. The <strong>Matlab Parallel
Server</strong> can also be used to run matrix calculations that are too
large to fit in the memory of a single computer.</p>
<div class="section level3">
<h3 id="parallelizing-loops-with-parfor">Parallelizing loops with <strong>parfor</strong>
<a class="anchor" aria-label="anchor" href="#parallelizing-loops-with-parfor"></a>
</h3>
<p>When iterations of a <strong>for</strong> loop do not depend on each
other, the iterations can be spread across multiple processes within the
same compute node in a distributed-memory manner, multiple threads in a
shared-memory approach, or they can be spread across multiple nodes. All
3 approaches are accomplished by changing the <strong>for</strong> loop
to a <strong>parfor</strong> loop. Computations will be split across
multiple cores whether they are on the same compute node or multiple
nodes. This provides a very easy means of parallelizing code and the
flexibility of running the same code in a variety of parallel
environments.</p>
<p>This flexibility comes with a prices though. Distributed-memory
approaches are often only efficient when the flow of data between
processes is careful controlled which is not possible here. It often
requires much more work to get the needed efficiency out of complex
algorithms. This type of automatic distributed-memory approach also
results in large data sets being redundantly copied to all processes
which can lead to extra execution time for the communications and much
extra memory usage. So if you are working with a 1 GB size matrix and
want to run on a 128 core AMD system you would have to copy and
redundantly store 128 GB of data at the start.</p>
<p>The multi-threaded approach is designed to avoid this redundant
memory use by leaving read-only data sets in place rather than copying
them to each thread. This holds much greater promise conceptually, but
tests with a simple parallel matrix multiplication are showing much
slower times than expected. Even a parallel dot product which is
trivially parallel takes longer than the serial version so it is unclear
how useful even the multi-threaded <strong>parfor</strong> is in
general.</p>
<p>So while Matlab provides an easy-to-use and flexible parallel
programming environment with <strong>parfor</strong>, it can suffer
greatly when dealing with large data sets and complex algorithms, and
doesn’t even do all that well on simple algorithms. From these tests so
far I would recommend using this approach mostly for trivially parallel
algorithms and smaller data sets and testing very carefully.</p>
<p><strong>NOTE: Loop iterations are non-deterministic and indices must
be consecutive increasing integers, and there is no nesting of loops
allowed.</strong></p>
</div>
</section><section><h2 class="section-heading" id="octave">Octave<a class="anchor" aria-label="anchor" href="#octave"></a>
</h2>
<hr class="half-width">
<p>GNU Octave is a language that is largely compatible with Matlab, but
it is free and unlicensed. It can be used to run many Matlab programs
using <strong>octave &lt; matlab_code.m</strong> though many advanced
features of Matlab may not be supported. There are many add-on packages
available for Octave but these are different from those available for
Matlab.</p>
<p>There is a <strong>parallel</strong> toolbox that is well developed.
This provides a local parallel execution environment similar to the
single-node multi-process capability of <strong>parpool</strong>. There
are also tools to work with clusters of computers, but these are more
similar to message-passing commands where you manually send and receive
data to and from remote processes and manually initiate function
evaluation.</p>
<div id="test-the-performance-of-the-matlab-matrix-multiplication-code." class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="test-the-performance-of-the-matlab-matrix-multiplication-code." class="callout-inner">
<h3 class="callout-title">Test the performance of the Matlab matrix
multiplication code.</h3>
<div class="callout-content">
<p>If you have access to a Matlab license or Octave, test the
performance of the <strong>matmult.m</strong> code for a matrix size of
1000 and compare to other languages.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>For the 1000x1000 matrices, I measure 5 seconds for the serial code,
0.7 seconds for the built-in matrix multiply that uses low level
optimized BLAS routines. The parpool multi-process test takes 530
seconds which is understandably slow since it is doing the matrix
multiplication in a distributed memory manner without explicitly
programming it to do this efficiently. The multi-threaded parpool test
measured in at &gt; 510 seconds which is very disappointing since there
should be no copying of the matrices at the beginning. It isn’t clear
what is happening behind the scenes for this to be so slow.</p>
</div>
</div>
</div>
</div>
<div id="test-the-performance-of-the-matlab-dot-product-code." class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="test-the-performance-of-the-matlab-dot-product-code." class="callout-inner">
<h3 class="callout-title">Test the performance of the Matlab dot product
code.</h3>
<div class="callout-content">
<p>Test the performance of the <strong>dot_product.m</strong> code for
an array size of 100,000,000 and compare to other languages.</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<p>I measure serial performance at 0.5 seconds with the built in
optimized routine at 0.2 seconds on 8 cores for a modest speedup. The
multi-core <strong>parfor</strong> loop on the same 8 cores takes 2.1
seconds while the multi-threaded <strong>parfor</strong> loop takes a
disappointing 0.9 seconds which is still greater than the serial code.
The overhead for using these methods is still much larger than the
performance gain which indicates the parfor method should only really be
used for very coarse grained algorithms.</p>
</div>
</div>
</div>
</div>
<div id="optional-homework-alter-the-matmult.m-code-to-run-on-multiple-nodes-and-multiple-cores." class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="optional-homework-alter-the-matmult.m-code-to-run-on-multiple-nodes-and-multiple-cores." class="callout-inner">
<h3 class="callout-title">Optional Homework: Alter the
<strong>matmult.m</strong> code to run on multiple nodes and multiple
cores.</h3>
<div class="callout-content">
<p>Test on multiple compute nodes and compare performance to the serial
and multi-threaded versions. If you want a real challenge try setting
the code up to run on a cloud server. And an even bigger challenge would
be to convert matmult.m to run on Octave’s parallel computing
environments.</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Show me the solution </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" data-bs-parent="#accordionSolution3" aria-labelledby="headingSolution3">
<div class="accordion-body">
<p>If you do develop code for this, let us know so we can consider
including your work for others to see.</p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="summary">Summary<a class="anchor" aria-label="anchor" href="#summary"></a>
</h2>
<hr class="half-width">
<p>The greatest value of Matlab is the very wide range of professionally
developed and maintained packages that are available in many areas of
science. This comes at a financial cost that often limits how codes can
be used, but some of this can be alleviated in an HPC environment by
using the Matlab <strong>mcc</strong> compiler to create an executable
that does not need a license to run on many compute nodes at once.</p>
<p>Matlab code itself is not that fast, but it uses highly-optimized
library routines seamlessly whenever possible. Adding parallelism into a
code manually is often as easy as changing the <strong>for</strong> loop
to a <strong>parfor</strong> loop, but flexibility and ease of use often
do not produce efficient code. These methods are probably only useful
for trivially parallel algorithms.</p>
<p>Octave is a viable option to avoid the cost of Matlab, and has many
add-on packages of its own as well as parallel computing capabilities.
You should however only expect the more basic Matlab codes to run with
Octave, then you would need to choose to split off into the Octave world
itself.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Learn about the characteristics of the Matlab language.</li>
</ul>
</div>
</div>
</div>
<div class="section level3">
<h3 id="links-for-additional-information">Links for additional information<a class="anchor" aria-label="anchor" href="#links-for-additional-information"></a>
</h3>
<ul>
<li><a href="https://www.mathworks.com/" class="external-link">Matlab documentation</a></li>
<li><a href="https://octave.org/" class="external-link">Octave website</a></li>
<li><a href="https://www.mathworks.com/products/parallel-computing.html" class="external-link">Matlab
Parallel Computing Toolbox</a></li>
<li><a href="https://www.mathworks.com/products/simulink.html" class="external-link">Matlab
Simulink</a></li>
<li><a href="https://www.mathworks.com/help/thingspeak/matlab-toolbox-access.html" class="external-link">Matlab
Toolboxes and Examples</a></li>
</ul>
</div>
</section></section><section id="aio-array-jobs"><p>Content from <a href="array-jobs.html">Array Jobs</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/array-jobs.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 15 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What do array jobs have to do with high-performance computing?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Learn what an array job is in a batch scheduler.</li>
<li>Understand what types of science can make use of array jobs.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="array-jobs-using-slurm">Array jobs using Slurm<a class="anchor" aria-label="anchor" href="#array-jobs-using-slurm"></a>
</h3>
<p>An array job is mostly just like a normal job script in that it has
arguments at the top prefaced with <strong>#SBATCH</strong> that tell
the scheduler what resources are being requested followed by a list of
commands to be executed at run time. The difference is that array jobs
have an extra allocation request line like <strong>#SBATCH
–array=1-5</strong> that tells the Slurm scheduler to launch in this
case 5 individual jobs identical in every way except that each will have
a different value for the environmental variable
<strong>$SLURM_ARRAY_TASK_ID</strong>. This variable can be used to make
each run unique as part of a series of related runs. It might be used as
an input argument to the code being run in order to let the application
determine what is different with each run. It may also be used to choose
a different input file from a list to use when running the application.
This is very flexible and is entirely up to the programmer to decide how
to use it.</p>
<p>For the job below the <strong>$SLURM_ARRAY_TASK_ID</strong> variable
will be set to 1, 3, or 5. since the script specifies that the task ID
starts at 1, ends at 5, and steps by 2.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co">#!/bin/bash -l</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="co">#SBATCH --job-name=array_test</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="co">#SBATCH --time=0-0:1:00</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="co">#SBATCH --nodes=1</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="co">#SBATCH --ntasks-per-node=1</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co">#SBATCH --mem=1G</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="co">#SBATCH --array=1-5:2</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="fu">hostname</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="bu">echo</span> <span class="st">"Hello from array task ID </span><span class="va">$SLURM_ARRAY_TASK_ID</span><span class="st">"</span></span></code></pre>
</div>
<div id="submit-an-array-job" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="submit-an-array-job" class="callout-inner">
<h3 class="callout-title">Submit an array job</h3>
<div class="callout-content">
<p>If you have access to an HPC system with Slurm installed, submit the
<strong>sb.array_test</strong> script from the <strong>scripts</strong>
sub-directory using <strong>sbatch sb.array_test</strong> then look at
the output. If your HPC system has a different scheduler you may need to
figure out how to submit an array job yourself and will need to write
the job script from scratch. If you want more of a challenge you can try
writing a script to choose an input filename from a list using
<strong>$SLURM_ARRAY_TASK_ID</strong>.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>This will run 3 individual jobs that will show the
<strong>$SLURM_ARRAY_TASK_ID</strong> to be 1, 3, or 5.</p>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="array-jobs-as-parallel-computing">Array jobs as parallel computing<a class="anchor" aria-label="anchor" href="#array-jobs-as-parallel-computing"></a>
</h3>
<p>Most of the time when we thing of parallel computing we think of
taking a single program and making it run faster by applying more
compute power to it in terms of more compute cores. Array jobs allow us
to do the same thing, but in this case we are running many individual
programs instead of just one.</p>
<p>One common area of science where we can make use of this is to do
what is called a parameter sweep. You may have a set of parameters such
as system temperature, pressure, atom type, and lattice type (atomic
arrangement) where you need to run the same code on all these different
input parameters. Array jobs allow you to do parameter sweeps like this
in a very convenient manner with a single job script. This makes it easy
to submit and manage.</p>
<p>Another common use is in doing statistical science. For applications
that use a random number sequence, you may want to run the same
simulation many times using a different seed to determine how the
results vary statistically as the random number sequence changes.</p>
</div>
<div class="section level3">
<h3 id="programming-habits-to-avoid">Programming habits to avoid<a class="anchor" aria-label="anchor" href="#programming-habits-to-avoid"></a>
</h3>
<p>Many programmers write scripts to submit lots of individual jobs
instead of making use of the array jobs functionality. While the result
is basically the same, this method should be avoided in general. Lots of
individual jobs can clog up the queue making it difficult for users to
see where other jobs are, and can also affect scheduling since batch
systems have limits on how deep they can look. Array jobs avoid both of
these issues and make it much easier to manage the resulting jobs since
canceling your array job is for instance just the same as canceling an
individual job.</p>
<p>The testing cycle is always more important when you are dealing with
large numbers of jobs. One user submitted an array job for tens of
thousands of tasks that had a typo in the email address so when it ran
it spammed the ticket system with tens of thousands of bounced emails.
Always start by running a few typical jobs to nail down your resource
requests. Running a test job with just a few array IDs will allow you to
ensure that each job is using the <strong>$SLURM_ARRAY_TASK_ID</strong>
in the desired manner. Then when you are confident that your script is
working as intended you are ready to submit the full array job.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Array jobs provide an easy way submit and manage large numbers of
similar jobs.</li>
<li>Array jobs are another way to do parallel computing, but by running
lots of small jobs individually.</li>
<li>Test your script carefully on a few array IDs before submitting the
full job.</li>
</ul>
</div>
</div>
</div>
</div></section><section id="aio-gpus"><p>Content from <a href="gpus.html">Accelerating Scientific Computing with GPUs</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/gpus.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 15 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What differences are there in handling applications that can use a
GPU?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Learn a little about how GPUs can accelerate some scientific
codes.</li>
<li>Understand the basics of compiling and running GPU codes.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="how-to-use-a-gpu-to-accelerate-scientific-calculations">How to use a GPU to Accelerate Scientific Calculations?<a class="anchor" aria-label="anchor" href="#how-to-use-a-gpu-to-accelerate-scientific-calculations"></a>
</h2>
<hr class="half-width">
<p>We normally think of a Graphics Processing Unit or GPU in terms of
displaying graphics to a computer monitor. GPU cards are designed with
many streaming processors that are great at performing lots of similar
computations. While this makes them ideal for doing graphics work, it
also makes them good for running some scientific codes. GPU cards can
accelerate some scientific codes by an order of magnitude while costing
much less than what the equivalent CPUs would.</p>
<p>NVIDIA dominates the GPU accelerating market with both 32-bit or
consumer grade GPUs like the NVIDIA RTX 4090 that can cost around $1500,
but they also produce 64-bit Tesla cards that have no graphics ports at
all and are only designed for scientific computing. These include the
NVIDIA A100 which can cost as much as $11,000 each or their newest H100
that can cost twice that. Compute nodes can host 1-8 GPU cards each and
in some systems the high-end A100s and H100s may be linked together
through a fast NVLink connection. Otherwise a multi-GPU run would need
to communication across the PCI bus.</p>
<p>AMD GPUs can also be used to accelerate scientific jobs and are
increasingly being found in the fastest supercomputers in the world. The
code development is still behind that of the NVIDIA CUDA community due
to its much later entrance into the scientific computing market. AMD has
a <strong>Hip</strong> compiler that is used to generate code for the
AMD GPUs, and it has the benefit of being able to compile the same code
for NVIDIA GPUs as well. The AMD GPU line includes 32-bit GPUs such as
the Radeon RX 6000 series and the 64-bit Radeon Instinct MI100 cards
with costs comparable to the NVIDIA line.</p>
<div class="section level3">
<h3 id="using-gpus-for-machine-learning">Using GPUs for Machine Learning<a class="anchor" aria-label="anchor" href="#using-gpus-for-machine-learning"></a>
</h3>
<p>Artificial Intelligence applications like Machine Learning can be
done on any CPU or GPU. However, GPUs with tensor units can do them
faster and less costly since tensor units can do more operations per
clock cycle, and the lower precision of the results do not matter for
Machine Learning applications. If your system is going to be primarily
used for Machine Learning, you’ll want to look at the tensor units in
the GPUs while the memory will limit the size of the system you can work
with.</p>
<p>AMD and Intel GPUs do not have tensor units. NVIDIA offers tensor
units in their 32-bit RTX GPUs providing an inexpensive means of
accelerating machine learning algorithms. The 32-bit NVIDIA RTX 3090 for
example offers 328 Tensor cores along with 10496 CUDA cores with a
maximum of 24 GB of memory. The 64-bit NVIDIA A100 offers 432 Tensor
cores along with 6912 CUDA cores for high-end computing and 40 GB or 80
GB of memory. These A100s can also be combined with the NVLink
connection so that an 8xA100 GPU cluster can look to the user like a
single GPU with 640 GB of memory.</p>
</div>
<div class="section level3">
<h3 id="profiling-gpu-code">Profiling GPU code<a class="anchor" aria-label="anchor" href="#profiling-gpu-code"></a>
</h3>
<p>It is more difficult to profile GPU programs since half of the code
is running on the CPU and half on the GPU. From outside the program, if
a user can ssh into the compute node then running
<strong>nvidia-smi</strong> provides a snapshot of the GPU utilization
and GPU memory usage. In the job script the <strong>nvprof</strong>
function can be used in place of the <strong>time</strong> function to
give profile information for various functions of the job.</p>
</div>
<div class="section level3">
<h3 id="compiling-and-running-gpu-jobs">Compiling and running GPU jobs<a class="anchor" aria-label="anchor" href="#compiling-and-running-gpu-jobs"></a>
</h3>
<p>Depending on your system you may need to load a module to gain access
to the <strong>nvcc</strong> compiler for CUDA code. <strong>nvcc
–help</strong> can provide you with all the optional parameters, but a
basic compile is like <strong>nvcc code.cu -o cuda_exec_name</strong>.
You can then run the executable like any other except that there must be
a GPU present. If you are on an HPC system with the Slurm scheduler, you
can request a single GPU by adding the <strong>–gres=gpu:1</strong>
parameter. You can also request a specific type of GPU, but this depends
on how each system is set up so you will need to refer to the user
documentations. On our HPC cluster at Kansas State University the
request for one NVIDIA RTX 3090 would be
<strong>–gres=gpu:geforce_rtx_3090:1</strong>.</p>
<div id="run-a-simple-gpu-job-if-you-have-access-to-an-hpc-system-with-gpus" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="run-a-simple-gpu-job-if-you-have-access-to-an-hpc-system-with-gpus" class="callout-inner">
<h3 class="callout-title">Run a simple GPU job if you have access to an
HPC system with GPUs</h3>
<div class="callout-content">
<p>Compile and run the hello_from_gpu.cu CUDA program. You may need to
load a module to gain access to the <strong>nvcc</strong> compiler.
There is an <strong>sb.hello_from_gpu</strong> Slurm batch script to
submit the job.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>The goal is just to start getting you comfortable with compiling and
submitting GPU jobs. Use <strong>nvcc hello_gpu.cu -o
hello_from_gpu</strong> to compile. If you have Slurm on your HPC system
you can submit the job with <strong>sbatch sb.hello_gpu</strong> but you
may need to add a partition.</p>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="summary">Summary<a class="anchor" aria-label="anchor" href="#summary"></a>
</h2>
<hr class="half-width">
<p>GPUs are more difficult to program, so for most scientists you will
only want to know how to run codes when GPUs are involved and not how to
program them yourself. If you are fortunate enough to have an algorithm
that someone has accelerated with a GPU, GPUs can often provide an order
of magnitude increase in speed over just using CPUs and greatly reduce
the cost of doing a calculation.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Start to become comfortable with using GPUs on an HPC system.</li>
</ul>
</div>
</div>
</div>
<div class="section level3">
<h3 id="links-for-additional-information">Links for additional information<a class="anchor" aria-label="anchor" href="#links-for-additional-information"></a>
</h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Tensor_Processing_Unit" class="external-link">GPU
Tensor Unit explanation</a></li>
<li><a href="https://docs.nvidia.com/cuda/" class="external-link">NVIDIA CUDA programming
documentation</a></li>
<li><a href="https://en.wikipedia.org/wiki/List_of_Nvidia_graphics_processing_units" class="external-link">NVIDIA
GPU specs</a></li>
<li><a href="https://rocm.docs.amd.com/projects/HIP/en/latest/" class="external-link">AMD Hip
programming documentation</a></li>
<li><a href="https://en.wikipedia.org/wiki/List_of_AMD_graphics_processing_units" class="external-link">AMD
GPU specs</a></li>
</ul>
</div>
</section></section><section id="aio-high-throughput-computing"><p>Content from <a href="high-throughput-computing.html">High-Throughput Computing</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/high-throughput-computing.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 15 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is the difference between high-throughput computing and cluster
computing?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Learn what types of jobs run well on HTC systems.</li>
<li>Understand how to submit jobs using OSG.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="high-throughput-computing">High-Throughput Computing<a class="anchor" aria-label="anchor" href="#high-throughput-computing"></a>
</h2>
<hr class="half-width">
<p>A typical HPC system today is a cluster computer made of one or more
head nodes and many compute nodes tied together with a common file
server and having a batch scheduler to control where jobs run. Some of
the largest supercomputers in the world are similar conceptually to a
cluster computer but have more custom designed circuit boards as nodes
and may be packaged up and racked in a different manner than cluster
systems that use more off-the-shelf components.</p>
<p>A High-Throughput Computer (HTC) system is designed to run very large
numbers of small jobs and is often made up of many HPC systems separated
geographically. In the U.S. the main example is the Open Science Grid
(OSG) which is open for use to anyone associated with a U.S. university
or national laboratory. Time is given away freely on a first-come
first-served basis and computer resources are donated by various
institutions. Since HTC is geared toward running large numbers of
smaller jobs, the jobs fit well into the spare nooks and crannies of
most HPC systems and these systems are set up to kill any OSG job when
the host institute needs those resources back. In this way the HTC jobs
run invisibly on the over 100 HPC sites spread across the U.S. offering
free computing to any who need to run small jobs while greatly enhancing
the usage of each HPC system by using the spare CPU cycles that would
otherwise go wasted.</p>
<div class="section level3">
<h3 id="large-numbers-of-small-jobs">Large numbers of small jobs<a class="anchor" aria-label="anchor" href="#large-numbers-of-small-jobs"></a>
</h3>
<p>One of the first examples of HTC was the SETI program where
individual PC users could donate their CPU cycles to the project to
search through large quantities of data to try to find signals that
might come from intelligent life. This problem is ideal for HTC since it
can be broken up into large numbers of small jobs, and any job that did
not return an answer in a given period was just thrown away and rerun on
another system.</p>
<p>OSG has the ability to run a wide variety of jobs including large
memory and GPU runs, but it is much more difficult than running the
simple small jobs that it was designed for. The OSG guidelines for the
typical job are 1-8 cores, up to 40 GB memory and 10 GB IO, and up to 20
hours run-time.</p>
<p>The most important aspect of working with HTC systems is that the
jobs be self-contained as much as possible, and be able to run on any
operating system and use mainstream modules. This is essential since
each job may be run on a wide range of HPC environments. Executables
that are dynamically linked can work if you request the matching
resources by specifying things like acceptable CPU architectures.
Statically linked executables will always work. Containers take more
effort to set up but are ideal for HTC since all executables, modules,
and environmental variables are set within the container. Running on
multiple nodes using MPI is possible but difficult usually requiring
containers with the MPI connections specified externally.</p>
</div>
<div class="section level3">
<h3 id="using-osg">Using OSG<a class="anchor" aria-label="anchor" href="#using-osg"></a>
</h3>
<p>Users may submit jobs to the OSG queue through their institute’s
portal if one exists or through the OSG Connect submission service at
the link below. If using the OSG Connect portal you will need to request
access and arrange for a short Zoom meeting with one of their support
staff. There are links to the OSG Consortium and support documentation
at the end of this lesson.</p>
</div>
<div class="section level3">
<h3 id="working-with-the-htcondor-scheduler">Working with the HTCondor scheduler<a class="anchor" aria-label="anchor" href="#working-with-the-htcondor-scheduler"></a>
</h3>
<p>Submitting jobs to HTCondor for scheduling on any of the hundreds of
remote systems available is similar to using any scheduler, except for
the notes above on the job not relying on modules and libraries that may
not be available or labeled the same everywhere. Below is an example job
script to run the stand-alone executable <strong>namd2</strong>. Note
that the X64_64 CPU architecture is specified. The script requests 1 GB
of disk for this job and directs that all files from the directory
<strong>input_files</strong> be transferred along with the job at the
start, and all files in <strong>output</strong> be transferred back at
the end. The <strong>queue 1</strong> command then specifies the number
of these jobs to submit. If multiple jobs are submitted then the
environmental variable <strong>$(Process)</strong> will be used in the
script to differentiate each with that being between zero and the number
of jobs specified minus one.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co">#!/bin/bash -l</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a> </span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="ex">output</span> = osg.namd.out</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="ex">error</span> = osg.namd.error</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="ex">log</span> = osg.namd.log</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a> </span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="co"># Requested resources</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="ex">request_cpus</span> = 8</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="ex">request_memory</span> = 8 GB</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="ex">request_disk</span> = 1 GB</span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="ex">requirements</span> = Arch == <span class="st">"X86_64"</span> <span class="kw">&amp;&amp;</span> <span class="ex">HAS_MODULES</span> == True</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a> </span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a><span class="ex">transfer_input_files</span> = input_files/         <span class="co"># Slash means all files in that directory</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a><span class="ex">executable</span> = namd2</span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a><span class="ex">arguments</span> = +p8 test.0.namd</span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a><span class="ex">transfer_output_files</span> = output</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a><span class="ex">queue</span> 1</span></code></pre>
</div>
<p>Most systems will have support for modules, but the
<strong>HAS_MODULES == True</strong> requirement can mean some systems
are not supported. Most systems use RHEL7, so specifying that may also
rule out use of RHEL6 and RHEL8 systems. In general, if you use a
mainstream operating system and modules then you should be fine.
Otherwise you likely will need to use a container.</p>
<p>Once you have the script you can submit, monitor, and control the job
using commands like those below.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="op">&gt;</span> condor_submit <span class="ex">htc_job.sh</span>                   <span class="co"># Submit the condor script to the queue</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="op">&gt;</span> condor_q                                   <span class="co"># Check on the status while in the queue</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="op">&gt;</span> condor_q <span class="ex">netid</span>                             <span class="co"># Check status of currently running jobs</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="op">&gt;</span> condor_q <span class="ex">121763</span>                            <span class="co"># Check status of a particular job</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="op">&gt;</span> condor_history <span class="ex">121763</span>                      <span class="co"># Check status of a job that is completed</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="op">&gt;</span> condor_history <span class="ex">-long</span> 121763                <span class="co"># Same but report more info</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="op">&gt;</span> condor_rm <span class="ex">121763</span>                           <span class="co"># Remove the job number specified</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="op">&gt;</span> condor_rm <span class="ex">daveturner</span>                       <span class="co"># Remove all jobs for the given username</span></span></code></pre>
</div>
</div>
</section><section><h2 class="section-heading" id="htc-outside-the-u-s-">HTC Outside the U.S.<a class="anchor" aria-label="anchor" href="#htc-outside-the-u-s-"></a>
</h2>
<hr class="half-width">
<p>Need to add info about non-US HTC systems</p>
<div id="optional-homework-get-an-osg-account-and-submit-a-test-job." class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div id="optional-homework-get-an-osg-account-and-submit-a-test-job." class="callout-inner">
<h3 class="callout-title">Optional Homework: Get an OSG account and
submit a test job.</h3>
<div class="callout-content">
<p>If you are in the U.S. and want a big challenge, request an OSG
account and try submitting some small jobs.</p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="summary">Summary<a class="anchor" aria-label="anchor" href="#summary"></a>
</h2>
<hr class="half-width">
<p>High-Throughput Computing is free in the U.S. using the Open Science
Grid. It is great for running large numbers of small jobs. Using it for
GPU jobs or when large memory or IO is needed is possible but much more
challenging. Aside from that it is similar to running jobs using any
other scheduler.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Explore the basics of HTC computing.</li>
</ul>
</div>
</div>
</div>
<div class="section level3">
<h3 id="links-for-additional-information">Links for additional information<a class="anchor" aria-label="anchor" href="#links-for-additional-information"></a>
</h3>
<ul>
<li><a href="https://osg-htc.org" class="external-link">OSG Consortium</a></li>
<li><a href="https://connect.osg-htc.org" class="external-link">OSG Connect</a></li>
<li><a href="https://support.opensciencegrid.org/support/home" class="external-link">OSG
support home</a></li>
<li><a href="https://osg-htc.org/services/open_science_pool.html" class="external-link">OSG
typical jobs</a></li>
<li><a href="https://support.opensciencegrid.org/support/solutions/articles/5000632058-is-the-open-science-grid-for-you-" class="external-link">OSG
typical jobs</a></li>
<li><a href="https://www.youtube.com/watch?v=oMAvxsFJaw4" class="external-link">HTCondor
scheduler youtube video</a></li>
</ul>
</div>
</section></section><section id="aio-hpc-resources"><p>Content from <a href="hpc-resources.html">HPC Resources</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/hpc-resources.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 15 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How do I get access to HPC resources?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand what HPC resources are available in the U.S.</li>
<li>Learn how to access these resources for free.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="getting-access-to-hpc-resources">Getting Access to HPC Resources<a class="anchor" aria-label="anchor" href="#getting-access-to-hpc-resources"></a>
</h2>
<hr class="half-width">
<p>It is very typical to start a project on a personal computer only to
find that you need more performance either as computing power or memory.
The next step may be to run your code on a more powerful workstation
such as a departmental server. But when you still need more performance
where do you go? Most scientists do not understand that there are many
options for getting more powerful computing resources, and that they are
commonly free for the asking.</p>
<p>If you are in a university or laboratory environment the first place
to look is your local supercomputing center if you have one. While many
provide priority access to the compute resources to those that provide
research funds, most also have some means of providing significant
resources to users that can’t provide financial support. Many university
cluster computers work on the <strong>condo</strong> model where
scientific groups can purchase compute nodes that they have full
priority on, but in return for the university managing those compute
nodes anyone else is allowed to use them when idle. This pay for
priority model works well in sharing computing resources between the
haves and the have nots.</p>
<p>In many states one of the larger universities may provide free access
to scientists in smaller universities in the state. Kansas State
University for example provides free access to anyone associated with
any university in the state. Many other states provide funding for a
single supercomputing center that all in the state can use.</p>
<div class="section level3">
<h3 id="remote-resources">Remote resources<a class="anchor" aria-label="anchor" href="#remote-resources"></a>
</h3>
<p>There are many national supercomputing centers in the U.S. that
receive federal funding from the National Science Foundation (NSF) and
Department of Energy (DoE). These supercomputers can cost $10-$100
million or above and have capacities now over 1 exa-flops (billion
billion floating-point operations per second). When these are funded,
part of the compute cycles are designated for access to scientists not
directly associated with those institutions.</p>
<p>Account and allocation requests as well as access is handled through
user portals. Most of these remote systems have startup accounts
available that may typically be in the range of 5,000 core-hours (5000
hours on 1 core or 500 hours on 10 cores for example). Getting access is
as easy as knowing where and how to ask.</p>
<div class="section level4">
<h4 id="the-access-portal-to-remote-nsf-supercomputers">The ACCESS portal to remote NSF supercomputers<a class="anchor" aria-label="anchor" href="#the-access-portal-to-remote-nsf-supercomputers"></a>
</h4>
<p>The ACCESS portal is formerly known as XSEDE. The link below is where
to go to request an account and allocation, submit a proposal, and find
documentation and support. There are a very wide variety of
supercomputing systems available to users associated with a university
or laboratory. Small startup allocations usually only take a few minutes
to apply for and are typically approved within a few days.</p>
<p>Many universities have a <strong>Campus Champion</strong> with a
larger allocation on many systems designed to be shared across a campus.
When these allocations run out, they can simply request more but they
are intended to get users needing long-term support the experience on a
system so that they can submit a full proposal. While startup requests
are typically on a specific system and may be around 5,000 core-hours,
campus champions may be granted ~5 times as much plus access to GPU and
large memory nodes. If you are on a campus with a Campus Champion then
you just need to apply for an account then contact them to get access to
the actual allocations.</p>
<p>Follow the ACCESS link at the end of this lesson for a complete list
of supercomputing resources, but below is an example of some of the
systems available (last updated August of 2022).</p>
</div>
</div>
<div class="section level3">
<h3 id="bridges2-at-the-pittsburgh-supercomputing-center-psc">Bridges2 at the Pittsburgh Supercomputing Center (PSC)<a class="anchor" aria-label="anchor" href="#bridges2-at-the-pittsburgh-supercomputing-center-psc"></a>
</h3>
<p><strong>488 RM Regular Memory compute nodes</strong></p>
<ul>
<li>2 x AMD EPYC 7742 –&gt; 128 cores</li>
<li>256 GB memory (16 more nodes have 512 GB each)</li>
<li>3.84 TB NVMe SSD</li>
<li>Mellanox HDR 200 Gbps network</li>
</ul>
<p><strong>4 EM Extreme Memory compute nodes</strong></p>
<ul>
<li>4 x Intel Cascade 8260M –&gt; 96 cores</li>
<li>4 TB memory</li>
<li>7.68 TB NVMe SSD</li>
<li>Mellanox HDR 200 Gbps network</li>
</ul>
<p><strong>24 GPU compute nodes</strong></p>
<ul>
<li>2 x Intel Gold Cascade 6248 –&gt; 40 cores</li>
<li>8 x NVIDIA Tesla v100 32 GB sxm2 GPU cards</li>
<li>512 GB memory</li>
<li>7.68 TB NVMe SSD</li>
<li>Mellanox HDR 200 Gbps network</li>
</ul>
</div>
<div class="section level3">
<h3 id="expanse-at-the-san-diego-supercomputing-center-sdsc">Expanse at the San Diego Supercomputing Center (SDSC)<a class="anchor" aria-label="anchor" href="#expanse-at-the-san-diego-supercomputing-center-sdsc"></a>
</h3>
<p><strong>728 compute nodes</strong></p>
<ul>
<li>2 x AMD EPYC 7742 –&gt; 128 cores</li>
<li>256 GB memory</li>
</ul>
<p><strong>4 Large Memory nodes</strong></p>
<ul>
<li>4 x Intel Cascade 8260M –&gt; 96 cores</li>
<li>2 TB memory</li>
</ul>
<p><strong>52 GPU nodes</strong></p>
<ul>
<li>2 x Intel Xeon 6248 –&gt; 40 cores</li>
<li>4 x NVIDIA Tesla v100 GPU cards</li>
<li>384 GB memory</li>
</ul>
<p><strong>Cluster-wide capabilities</strong></p>
<ul>
<li>12 PetaByte Lustre file system</li>
<li>7 PetaByte CEPH object store</li>
<li>56 Gbps bi-directional HDR InfiniBand network</li>
</ul>
</div>
</section><section><h2 class="section-heading" id="national-energy-research-scientific-computing-center-nersc">National Energy Research Scientific Computing Center (NERSC)<a class="anchor" aria-label="anchor" href="#national-energy-research-scientific-computing-center-nersc"></a>
</h2>
<hr class="half-width">
<p>While allocations for the NSF supercomputing centers are managed
through the ACCESS website, external access to the Department of Energy
(DoE) supercomputers are managed through NERSC with the website link at
the end of this module. Many DoE supercomputers can be accessed by
scientists in universities and laboratories, but the process is more
involved. Access is still free, but you typically need to write a
proposal for significant node-hours and fully justify that the science
you intend to do is important and fits within the DoE mission, and
demonstrate that your code will use the requested resources
efficiently.</p>
</section><section><h2 class="section-heading" id="open-science-grid-osg">Open Science Grid (OSG)<a class="anchor" aria-label="anchor" href="#open-science-grid-osg"></a>
</h2>
<hr class="half-width">
<p>If you need to run many smaller jobs, then High-Throughput Computing
(HTC) covered in the previous chapter may be ideal for you. OSG access
is fairly easy for users in the U.S. and provides virtually unlimited
access.</p>
</section><section><h2 class="section-heading" id="national-research-platform-nrp">National Research Platform (NRP)<a class="anchor" aria-label="anchor" href="#national-research-platform-nrp"></a>
</h2>
<hr class="half-width">
<p>The NRP is a partnership of over 50 institutions led by UC San Diego
supported in large part by NSF. The Nautilus system is a HyperCluster
for running containerized big data applications using kubernetes for the
container management. This is a distributed set of compute nodes similar
to OSG but applications must specifically be self-contained and are
guaranteed isolated access to the resources allocated.</p>
<p>While kubernetes is more difficult for the average user, this system
provides access to much more powerful computing including very high-end
GPUs. The compute nodes are mainly GPU-based and research is aimed at
Machine Learning codes.</p>
</section><section><h2 class="section-heading" id="cloud-computing">Cloud Computing<a class="anchor" aria-label="anchor" href="#cloud-computing"></a>
</h2>
<hr class="half-width">
<p>Running HPC jobs in the cloud is much more difficult and costly than
many people understand. Most cloud computing vendors do give small
amounts of access away for free on a trial basis for those that want to
experiment. The amount is very minimal in the context of running an HPC
job.</p>
<p>As of August of 2024, Google Cloud Platform (GCP) offered $300 credit
to new customers for example. Amazon Web Services (AWS) offered several
free trial plans with $750 credits. Microsoft Azure offers a $200 credit
for 30 days for eligible new customers.</p>
</section><section><h2 class="section-heading" id="summary">Summary<a class="anchor" aria-label="anchor" href="#summary"></a>
</h2>
<hr class="half-width">
<p>Many projects that start on a laptop or desktop system end up needing
larger resources. Transitioning to an HPC system can be challenging, but
the best news is that HPC resources are often free for the asking. You
just need to know where and how to ask, and hopefully this module will
give you ideas on where to start.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>There are many HPC resources that are totally free for the
asking.</li>
</ul>
</div>
</div>
</div>
<div class="section level3">
<h3 id="links-for-additional-information">Links for additional information<a class="anchor" aria-label="anchor" href="#links-for-additional-information"></a>
</h3>
<ul>
<li><a href="https://access-ci.org" class="external-link">ACCESS Portal</a></li>
<li><a href="https://nersc.gov/" class="external-link">NERSC Portal</a></li>
<li><a href="https://osg-htc.org" class="external-link">OSG Consortium</a></li>
<li><a href="https://nationalresearchplatform.org" class="external-link">NRP National Research
Platform</a></li>
<li><a href="https://aws.amazon.com/free/" class="external-link">AWS Cloud Services</a></li>
<li><a href="https://cloud.google.com/free" class="external-link">GCP Services</a></li>
<li><a href="https://azure.microsoft.com/en-us/offers/ms-azr-0044p/" class="external-link">Microsoft
Azure</a></li>
</ul>
</div>
</section></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/README.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/DrDaveTurner/HPC-User/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/DrDaveTurner/HPC-User/" class="external-link">Source</a></p>
				<p><a href="https://github.com/DrDaveTurner/HPC-User/blob/main/CITATION.cff" class="external-link">Cite</a> | <a href="mailto:drdaveturner@gmail.com">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.17.1" class="external-link">sandpaper (0.17.1)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.9" class="external-link">pegboard (0.7.9)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.7" class="external-link">varnish (1.0.7)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "LearningResource",
  "@id": "https://DrDaveTurner.github.io/HPC-User/instructor/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/LearningResource/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": " HPC, software, lesson, The Carpentries, Python, C, C++, Fortran, R, Matlab",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://DrDaveTurner.github.io/HPC-User/instructor/aio.html",
  "identifier": "https://DrDaveTurner.github.io/HPC-User/instructor/aio.html",
  "dateCreated": "2022-01-01",
  "dateModified": "2025-12-02",
  "datePublished": "2025-12-02"
}

  </script><script>
		feather.replace();
	</script>
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

